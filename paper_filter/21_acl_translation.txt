|Contrastive Learning for Many-to-many Multilingual Neural Machine Translation|acl21||https://aclanthology.org/2021.acl-long.21/|
|Understanding the Properties of Minimum Bayes Risk Decoding in Neural Machine Translation|acl21||https://aclanthology.org/2021.acl-long.22/|
|Multi-Head Highly Parallelized LSTM Decoder for Neural Machine Translation|acl21||https://aclanthology.org/2021.acl-long.23/|
|Learning Language Specific Sub-network for Multilingual Machine Translation|acl21||https://aclanthology.org/2021.acl-long.25/|
|Do Context-Aware Translation Models Pay the Right Attention?|acl21||https://aclanthology.org/2021.acl-long.65/|
|Multilingual Speech Translation from Efficient Finetuning of Pretrained Models|acl21||https://aclanthology.org/2021.acl-long.68/|
|Analyzing the Source and Target Contributions to Predictions in Neural Machine Translation|acl21||https://aclanthology.org/2021.acl-long.91/|
|Improving Zero-Shot Translation by Disentangling Positional Information|acl21||https://aclanthology.org/2021.acl-long.101/|
|Attention Calibration for Transformer in Neural Machine Translation|acl21||https://aclanthology.org/2021.acl-long.103/|
|Diverse Pretrained Context Encodings Improve Document Translation|acl21||https://aclanthology.org/2021.acl-long.104/|
|Crafting Adversarial Examples for Neural Machine Translation|acl21||https://aclanthology.org/2021.acl-long.153/|
|Glancing Transformer for Non-Autoregressive Neural Machine Translation|acl21||https://aclanthology.org/2021.acl-long.155/|
|Beyond Sentence-Level End-to-End Speech Translation: Context Helps|acl21||https://aclanthology.org/2021.acl-long.200/|
|Stacked Acoustic-and-Textual Encoding: Integrating the Pre-trained Models into Speech Translation Encoders|acl21||https://aclanthology.org/2021.acl-long.204/|
|Self-Training Sampling with Monolingual Data Uncertainty for Neural Machine Translation|acl21||https://aclanthology.org/2021.acl-long.221/|
|Breaking the Corpus Bottleneck for Context-Aware Neural Machine Translation with Cross-Task Pre-training|acl21||https://aclanthology.org/2021.acl-long.222/|
|Guiding Teacher Forcing with Seer Forcing for Neural Machine Translation|acl21||https://aclanthology.org/2021.acl-long.223/|
|Cascade versus Direct Speech Translation: Do the Differences Still Make a Difference?|acl21||https://aclanthology.org/2021.acl-long.224/|
|Unsupervised Neural Machine Translation for Low-Resource Domains via Meta-Learning|acl21||https://aclanthology.org/2021.acl-long.225/|
|Online Learning Meets Machine Translation Evaluation: Finding the Best Systems with the Least Human Effort|acl21||https://aclanthology.org/2021.acl-long.242/|
|From Machine Translation to Code-Switching: Generating High-Quality Code-Switched Text|acl21||https://aclanthology.org/2021.acl-long.245/|
|Fast and Accurate Neural Machine Translation with Translation Memory|acl21||https://aclanthology.org/2021.acl-long.246/|
|Rejuvenating Low-Frequency Words: Making the Most of Parallel Data in Non-Autoregressive Translation|acl21||https://aclanthology.org/2021.acl-long.266/|
|G-Transformer for Document-Level Machine Translation|acl21||https://aclanthology.org/2021.acl-long.267/|
|Prevent the Language Model from being Overconfident in Neural Machine Translation|acl21||https://aclanthology.org/2021.acl-long.268/|
|Point, Disambiguate and Copy: Incorporating Bilingual Dictionaries for Neural Machine Translation|acl21||https://aclanthology.org/2021.acl-long.307/|
|Towards User-Driven Neural Machine Translation|acl21||https://aclanthology.org/2021.acl-long.310/|
|End-to-End Lexically Constrained Machine Translation for Morphologically Rich Languages|acl21||https://aclanthology.org/2021.acl-long.311/|
|Improving Speech Translation by Understanding and Learning from the Auxiliary Text Translation Task|acl21||https://aclanthology.org/2021.acl-long.328/|
|SemFace: Pre-training Encoder and Decoder with a Semantic Interface for Neural Machine Translation|acl21||https://aclanthology.org/2021.acl-long.348/|
|Energy-Based Reranking: Improving Neural Machine Translation Using Energy-Based Models|acl21||https://aclanthology.org/2021.acl-long.349/|
|On Compositional Generalization of Neural Machine Translation|acl21||https://aclanthology.org/2021.acl-long.368/|
|GWLAN: General Word-Level AutocompletioN for Computer-Aided Translation|acl21||https://aclanthology.org/2021.acl-long.370/|
|CTFN: Hierarchical Learning for Multimodal Sentiment Analysis Using Coupled-Translation Fusion Network|acl21||https://aclanthology.org/2021.acl-long.412/|
|Rewriter-Evaluator Architecture for Neural Machine Translation|acl21||https://aclanthology.org/2021.acl-long.443/|
|Modeling Bilingual Conversational Characteristics for Neural Chat Translation|acl21||https://aclanthology.org/2021.acl-long.444/|
|Importance-based Neuron Allocation for Multilingual Neural Machine Translation|acl21||https://aclanthology.org/2021.acl-long.445/|
|Good for Misconceived Reasons: An Empirical Revisiting on the Need for Visual Context in Multimodal Machine Translation|acl21||https://aclanthology.org/2021.acl-long.480/|
|Selective Knowledge Distillation for Neural Machine Translation|acl21||https://aclanthology.org/2021.acl-long.504/|
|Measuring and Increasing Context Usage in Context-Aware Machine Translation|acl21||https://aclanthology.org/2021.acl-long.505/|
|Mid-Air Hand Gestures for Post-Editing of Machine Translation|acl21||https://aclanthology.org/2021.acl-long.527/|
|Beyond Noise: Mitigating the Impact of Fine-grained Semantic Divergences on Neural Machine Translation|acl21||https://aclanthology.org/2021.acl-long.562/|
|Discriminative Reranking for Neural Machine Translation|acl21||https://aclanthology.org/2021.acl-long.563/|
|Scientific Credibility of Machine Translation Research: A Meta-Evaluation of 769 Papers|acl21||https://aclanthology.org/2021.acl-long.566/|
|Neural Machine Translation with Monolingual Translation Memory|acl21||https://aclanthology.org/2021.acl-long.567/|
|Vocabulary Learning via Optimal Transport for Neural Machine Translation|acl21||https://aclanthology.org/2021.acl-long.571/|
|Difficulty-Aware Machine Translation Evaluation|acl21||https://aclanthology.org/2021.acl-short.5/|
|Gender bias amplification during Speed-Quality optimization in Neural Machine Translation|acl21||https://aclanthology.org/2021.acl-short.15/|
|Machine Translation into Low-resource Language Varieties|acl21||https://aclanthology.org/2021.acl-short.16/|
|The Case for Translation-Invariant Self-Attention in Transformer-Based Language Models|acl21||https://aclanthology.org/2021.acl-short.18/|
|Multilingual Agreement for Multilingual Neural Machine Translation|acl21||https://aclanthology.org/2021.acl-short.31/|
|Modeling Task-Aware MIMO Cardinality for Efficient Multilingual Neural Machine Translation|acl21||https://aclanthology.org/2021.acl-short.46/|
|Adaptive Nearest Neighbor Machine Translation|acl21||https://aclanthology.org/2021.acl-short.47/|
|Bilingual Mutual Information Based Adaptive Training for Neural Machine Translation|acl21||https://aclanthology.org/2021.acl-short.65/|
|When is Char Better Than Subword: A Systematic Study of Segmentation Algorithms for Neural Machine Translation|acl21||https://aclanthology.org/2021.acl-short.69/|
|Improving Lexically Constrained Neural Machine Translation with Source-Conditioned Masked Span Prediction|acl21||https://aclanthology.org/2021.acl-short.94/|
|Lightweight Adapter Tuning for Multilingual Speech Translation|acl21||https://aclanthology.org/2021.acl-short.103/|
|BERTTune: Fine-Tuning Neural Machine Translation with BERTScore|acl21||https://aclanthology.org/2021.acl-short.115/|
|Don’t Rule Out Monolingual Speakers: A Method For Crowdsourcing Machine Translation Data|acl21||https://aclanthology.org/2021.acl-short.139/|
|Transformer-Based Direct Hidden Markov Model for Machine Translation|acl21||https://aclanthology.org/2021.acl-srw.3/|
|Video-guided Machine Translation with Spatial Hierarchical Attention Network|acl21||https://aclanthology.org/2021.acl-srw.9/|
|Data Augmentation with Unsupervised Machine Translation Improves the Structural Similarity of Cross-lingual Word Embeddings|acl21||https://aclanthology.org/2021.acl-srw.17/|
|Neural Machine Translation with Synchronous Latent Phrase Structure|acl21||https://aclanthology.org/2021.acl-srw.33/|
|On the differences between BERT and MT encoder spaces and how to address them in translation tasks|acl21||https://aclanthology.org/2021.acl-srw.35/|
|Synchronous Syntactic Attention for Transformer Neural Machine Translation|acl21||https://aclanthology.org/2021.acl-srw.36/|
|IntelliCAT: Intelligent Machine Translation Post-Editing with Quality Estimation and Translation Suggestion|acl21||https://aclanthology.org/2021.acl-demo.2/|
|NeurST: Neural Speech Translation Toolkit|acl21||https://aclanthology.org/2021.acl-demo.7/|
|ChrEnTranslate: Cherokee-English Machine Translation Demo with Quality Estimation and Corrective Feedback|acl21||https://aclanthology.org/2021.acl-demo.33/|
|Many-to-English Machine Translation Tools, Data, and Pretrained Models|acl21||https://aclanthology.org/2021.acl-demo.37/|
|Pre-training Methods for Neural Machine Translation|acl21||https://aclanthology.org/2021.acl-tutorials.4/|
|Product Review Translation: Parallel Corpus Creation and Robustness towards User-generated Noisy Text|acl21||https://aclanthology.org/2021.ecnlp-1.21/|
|Evaluating Gender Bias in Hindi-English Machine Translation|acl21||https://aclanthology.org/2021.gebnlp-1.3/|
|Proceedings of the 18th International Conference on Spoken Language Translation (IWSLT 2021)|acl21||https://aclanthology.org/2021.iwslt-1.0/|
|The USTC-NELSLIP Systems for Simultaneous Speech Translation Task at IWSLT 2021|acl21||https://aclanthology.org/2021.iwslt-1.2/|
|NAIST English-to-Japanese Simultaneous Translation System for IWSLT 2021 Simultaneous Text-to-text Task|acl21||https://aclanthology.org/2021.iwslt-1.3/|
|The University of Edinburgh’s Submission to the IWSLT21 Simultaneous Translation Task|acl21||https://aclanthology.org/2021.iwslt-1.4/|
|Without Further Ado: Direct and Simultaneous Speech Translation by AppTek in 2021|acl21||https://aclanthology.org/2021.iwslt-1.5/|
|The Volctrans Neural Speech Translation System for IWSLT 2021|acl21||https://aclanthology.org/2021.iwslt-1.6/|
|The NiuTrans End-to-End Speech Translation System for IWSLT 2021 Offline Task|acl21||https://aclanthology.org/2021.iwslt-1.9/|
|ESPnet-ST IWSLT 2021 Offline Speech Translation System|acl21||https://aclanthology.org/2021.iwslt-1.10/|
|End-to-End Speech Translation with Pre-trained Models and Adapters: UPC at IWSLT 2021|acl21||https://aclanthology.org/2021.iwslt-1.11/|
|VUS at IWSLT 2021: A Finetuned Pipeline for Offline Speech Translation|acl21||https://aclanthology.org/2021.iwslt-1.12/|
|KIT’s IWSLT 2021 Offline Speech Translation System|acl21||https://aclanthology.org/2021.iwslt-1.13/|
|FST: the FAIR Speech Translation System for the IWSLT21 Multilingual Shared Task|acl21||https://aclanthology.org/2021.iwslt-1.14/|
|Maastricht University’s Multilingual Speech Translation System for IWSLT 2021|acl21||https://aclanthology.org/2021.iwslt-1.15/|
|ZJU’s IWSLT 2021 Speech Translation System|acl21||https://aclanthology.org/2021.iwslt-1.16/|
|Multilingual Speech Translation with Unified Transformer: Huawei Noah’s Ark Lab at IWSLT 2021|acl21||https://aclanthology.org/2021.iwslt-1.17/|
|Multilingual Speech Translation KIT @ IWSLT2021|acl21||https://aclanthology.org/2021.iwslt-1.18/|
|Edinburgh’s End-to-End Multilingual Speech Translation System for IWSLT 2021|acl21||https://aclanthology.org/2021.iwslt-1.19/|
|ON-TRAC’ systems for the IWSLT 2021 low-resource speech translation and multilingual speech translation shared tasks|acl21||https://aclanthology.org/2021.iwslt-1.20/|
|IMS’ Systems for the IWSLT 2021 Low-Resource Speech Translation Task|acl21||https://aclanthology.org/2021.iwslt-1.21/|
|The USYD-JD Speech Translation System for IWSLT2021|acl21||https://aclanthology.org/2021.iwslt-1.22/|
|mixSeq: A Simple Data Augmentation Methodfor Neural Machine Translation|acl21||https://aclanthology.org/2021.iwslt-1.23/|
|Self-Guided Curriculum Learning for Neural Machine Translation|acl21||https://aclanthology.org/2021.iwslt-1.25/|
|Inverted Projection for Robust Speech Translation|acl21||https://aclanthology.org/2021.iwslt-1.28/|
|Towards the evaluation of automatic simultaneous speech translation from a communicative perspective|acl21||https://aclanthology.org/2021.iwslt-1.29/|
|Tag Assisted Neural Machine Translation of Film Subtitles|acl21||https://aclanthology.org/2021.iwslt-1.30/|
|Data Augmentation by Concatenation for Low-Resource Translation: A Mystery and a Solution|acl21||https://aclanthology.org/2021.iwslt-1.33/|
|Time-Aware Ancient Chinese Text Translation and Inference|acl21||https://aclanthology.org/2021.lchange-1.1/|
|Code to Comment Translation: A Comparative Study on Model Effectiveness & Errors|acl21||https://aclanthology.org/2021.nlp4prog-1.1/|
|Inductively Representing Out-of-Knowledge-Graph Entities by Optimal Estimation Under Translational Assumptions|acl21||https://aclanthology.org/2021.repl4nlp-1.10/|
|IIE-NLP-Eyas at SemEval-2021 Task 4: Enhancing PLM for ReCAM with Special Tokens, Re-Ranking, Siamese Encoders and Back Translation|acl21||https://aclanthology.org/2021.semeval-1.22/|
|UAlberta at SemEval-2021 Task 2: Determining Sense Synonymy via Translations|acl21||https://aclanthology.org/2021.semeval-1.101/|
|A Study of Morphological Robustness of Neural Machine Translation|acl21||https://aclanthology.org/2021.sigmorphon-1.6/|
|Proceedings of the 8th Workshop on Asian Translation (WAT2021)|acl21||https://aclanthology.org/2021.wat-1.0/|
|Overview of the 8th Workshop on Asian Translation|acl21||https://aclanthology.org/2021.wat-1.1/|
|NHK’s Lexically-Constrained Neural Machine Translation at WAT 2021|acl21||https://aclanthology.org/2021.wat-1.2/|
|Input Augmentation Improves Constrained Beam Search for Neural Machine Translation: NTT at WAT 2021|acl21||https://aclanthology.org/2021.wat-1.3/|
|NICT’s Neural Machine Translation Systems for the WAT21 Restricted Translation Task|acl21||https://aclanthology.org/2021.wat-1.4/|
|Machine Translation with Pre-specified Target-side Words Using a Semi-autoregressive Model|acl21||https://aclanthology.org/2021.wat-1.5/|
|Hybrid Statistical Machine Translation for English-Myanmar: UTYCC Submission to WAT-2021|acl21||https://aclanthology.org/2021.wat-1.7/|
|NICT-2 Translation System at WAT-2021: Applying a Pretrained Multilingual Encoder-Decoder Model to Low-resource Language Pairs|acl21||https://aclanthology.org/2021.wat-1.8/|
|Rakuten’s Participation in WAT 2021: Examining the Effectiveness of Pre-trained Models for Multilingual and Multimodal Machine Translation|acl21||https://aclanthology.org/2021.wat-1.9/|
|Zero-pronoun Data Augmentation for Japanese-to-English Translation|acl21||https://aclanthology.org/2021.wat-1.11/|
|Evaluation Scheme of Focal Translation for Japanese Partially Amended Statutes|acl21||https://aclanthology.org/2021.wat-1.12/|
|Improved English to Hindi Multimodal Neural Machine Translation|acl21||https://aclanthology.org/2021.wat-1.17/|
|IITP at WAT 2021: System description for English-Hindi Multimodal Translation Task|acl21||https://aclanthology.org/2021.wat-1.18/|
|ViTA: Visual-Linguistic Translation by Aligning Object Tags|acl21||https://aclanthology.org/2021.wat-1.19/|
|TMEKU System for the WAT2021 Multimodal Translation Task|acl21||https://aclanthology.org/2021.wat-1.20/|
|Optimal Word Segmentation for Neural Machine Translation into Dravidian Languages|acl21||https://aclanthology.org/2021.wat-1.21/|
|Itihasa: A large-scale corpus for Sanskrit to English translation|acl21||https://aclanthology.org/2021.wat-1.22/|
|Multilingual Machine Translation Systems at WAT 2021: One-to-Many and Many-to-One Transformer based NMT|acl21||https://aclanthology.org/2021.wat-1.28/|
|IITP-MT at WAT2021: Indic-English Multilingual Neural Machine Translation using Romanized Vocabulary|acl21||https://aclanthology.org/2021.wat-1.29/|
|ANVITA Machine Translation System for WAT 2021 MultiIndicMT Shared Task|acl21||https://aclanthology.org/2021.wat-1.30/|
