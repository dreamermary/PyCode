|题目|会议||链接|
|---|---|---|---|
|The USTC-NELSLIP Systems for Simultaneous Speech Translation Task at IWSLT 2021|acl21||https://aclanthology.org/2021.iwslt-1.2/|
|Multilingual Speech Translation from Efficient Finetuning of Pretrained Models|acl21||https://aclanthology.org/2021.acl-long.68/|
|Beyond Sentence-Level End-to-End Speech Translation: Context Helps|acl21||https://aclanthology.org/2021.acl-long.200/|
|Stacked Acoustic-and-Textual Encoding: Integrating the Pre-trained Models into Speech Translation Encoders|acl21||https://aclanthology.org/2021.acl-long.204/|
|Cascade versus Direct Speech Translation: Do the Differences Still Make a Difference?|acl21||https://aclanthology.org/2021.acl-long.224/|
|Improving Speech Translation by Understanding and Learning from the Auxiliary Text Translation Task|acl21||https://aclanthology.org/2021.acl-long.328/|
|Without Further Ado: Direct and Simultaneous Speech Translation by AppTek in 2021|acl21||https://aclanthology.org/2021.iwslt-1.5/|
|The Volctrans Neural Speech Translation System for IWSLT 2021|acl21||https://aclanthology.org/2021.iwslt-1.6/|
|A Large-Scale Chinese Multimodal NER Dataset with Speech Clues|acl21||https://aclanthology.org/2021.acl-long.218/|
|The NiuTrans End-to-End Speech Translation System for IWSLT 2021 Offline Task|acl21||https://aclanthology.org/2021.iwslt-1.9/|
|ESPnet-ST IWSLT 2021 Offline Speech Translation System|acl21||https://aclanthology.org/2021.iwslt-1.10/|
|End-to-End Speech Translation with Pre-trained Models and Adapters: UPC at IWSLT 2021|acl21||https://aclanthology.org/2021.iwslt-1.11/|
|VUS at IWSLT 2021: A Finetuned Pipeline for Offline Speech Translation|acl21||https://aclanthology.org/2021.iwslt-1.12/|
|KIT’s IWSLT 2021 Offline Speech Translation System|acl21||https://aclanthology.org/2021.iwslt-1.13/|
|FST: the FAIR Speech Translation System for the IWSLT21 Multilingual Shared Task|acl21||https://aclanthology.org/2021.iwslt-1.14/|
|Maastricht University’s Multilingual Speech Translation System for IWSLT 2021|acl21||https://aclanthology.org/2021.iwslt-1.15/|
|ZJU’s IWSLT 2021 Speech Translation System|acl21||https://aclanthology.org/2021.iwslt-1.16/|
|Multilingual Speech Translation with Unified Transformer: Huawei Noah’s Ark Lab at IWSLT 2021|acl21||https://aclanthology.org/2021.iwslt-1.17/|
|Multilingual Speech Translation KIT @ IWSLT2021|acl21||https://aclanthology.org/2021.iwslt-1.18/|
|Edinburgh’s End-to-End Multilingual Speech Translation System for IWSLT 2021|acl21||https://aclanthology.org/2021.iwslt-1.19/|
|ON-TRAC’ systems for the IWSLT 2021 low-resource speech translation and multilingual speech translation shared tasks|acl21||https://aclanthology.org/2021.iwslt-1.20/|
|IMS’ Systems for the IWSLT 2021 Low-Resource Speech Translation Task|acl21||https://aclanthology.org/2021.iwslt-1.21/|
|The USYD-JD Speech Translation System for IWSLT2021|acl21||https://aclanthology.org/2021.iwslt-1.22/|
|Inverted Projection for Robust Speech Translation|acl21||https://aclanthology.org/2021.iwslt-1.28/|
|Towards the evaluation of automatic simultaneous speech translation from a communicative perspective|acl21||https://aclanthology.org/2021.iwslt-1.29/|
|Lightweight Adapter Tuning for Multilingual Speech Translation|acl21||https://aclanthology.org/2021.acl-short.103/|
|NeurST: Neural Speech Translation Toolkit|acl21||https://aclanthology.org/2021.acl-demo.7/|
|||||
|Uwspeech: Speech To Speech Translation For Unwritten Languages|aaai21||	https://arxiv.org/abs/2006.07926|
|Listen, Understand And Translate: Triple Supervision Decouples End-To-End Speech-To-Text Translation	|aaai21||https://www.aaai.org/AAAI21Papers/AAAI-10343.DongQ.pdf|
|Multi-Spectrogan: High-Diversity And High-Fidelity Spectrogram Generation With Adversarial Style Combination For Speech Synthesis|aaai21||	https://arxiv.org/abs/2012.07267|
|Consecutive Decoding For Speech-To-Text Translation	|aaai21||https://www.aaai.org/AAAI21Papers/AAAI-9845.DongQ.pdf|
|||||
|Is "moby dick" a Whale or a Bird? Named Entities and Terminology in Speech Translation.|emnlp21||	https://arxiv.org/abs/2109.07439|
|Speechformer - Reducing Information Loss in Direct Speech Translation.|emnlp21||	https://arxiv.org/abs/2109.04574|
|Mutual-Learning Improves End-to-End Speech Translation.	|emnlp21||https://dblp.org/rec/conf/emnlp/ZhaoLCG21|
|||||
|Sig2Sig: Signal Translation Networks to Take the Remains of the Past	|icassp21||https://ieeexplore.ieee.org/document/9415084|
|Robust Latent Representations Via Cross-Modal Translation and Alignment|icassp21||	https://ieeexplore.ieee.org/document/9413456|
|ORTHROS: non-autoregressive end-to-end speech translation With dual-decoder|icassp21||	https://ieeexplore.ieee.org/document/9415093|
|Cascaded Models with Cyclic Feedback for Direct Speech Translation|icassp21||	https://ieeexplore.ieee.org/document/9413719|
|Jointly Trained Transformers Models for Spoken Language Translation|icassp21||	https://ieeexplore.ieee.org/document/9414159|
|Streaming Simultaneous Speech Translation with Augmented Memory Transformer|icassp21||	https://ieeexplore.ieee.org/document/9414897|
|An Empirical Study of End-To-End Simultaneous Speech Translation Decoding Strategies|icassp21||	https://ieeexplore.ieee.org/document/9414276|
|Sentence Boundary Augmentation for Neural Machine Translation Robustness|icassp21||	https://ieeexplore.ieee.org/document/9413492|
|An Empirical Study on Task-Oriented Dialogue Translation	|icassp21||https://ieeexplore.ieee.org/document/9413521|
|Machine Translation Verbosity Control for Automatic Dubbing|icassp21||	https://ieeexplore.ieee.org/document/9414411|
|||||
|End-to-End Speech Translation for Code Switched Speech|acl22||https://arxiv.org/abs/2204.05076|
|Learning When to Translate for Streaming Speech|acl22||https://arxiv.org/abs/2109.07368|
|Direct speech-to-speech translation with discrete units|acl22||https://arxiv.org/abs/2107.05604|
|Under the Morphosyntactic Lens: A Multifaceted Evaluation of Gender Bias in Speech Translation|acl22||https://arxiv.org/abs/2203.09866|
|Sample, Translate, Recombine: Leveraging Audio Alignments for Data Augmentation in End-to-end Speech Translation|acl22||https://arxiv.org/abs/2203.08757|
|STEMM: Self-learning with Speech-text Manifold Mixup for Speech Translation|acl22||https://arxiv.org/abs/2203.10426|
|||||
|Regularizing End-to-End Speech Translation with Triangular Decomposition Agreement|aaai22||https://arxiv.org/abs/2112.10991|
|||||
|Tackling data scarcity in speech translation using zero-shot multilingual machine translation techniques|icassp22||https://arxiv.org/abs/2201.11172|
|Isometric MT: Neural Machine Translation for Automatic Dubbing|icassp22||https://arxiv.org/abs/2112.08682|
|Prosody-Aware Neural Machine Translation for Dubbing|icassp22||https://arxiv.org/abs/2112.08548|
|||||

