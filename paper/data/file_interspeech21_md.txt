|Conversion of Airborne to Bone-Conducted Speech with Deep Neural Networks|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/pucher21_interspeech.html|Speech Synthesis: Other Topics|https://www.isca-speech.org/archive/interspeech_2021/pucher21_interspeech.html|
|T5G2P: Using Text-to-Text Transfer Transformer for Grapheme-to-Phoneme Conversion|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/rezackova21_interspeech.html|Speech Synthesis: Other Topics|https://www.isca-speech.org/archive/interspeech_2021/rezackova21_interspeech.html|
|Evaluating the Extrapolation Capabilities of Neural Vocoders to Extreme Pitch Values|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/perrotin21_interspeech.html|Speech Synthesis: Other Topics|https://www.isca-speech.org/archive/interspeech_2021/perrotin21_interspeech.html|
|A Systematic Review and Analysis of Multilingual Data Strategies in Text-to-Speech for Low-Resource Languages|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/do21_interspeech.html|Speech Synthesis: Other Topics|https://www.isca-speech.org/archive/interspeech_2021/do21_interspeech.html|
|Acoustic Indicators of Speech Motor Coordination in Adults With and Without Traumatic Brain Injury|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/talkar21_interspeech.html|Disordered Speech|https://www.isca-speech.org/archive/interspeech_2021/talkar21_interspeech.html|
|On Modeling Glottal Source Information for Phonation Assessment in Parkinson’s Disease|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/vasquezcorrea21_interspeech.html|Disordered Speech|https://www.isca-speech.org/archive/interspeech_2021/vasquezcorrea21_interspeech.html|
|Distortion of Voiced Obstruents for Differential Diagnosis Between Parkinson’s Disease and Multiple System Atrophy|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/daoudi21_interspeech.html|Disordered Speech|https://www.isca-speech.org/archive/interspeech_2021/daoudi21_interspeech.html|
|A Study into Pre-Training Strategies for Spoken Language Understanding on Dysarthric Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21_interspeech.html|Disordered Speech|https://www.isca-speech.org/archive/interspeech_2021/wang21_interspeech.html|
|EasyCall Corpus: A Dysarthric Speech Dataset|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/turrisi21_interspeech.html|Disordered Speech|https://www.isca-speech.org/archive/interspeech_2021/turrisi21_interspeech.html|
|A Benchmark of Dynamical Variational Autoencoders Applied to Speech Spectrogram Modeling|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/bie21_interspeech.html|Speech Signal Analysis and Representation II|https://www.isca-speech.org/archive/interspeech_2021/bie21_interspeech.html|
|Fricative Phoneme Detection Using Deep Neural Networks and its Comparison to Traditional Methods|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/yurt21_interspeech.html|Speech Signal Analysis and Representation II|https://www.isca-speech.org/archive/interspeech_2021/yurt21_interspeech.html|
|Identification of F1 and F2 in Speech Using Modified Zero Frequency Filtering|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/prasad21_interspeech.html|Speech Signal Analysis and Representation II|https://www.isca-speech.org/archive/interspeech_2021/prasad21_interspeech.html|
|Phoneme-to-Audio Alignment with Recurrent Neural Networks for Speaking and Singing Voice|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/teytaut21_interspeech.html|Speech Signal Analysis and Representation II|https://www.isca-speech.org/archive/interspeech_2021/teytaut21_interspeech.html|
|Adaptive Convolutional Neural Network for Text-Independent Speaker Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kim21_interspeech.html|Feature, Embedding and Neural Architecture for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/kim21_interspeech.html|
|Bidirectional Multiscale Feature Aggregation for Speaker Verification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/qi21_interspeech.html|Feature, Embedding and Neural Architecture for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/qi21_interspeech.html|
|Improving Time Delay Neural Network Based Speaker Recognition with Convolutional Block and Feature Aggregation Methods|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21_interspeech.html|Feature, Embedding and Neural Architecture for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/zhang21_interspeech.html|
|Improving Deep CNN Architectures with Variable-Length Training Samples for Text-Independent Speaker Verification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wu21_interspeech.html|Feature, Embedding and Neural Architecture for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/wu21_interspeech.html|
|Binary Neural Network for Speaker Verification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhu21_interspeech.html|Feature, Embedding and Neural Architecture for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/zhu21_interspeech.html|
|Mutual Information Enhanced Training for Speaker Embedding|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/tu21_interspeech.html|Feature, Embedding and Neural Architecture for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/tu21_interspeech.html|
|Y-Vector: Multiscale Waveform Encoder for Speaker Embedding|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhu21b_interspeech.html|Feature, Embedding and Neural Architecture for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/zhu21b_interspeech.html|
|Phoneme-Aware and Channel-Wise Attentive Learning for Text Dependent Speaker Verification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/liu21_interspeech.html|Feature, Embedding and Neural Architecture for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/liu21_interspeech.html|
|Serialized Multi-Layer Multi-Head Attention for Neural Speaker Embedding|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhu21c_interspeech.html|Feature, Embedding and Neural Architecture for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/zhu21c_interspeech.html|
|TacoLPCNet: Fast and Stable TTS by Conditioning LPCNet on Mel Spectrogram Predictions|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/gong21_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis II|https://www.isca-speech.org/archive/interspeech_2021/gong21_interspeech.html|
|FastPitchFormant: Source-Filter Based Decomposed Modeling for Speech Synthesis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/bak21_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis II|https://www.isca-speech.org/archive/interspeech_2021/bak21_interspeech.html|
|Sequence-to-Sequence Learning for Deep Gaussian Process Based Speech Synthesis Using Self-Attention GP Layer|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/nakamura21_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis II|https://www.isca-speech.org/archive/interspeech_2021/nakamura21_interspeech.html|
|Phonetic and Prosodic Information Estimation from Texts for Genuine Japanese End-to-End Text-to-Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kakegawa21_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis II|https://www.isca-speech.org/archive/interspeech_2021/kakegawa21_interspeech.html|
|Information Sieve: Content Leakage Reduction in End-to-End Prosody Transfer for Expressive Speech Synthesis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/dai21_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis II|https://www.isca-speech.org/archive/interspeech_2021/dai21_interspeech.html|
|Deliberation-Based Multi-Pass Speech Synthesis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/dou21_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis II|https://www.isca-speech.org/archive/interspeech_2021/dou21_interspeech.html|
|Parallel Tacotron 2: A Non-Autoregressive Neural TTS Model with Differentiable Duration Modeling|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/elias21_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis II|https://www.isca-speech.org/archive/interspeech_2021/elias21_interspeech.html|
|Transformer-Based Acoustic Modeling for Streaming Speech Synthesis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wu21b_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis II|https://www.isca-speech.org/archive/interspeech_2021/wu21b_interspeech.html|
|PnG BERT: Augmented BERT on Phonemes and Graphemes for Neural TTS|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/jia21_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis II|https://www.isca-speech.org/archive/interspeech_2021/jia21_interspeech.html|
|Speed up Training with Variable Length Inputs by Efficient Batching Strategies|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ge21_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis II|https://www.isca-speech.org/archive/interspeech_2021/ge21_interspeech.html|
|Funnel Deep Complex U-Net for Phase-Aware Speech Enhancement|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/sun21_interspeech.html|Speech Enhancement and Intelligibility|https://www.isca-speech.org/archive/interspeech_2021/sun21_interspeech.html|
|Temporal Convolutional Network with Frequency Dimension Adaptive Attention for Speech Enhancement|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21b_interspeech.html|Speech Enhancement and Intelligibility|https://www.isca-speech.org/archive/interspeech_2021/zhang21b_interspeech.html|
|Perceptual Contributions of Vowels and Consonant-Vowel Transitions in Understanding Time-Compressed Mandarin Sentences|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/pan21_interspeech.html|Speech Enhancement and Intelligibility|https://www.isca-speech.org/archive/interspeech_2021/pan21_interspeech.html|
|Transfer Learning for Speech Intelligibility Improvement in Noisy Environments|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/biswas21_interspeech.html|Speech Enhancement and Intelligibility|https://www.isca-speech.org/archive/interspeech_2021/biswas21_interspeech.html|
|Comparison of Remote Experiments Using Crowdsourcing and Laboratory Experiments on Speech Intelligibility|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/yamamoto21_interspeech.html|Speech Enhancement and Intelligibility|https://www.isca-speech.org/archive/interspeech_2021/yamamoto21_interspeech.html|
|Know Your Enemy, Know Yourself: A Unified Two-Stage Framework for Speech Enhancement|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/liu21b_interspeech.html|Speech Enhancement and Intelligibility|https://www.isca-speech.org/archive/interspeech_2021/liu21b_interspeech.html|
|Speech Enhancement with Weakly Labelled Data from AudioSet|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kong21_interspeech.html|Speech Enhancement and Intelligibility|https://www.isca-speech.org/archive/interspeech_2021/kong21_interspeech.html|
|Improving Perceptual Quality by Phone-Fortified Perceptual Loss Using Wasserstein Distance for Speech Enhancement|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/hsieh21_interspeech.html|Speech Enhancement and Intelligibility|https://www.isca-speech.org/archive/interspeech_2021/hsieh21_interspeech.html|
|MetricGAN+: An Improved Version of MetricGAN for Speech Enhancement|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/fu21_interspeech.html|Speech Enhancement and Intelligibility|https://www.isca-speech.org/archive/interspeech_2021/fu21_interspeech.html|
|A Spectro-Temporal Glimpsing Index (STGI) for Speech Intelligibility Prediction|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/edraki21_interspeech.html|Speech Enhancement and Intelligibility|https://www.isca-speech.org/archive/interspeech_2021/edraki21_interspeech.html|
|Self-Supervised Learning Based Phone-Fortified Speech Enhancement|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/qiu21_interspeech.html|Speech Enhancement and Intelligibility|https://www.isca-speech.org/archive/interspeech_2021/qiu21_interspeech.html|
|Incorporating Embedding Vectors from a Human Mean-Opinion Score Prediction Model for Monaural Speech Enhancement|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/nayem21_interspeech.html|Speech Enhancement and Intelligibility|https://www.isca-speech.org/archive/interspeech_2021/nayem21_interspeech.html|
|Restoring Degraded Speech via a Modified Diffusion Model|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21c_interspeech.html|Speech Enhancement and Intelligibility|https://www.isca-speech.org/archive/interspeech_2021/zhang21c_interspeech.html|
|User-Initiated Repetition-Based Recovery in Multi-Utterance Dialogue Systems|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/nguyen21_interspeech.html|Spoken Dialogue Systems I|https://www.isca-speech.org/archive/interspeech_2021/nguyen21_interspeech.html|
|Self-Supervised Dialogue Learning for Spoken Conversational Question Answering|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chen21_interspeech.html|Spoken Dialogue Systems I|https://www.isca-speech.org/archive/interspeech_2021/chen21_interspeech.html|
|Act-Aware Slot-Value Predicting in Multi-Domain Dialogue State Tracking|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/su21_interspeech.html|Spoken Dialogue Systems I|https://www.isca-speech.org/archive/interspeech_2021/su21_interspeech.html|
|Dialogue Situation Recognition for Everyday Conversation Using Multimodal Information|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chiba21_interspeech.html|Spoken Dialogue Systems I|https://www.isca-speech.org/archive/interspeech_2021/chiba21_interspeech.html|
|Neural Spoken-Response Generation Using Prosodic and Linguistic Context for Conversational Systems|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/yamazaki21_interspeech.html|Spoken Dialogue Systems I|https://www.isca-speech.org/archive/interspeech_2021/yamazaki21_interspeech.html|
|Semantic Transportation Prototypical Network for Few-Shot Intent Detection|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/xu21_interspeech.html|Spoken Dialogue Systems I|https://www.isca-speech.org/archive/interspeech_2021/xu21_interspeech.html|
|Domain-Specific Multi-Agent Dialog Policy Learning in Multi-Domain Task-Oriented Scenarios|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/tang21_interspeech.html|Spoken Dialogue Systems I|https://www.isca-speech.org/archive/interspeech_2021/tang21_interspeech.html|
|Leveraging ASR N-Best in Deep Entity Retrieval|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21b_interspeech.html|Spoken Dialogue Systems I|https://www.isca-speech.org/archive/interspeech_2021/wang21b_interspeech.html|
|End-to-End Spelling Correction Conditioned on Acoustic Feature for Code-Switching Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21d_interspeech.html|Topics in ASR: Robustness, Feature Extraction, and Far-Field ASR|https://www.isca-speech.org/archive/interspeech_2021/zhang21d_interspeech.html|
|Phoneme Recognition Through Fine Tuning of Phonetic Representations: A Case Study on Luhya Language Varieties|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/siminyu21_interspeech.html|Topics in ASR: Robustness, Feature Extraction, and Far-Field ASR|https://www.isca-speech.org/archive/interspeech_2021/siminyu21_interspeech.html|
|Speech Acoustic Modelling Using Raw Source and Filter Components|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/loweimi21_interspeech.html|Topics in ASR: Robustness, Feature Extraction, and Far-Field ASR|https://www.isca-speech.org/archive/interspeech_2021/loweimi21_interspeech.html|
|Noise Robust Acoustic Modeling for Single-Channel Speech Recognition Based on a Stream-Wise Transformer Architecture|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/fujimoto21_interspeech.html|Topics in ASR: Robustness, Feature Extraction, and Far-Field ASR|https://www.isca-speech.org/archive/interspeech_2021/fujimoto21_interspeech.html|
|IR-GAN: Room Impulse Response Generator for Far-Field Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ratnarajah21_interspeech.html|Topics in ASR: Robustness, Feature Extraction, and Far-Field ASR|https://www.isca-speech.org/archive/interspeech_2021/ratnarajah21_interspeech.html|
|Scaling Sparsemax Based Channel Selection for Speech Recognition with ad-hoc Microphone Arrays|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chen21b_interspeech.html|Topics in ASR: Robustness, Feature Extraction, and Far-Field ASR|https://www.isca-speech.org/archive/interspeech_2021/chen21b_interspeech.html|
|Multi-Channel Transformer Transducer for Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chang21_interspeech.html|Topics in ASR: Robustness, Feature Extraction, and Far-Field ASR|https://www.isca-speech.org/archive/interspeech_2021/chang21_interspeech.html|
|Data Augmentation Methods for End-to-End Speech Recognition on Distant-Talk Scenarios|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/tsunoo21_interspeech.html|Topics in ASR: Robustness, Feature Extraction, and Far-Field ASR|https://www.isca-speech.org/archive/interspeech_2021/tsunoo21_interspeech.html|
|Leveraging Phone Mask Training for Phonetic-Reduction-Robust E2E Uyghur Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ma21_interspeech.html|Topics in ASR: Robustness, Feature Extraction, and Far-Field ASR|https://www.isca-speech.org/archive/interspeech_2021/ma21_interspeech.html|
|Rethinking Evaluation in ASR: Are Our Models Robust Enough?|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/likhomanenko21_interspeech.html|Topics in ASR: Robustness, Feature Extraction, and Far-Field ASR|https://www.isca-speech.org/archive/interspeech_2021/likhomanenko21_interspeech.html|
|Raw Waveform Encoder with Multi-Scale Globally Attentive Locally Recurrent Networks for End-to-End Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lam21_interspeech.html|Topics in ASR: Robustness, Feature Extraction, and Far-Field ASR|https://www.isca-speech.org/archive/interspeech_2021/lam21_interspeech.html|
|Attention-Based Cross-Modal Fusion for Audio-Visual Voice Activity Detection in Musical Video Streams|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/hou21_interspeech.html|Voice Activity Detection and Keyword Spotting|https://www.isca-speech.org/archive/interspeech_2021/hou21_interspeech.html|
|Noise-Tolerant Self-Supervised Learning for Audio-Visual Voice Activity Detection|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kim21b_interspeech.html|Voice Activity Detection and Keyword Spotting|https://www.isca-speech.org/archive/interspeech_2021/kim21b_interspeech.html|
|Noisy Student-Teacher Training for Robust Keyword Spotting|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/park21_interspeech.html|Voice Activity Detection and Keyword Spotting|https://www.isca-speech.org/archive/interspeech_2021/park21_interspeech.html|
|Multi-Channel VAD for Transcription of Group Discussion|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ichikawa21_interspeech.html|Voice Activity Detection and Keyword Spotting|https://www.isca-speech.org/archive/interspeech_2021/ichikawa21_interspeech.html|
|Audio-Visual Information Fusion Using Cross-Modal Teacher-Student Learning for Voice Activity Detection in Realistic Environments|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhou21_interspeech.html|Voice Activity Detection and Keyword Spotting|https://www.isca-speech.org/archive/interspeech_2021/zhou21_interspeech.html|
|Enrollment-Less Training for Personalized Voice Activity Detection|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/makishima21_interspeech.html|Voice Activity Detection and Keyword Spotting|https://www.isca-speech.org/archive/interspeech_2021/makishima21_interspeech.html|
|Voice Activity Detection for Live Speech of Baseball Game Based on Tandem Connection with Speech/Noise Separation Model|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/nonaka21_interspeech.html|Voice Activity Detection and Keyword Spotting|https://www.isca-speech.org/archive/interspeech_2021/nonaka21_interspeech.html|
|FastICARL: Fast Incremental Classifier and Representation Learning with Efficient Budget Allocation in Audio Sensing Applications|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kwon21_interspeech.html|Voice Activity Detection and Keyword Spotting|https://www.isca-speech.org/archive/interspeech_2021/kwon21_interspeech.html|
|End-to-End Transformer-Based Open-Vocabulary Keyword Spotting with Location-Guided Local Attention|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wei21_interspeech.html|Voice Activity Detection and Keyword Spotting|https://www.isca-speech.org/archive/interspeech_2021/wei21_interspeech.html|
|Segmental Contrastive Predictive Coding for Unsupervised Word Segmentation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/bhati21_interspeech.html|Voice Activity Detection and Keyword Spotting|https://www.isca-speech.org/archive/interspeech_2021/bhati21_interspeech.html|
|A Lightweight Framework for Online Voice Activity Detection in the Wild|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/xu21b_interspeech.html|Voice Activity Detection and Keyword Spotting|https://www.isca-speech.org/archive/interspeech_2021/xu21b_interspeech.html|
|“See what I mean, huh?” Evaluating Visual Inspection of F0 Tracking in Nasal Grunts|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chlebowski21_interspeech.html|Voice and Voicing|https://www.isca-speech.org/archive/interspeech_2021/chlebowski21_interspeech.html|
|System Performance as a Function of Calibration Methods, Sample Size and Sampling Variability in Likelihood Ratio-Based Forensic Voice Comparison|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21c_interspeech.html|Voice and Voicing|https://www.isca-speech.org/archive/interspeech_2021/wang21c_interspeech.html|
|Voicing Assimilations by French Speakers of German in Stop-Fricative Sequences|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/bonneau21_interspeech.html|Voice and Voicing|https://www.isca-speech.org/archive/interspeech_2021/bonneau21_interspeech.html|
|The Four-Way Classification of Stops with Voicing and Aspiration for Non-Native Speech Evaluation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chakraborty21_interspeech.html|Voice and Voicing|https://www.isca-speech.org/archive/interspeech_2021/chakraborty21_interspeech.html|
|Acoustic and Prosodic Correlates of Emotions in Urdu Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/urooj21_interspeech.html|Voice and Voicing|https://www.isca-speech.org/archive/interspeech_2021/urooj21_interspeech.html|
|Voicing Contrasts in the Singleton Stops of Palestinian Arabic: Production and Perception|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/tamim21_interspeech.html|Voice and Voicing|https://www.isca-speech.org/archive/interspeech_2021/tamim21_interspeech.html|
|A Comparison of the Accuracy of Dissen and Keshet’s (2016) DeepFormants and Traditional LPC Methods for Semi-Automatic Speaker Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/coy21_interspeech.html|Voice and Voicing|https://www.isca-speech.org/archive/interspeech_2021/coy21_interspeech.html|
|MAP Adaptation Characteristics in Forensic Long-Term Formant Analysis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/jessen21_interspeech.html|Voice and Voicing|https://www.isca-speech.org/archive/interspeech_2021/jessen21_interspeech.html|
|Cross-Linguistic Speaker Individuality of Long-Term Formant Distributions: Phonetic and Forensic Perspectives|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lo21_interspeech.html|Voice and Voicing|https://www.isca-speech.org/archive/interspeech_2021/lo21_interspeech.html|
|Sound Change in Spontaneous Bilingual Speech: A Corpus Study on the Cantonese n-l Merger in Cantonese-English Bilinguals|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/soo21_interspeech.html|Voice and Voicing|https://www.isca-speech.org/archive/interspeech_2021/soo21_interspeech.html|
|Characterizing Voiced and Voiceless Nasals in Mizo|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lalhminghlui21_interspeech.html|Voice and Voicing|https://www.isca-speech.org/archive/interspeech_2021/lalhminghlui21_interspeech.html|
|The INTERSPEECH 2021 Computational Paralinguistics Challenge: COVID-19 Cough, COVID-19 Speech, Escalation & Primates|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/schuller21_interspeech.html|The INTERSPEECH 2021 Computational Paralinguistics Challenge (ComParE) — COVID-19 Cough, COVID-19 Speech, Escalation & Primates|https://www.isca-speech.org/archive/interspeech_2021/schuller21_interspeech.html|
|Transfer Learning-Based Cough Representations for Automatic Detection of COVID-19|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/soleraurena21_interspeech.html|The INTERSPEECH 2021 Computational Paralinguistics Challenge (ComParE) — COVID-19 Cough, COVID-19 Speech, Escalation & Primates|https://www.isca-speech.org/archive/interspeech_2021/soleraurena21_interspeech.html|
|The Phonetic Footprint of Covid-19?|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/klumpp21_interspeech.html|The INTERSPEECH 2021 Computational Paralinguistics Challenge (ComParE) — COVID-19 Cough, COVID-19 Speech, Escalation & Primates|https://www.isca-speech.org/archive/interspeech_2021/klumpp21_interspeech.html|
|Transfer Learning and Data Augmentation Techniques to the COVID-19 Identification Tasks in ComParE 2021|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/casanova21_interspeech.html|The INTERSPEECH 2021 Computational Paralinguistics Challenge (ComParE) — COVID-19 Cough, COVID-19 Speech, Escalation & Primates|https://www.isca-speech.org/archive/interspeech_2021/casanova21_interspeech.html|
|Visual Transformers for Primates Classification and Covid Detection|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/illium21_interspeech.html|The INTERSPEECH 2021 Computational Paralinguistics Challenge (ComParE) — COVID-19 Cough, COVID-19 Speech, Escalation & Primates|https://www.isca-speech.org/archive/interspeech_2021/illium21_interspeech.html|
|Deep-Learning-Based Central African Primate Species Classification with MixUp and SpecAugment|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/pellegrini21_interspeech.html|The INTERSPEECH 2021 Computational Paralinguistics Challenge (ComParE) — COVID-19 Cough, COVID-19 Speech, Escalation & Primates|https://www.isca-speech.org/archive/interspeech_2021/pellegrini21_interspeech.html|
|A Deep and Recurrent Architecture for Primate Vocalization Classification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/muller21_interspeech.html|The INTERSPEECH 2021 Computational Paralinguistics Challenge (ComParE) — COVID-19 Cough, COVID-19 Speech, Escalation & Primates|https://www.isca-speech.org/archive/interspeech_2021/muller21_interspeech.html|
|Introducing a Central African Primate Vocalisation Dataset for Automated Species Classification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zwerts21_interspeech.html|The INTERSPEECH 2021 Computational Paralinguistics Challenge (ComParE) — COVID-19 Cough, COVID-19 Speech, Escalation & Primates|https://www.isca-speech.org/archive/interspeech_2021/zwerts21_interspeech.html|
|Multi-Attentive Detection of the Spider Monkey Whinny in the (Actual) Wild|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/rizos21_interspeech.html|The INTERSPEECH 2021 Computational Paralinguistics Challenge (ComParE) — COVID-19 Cough, COVID-19 Speech, Escalation & Primates|https://www.isca-speech.org/archive/interspeech_2021/rizos21_interspeech.html|
|Identifying Conflict Escalation and Primates by Using Ensemble X-Vectors and Fisher Vector Features|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/egaslopez21_interspeech.html|The INTERSPEECH 2021 Computational Paralinguistics Challenge (ComParE) — COVID-19 Cough, COVID-19 Speech, Escalation & Primates|https://www.isca-speech.org/archive/interspeech_2021/egaslopez21_interspeech.html|
|Ensemble-Within-Ensemble Classification for Escalation Prediction from Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/verkholyak21_interspeech.html|The INTERSPEECH 2021 Computational Paralinguistics Challenge (ComParE) — COVID-19 Cough, COVID-19 Speech, Escalation & Primates|https://www.isca-speech.org/archive/interspeech_2021/verkholyak21_interspeech.html|
|Analysis by Synthesis: Using an Expressive TTS Model as Feature Extractor for Paralinguistic Speech Classification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/schiller21_interspeech.html|The INTERSPEECH 2021 Computational Paralinguistics Challenge (ComParE) — COVID-19 Cough, COVID-19 Speech, Escalation & Primates|https://www.isca-speech.org/archive/interspeech_2021/schiller21_interspeech.html|
|Towards Automatic Speech Recognition for People with Atypical Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/christensen21_interspeech.html|Survey Talk 1: Heidi Christensen|https://www.isca-speech.org/archive/interspeech_2021/christensen21_interspeech.html|
|Leveraging Speaker Attribute Information Using Multi Task Learning for Speaker Verification and Diarization|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/luu21_interspeech.html|Embedding and Network Architecture for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/luu21_interspeech.html|
|Spine2Net: SpineNet with Res2Net and Time-Squeeze-and-Excitation Blocks for Speaker Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/rybicka21_interspeech.html|Embedding and Network Architecture for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/rybicka21_interspeech.html|
|Speaker Embeddings by Modeling Channel-Wise Correlations|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/stafylakis21_interspeech.html|Embedding and Network Architecture for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/stafylakis21_interspeech.html|
|Multi-Task Neural Network for Robust Multiple Speaker Embedding Extraction|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/he21_interspeech.html|Embedding and Network Architecture for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/he21_interspeech.html|
|ICSpk: Interpretable Complex Speaker Embedding Extractor from Raw Waveform|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/peng21_interspeech.html|Embedding and Network Architecture for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/peng21_interspeech.html|
|Prosodic Disambiguation Using Chironomic Stylization of Intonation with Native and Non-Native Speakers|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/xiao21_interspeech.html|Speech Perception I|https://www.isca-speech.org/archive/interspeech_2021/xiao21_interspeech.html|
|Variation in Perceptual Sensitivity and Compensation for Coarticulation Across Adult and Child Naturally-Produced and TTS Voices|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/block21_interspeech.html|Speech Perception I|https://www.isca-speech.org/archive/interspeech_2021/block21_interspeech.html|
|Extracting Different Levels of Speech Information from EEG Using an LSTM-Based Model|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/monesi21_interspeech.html|Speech Perception I|https://www.isca-speech.org/archive/interspeech_2021/monesi21_interspeech.html|
|Word Competition: An Entropy-Based Approach in the DIANA Model of Human Word Comprehension|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/bosch21_interspeech.html|Speech Perception I|https://www.isca-speech.org/archive/interspeech_2021/bosch21_interspeech.html|
|Time-to-Event Models for Analyzing Reaction Time Sequences|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/bosch21b_interspeech.html|Speech Perception I|https://www.isca-speech.org/archive/interspeech_2021/bosch21b_interspeech.html|
|Models of Reaction Times in Auditory Lexical Decision: RTonset versus RToffset|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/brand21_interspeech.html|Speech Perception I|https://www.isca-speech.org/archive/interspeech_2021/brand21_interspeech.html|
|SpecMix : A Mixed Sample Data Augmentation Method for Training with Time-Frequency Domain Features|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kim21c_interspeech.html|Acoustic Event Detection and Acoustic Scene Classification|https://www.isca-speech.org/archive/interspeech_2021/kim21c_interspeech.html|
|SpecAugment++: A Hidden Space Data Augmentation Method for Acoustic Scene Classification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21d_interspeech.html|Acoustic Event Detection and Acoustic Scene Classification|https://www.isca-speech.org/archive/interspeech_2021/wang21d_interspeech.html|
|An Effective Mutual Mean Teaching Based Domain Adaptation Method for Sound Event Detection|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zheng21_interspeech.html|Acoustic Event Detection and Acoustic Scene Classification|https://www.isca-speech.org/archive/interspeech_2021/zheng21_interspeech.html|
|Acoustic Scene Classification Using Kervolution-Based SubSpectralNet|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/nandi21_interspeech.html|Acoustic Event Detection and Acoustic Scene Classification|https://www.isca-speech.org/archive/interspeech_2021/nandi21_interspeech.html|
|Event Specific Attention for Polyphonic Sound Event Detection|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/sundar21_interspeech.html|Acoustic Event Detection and Acoustic Scene Classification|https://www.isca-speech.org/archive/interspeech_2021/sundar21_interspeech.html|
|AST: Audio Spectrogram Transformer|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/gong21b_interspeech.html|Acoustic Event Detection and Acoustic Scene Classification|https://www.isca-speech.org/archive/interspeech_2021/gong21b_interspeech.html|
|Shallow Convolution-Augmented Transformer with Differentiable Neural Computer for Low-Complexity Classification of Variable-Length Acoustic Scene|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/seo21_interspeech.html|Acoustic Event Detection and Acoustic Scene Classification|https://www.isca-speech.org/archive/interspeech_2021/seo21_interspeech.html|
|An Evaluation of Data Augmentation Methods for Sound Scene Geotagging|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/bear21_interspeech.html|Acoustic Event Detection and Acoustic Scene Classification|https://www.isca-speech.org/archive/interspeech_2021/bear21_interspeech.html|
|Optimizing Latency for Online Video Captioning Using Audio-Visual Transformers|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/hori21_interspeech.html|Acoustic Event Detection and Acoustic Scene Classification|https://www.isca-speech.org/archive/interspeech_2021/hori21_interspeech.html|
|Variational Information Bottleneck for Effective Low-Resource Audio Classification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/si21_interspeech.html|Acoustic Event Detection and Acoustic Scene Classification|https://www.isca-speech.org/archive/interspeech_2021/si21_interspeech.html|
|Improving Weakly Supervised Sound Event Detection with Self-Supervised Auxiliary Tasks|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/deshmukh21_interspeech.html|Acoustic Event Detection and Acoustic Scene Classification|https://www.isca-speech.org/archive/interspeech_2021/deshmukh21_interspeech.html|
|Acoustic Event Detection with Classifier Chains|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/komatsu21_interspeech.html|Acoustic Event Detection and Acoustic Scene Classification|https://www.isca-speech.org/archive/interspeech_2021/komatsu21_interspeech.html|
|Segment and Tone Production in Continuous Speech of Hearing and Hearing-Impaired Children|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/tseng21_interspeech.html|Diverse Modes of Speech Acquisition and Processing|https://www.isca-speech.org/archive/interspeech_2021/tseng21_interspeech.html|
|Effect of Carrier Bandwidth on Understanding Mandarin Sentences in Simulated Electric-Acoustic Hearing|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21e_interspeech.html|Diverse Modes of Speech Acquisition and Processing|https://www.isca-speech.org/archive/interspeech_2021/wang21e_interspeech.html|
|A Comparative Study of Different EMG Features for Acoustics-to-EMG Mapping|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/sharma21_interspeech.html|Diverse Modes of Speech Acquisition and Processing|https://www.isca-speech.org/archive/interspeech_2021/sharma21_interspeech.html|
|Image-Based Assessment of Jaw Parameters and Jaw Kinematics for Articulatory Simulation: Preliminary Results|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/abraham21_interspeech.html|Diverse Modes of Speech Acquisition and Processing|https://www.isca-speech.org/archive/interspeech_2021/abraham21_interspeech.html|
|An Attention Self-Supervised Contrastive Learning Based Three-Stage Model for Hand Shape Feature Representation in Cued Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21f_interspeech.html|Diverse Modes of Speech Acquisition and Processing|https://www.isca-speech.org/archive/interspeech_2021/wang21f_interspeech.html|
|Remote Smartphone-Based Speech Collection: Acceptance and Barriers in Individuals with Major Depressive Disorder|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/dineley21_interspeech.html|Diverse Modes of Speech Acquisition and Processing|https://www.isca-speech.org/archive/interspeech_2021/dineley21_interspeech.html|
|An Automatic, Simple Ultrasound Biofeedback Parameter for Distinguishing Accurate and Misarticulated Rhotic Syllables|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/li21_interspeech.html|Diverse Modes of Speech Acquisition and Processing|https://www.isca-speech.org/archive/interspeech_2021/li21_interspeech.html|
|Silent versus Modal Multi-Speaker Speech Recognition from Ultrasound and Video|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ribeiro21_interspeech.html|Diverse Modes of Speech Acquisition and Processing|https://www.isca-speech.org/archive/interspeech_2021/ribeiro21_interspeech.html|
|RaSSpeR: Radar-Based Silent Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ferreira21_interspeech.html|Diverse Modes of Speech Acquisition and Processing|https://www.isca-speech.org/archive/interspeech_2021/ferreira21_interspeech.html|
|Investigating Speech Reconstruction for Laryngectomees for Silent Speech Interfaces|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/cao21_interspeech.html|Diverse Modes of Speech Acquisition and Processing|https://www.isca-speech.org/archive/interspeech_2021/cao21_interspeech.html|
|LACOPE: Latency-Constrained Pitch Estimation for Speech Enhancement|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/schroter21_interspeech.html|Multi-Channel Speech Enhancement and Hearing Aids|https://www.isca-speech.org/archive/interspeech_2021/schroter21_interspeech.html|
|Alpha-Stable Autoregressive Fast Multichannel Nonnegative Matrix Factorization for Joint Speech Enhancement and Dereverberation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/fontaine21_interspeech.html|Multi-Channel Speech Enhancement and Hearing Aids|https://www.isca-speech.org/archive/interspeech_2021/fontaine21_interspeech.html|
|Microphone Array Generalization for Multichannel Narrowband Deep Speech Enhancement|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21e_interspeech.html|Multi-Channel Speech Enhancement and Hearing Aids|https://www.isca-speech.org/archive/interspeech_2021/zhang21e_interspeech.html|
|Multiple Sound Source Localization Based on Interchannel Phase Differences in All Frequencies with Spectral Masks|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/song21_interspeech.html|Multi-Channel Speech Enhancement and Hearing Aids|https://www.isca-speech.org/archive/interspeech_2021/song21_interspeech.html|
|Cancellation of Local Competing Speaker with Near-Field Localization for Distributed ad-hoc Sensor Network|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zarazaga21_interspeech.html|Multi-Channel Speech Enhancement and Hearing Aids|https://www.isca-speech.org/archive/interspeech_2021/zarazaga21_interspeech.html|
|A Deep Learning Method to Multi-Channel Active Noise Control|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21f_interspeech.html|Multi-Channel Speech Enhancement and Hearing Aids|https://www.isca-speech.org/archive/interspeech_2021/zhang21f_interspeech.html|
|Clarity-2021 Challenges: Machine Learning Challenges for Advancing Hearing Aid Processing|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/graetzer21_interspeech.html|Multi-Channel Speech Enhancement and Hearing Aids|https://www.isca-speech.org/archive/interspeech_2021/graetzer21_interspeech.html|
|Optimising Hearing Aid Fittings for Speech in Noise with a Differentiable Hearing Loss Model|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/tu21b_interspeech.html|Multi-Channel Speech Enhancement and Hearing Aids|https://www.isca-speech.org/archive/interspeech_2021/tu21b_interspeech.html|
|Explaining Deep Learning Models for Speech Enhancement|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/sivasankaran21_interspeech.html|Multi-Channel Speech Enhancement and Hearing Aids|https://www.isca-speech.org/archive/interspeech_2021/sivasankaran21_interspeech.html|
|Minimum-Norm Differential Beamforming for Linear Array with Directional Microphones|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/huang21_interspeech.html|Multi-Channel Speech Enhancement and Hearing Aids|https://www.isca-speech.org/archive/interspeech_2021/huang21_interspeech.html|
|Improving Streaming Transformer Based ASR Under a Framework of Self-Supervised Learning|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/cao21b_interspeech.html|Self-Supervision and Semi-Supervision for Neural ASR Training|https://www.isca-speech.org/archive/interspeech_2021/cao21b_interspeech.html|
|wav2vec-C: A Self-Supervised Model for Speech Representation Learning|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/sadhu21_interspeech.html|Self-Supervision and Semi-Supervision for Neural ASR Training|https://www.isca-speech.org/archive/interspeech_2021/sadhu21_interspeech.html|
|On the Learning Dynamics of Semi-Supervised Training for ASR|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wallington21_interspeech.html|Self-Supervision and Semi-Supervision for Neural ASR Training|https://www.isca-speech.org/archive/interspeech_2021/wallington21_interspeech.html|
|Robust wav2vec 2.0: Analyzing Domain Shift in Self-Supervised Pre-Training|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/hsu21_interspeech.html|Self-Supervision and Semi-Supervision for Neural ASR Training|https://www.isca-speech.org/archive/interspeech_2021/hsu21_interspeech.html|
|Momentum Pseudo-Labeling for Semi-Supervised Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/higuchi21_interspeech.html|Self-Supervision and Semi-Supervision for Neural ASR Training|https://www.isca-speech.org/archive/interspeech_2021/higuchi21_interspeech.html|
|A Comparison of Supervised and Unsupervised Pre-Training of End-to-End Models|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/misra21_interspeech.html|Self-Supervision and Semi-Supervision for Neural ASR Training|https://www.isca-speech.org/archive/interspeech_2021/misra21_interspeech.html|
|Semi-Supervision in ASR: Sequential MixMatch and Factorized TTS-Based Augmentation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chen21c_interspeech.html|Self-Supervision and Semi-Supervision for Neural ASR Training|https://www.isca-speech.org/archive/interspeech_2021/chen21c_interspeech.html|
|slimIPL: Language-Model-Free Iterative Pseudo-Labeling|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/likhomanenko21b_interspeech.html|Self-Supervision and Semi-Supervision for Neural ASR Training|https://www.isca-speech.org/archive/interspeech_2021/likhomanenko21b_interspeech.html|
|Phonetically Motivated Self-Supervised Speech Representation Learning|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/yue21_interspeech.html|Self-Supervision and Semi-Supervision for Neural ASR Training|https://www.isca-speech.org/archive/interspeech_2021/yue21_interspeech.html|
|Improving RNN-T for Domain Scaling Using Semi-Supervised Training with Neural TTS|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/deng21_interspeech.html|Self-Supervision and Semi-Supervision for Neural ASR Training|https://www.isca-speech.org/archive/interspeech_2021/deng21_interspeech.html|
|Speaker-Conversation Factorial Designs for Diarization Error Analysis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/seyfarth21_interspeech.html|Spoken Language Processing I|https://www.isca-speech.org/archive/interspeech_2021/seyfarth21_interspeech.html|
|SmallER: Scaling Neural Entity Resolution for Edge Devices|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/mcgowan21_interspeech.html|Spoken Language Processing I|https://www.isca-speech.org/archive/interspeech_2021/mcgowan21_interspeech.html|
|Disfluency Detection with Unlabeled Data and Small BERT Models|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/rocholl21_interspeech.html|Spoken Language Processing I|https://www.isca-speech.org/archive/interspeech_2021/rocholl21_interspeech.html|
|Discriminative Self-Training for Punctuation Prediction|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chen21d_interspeech.html|Spoken Language Processing I|https://www.isca-speech.org/archive/interspeech_2021/chen21d_interspeech.html|
|Zero-Shot Joint Modeling of Multiple Spoken-Text-Style Conversion Tasks Using Switching Tokens|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ihori21_interspeech.html|Spoken Language Processing I|https://www.isca-speech.org/archive/interspeech_2021/ihori21_interspeech.html|
|A Noise Robust Method for Word-Level Pronunciation Assessment|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lin21_interspeech.html|Spoken Language Processing I|https://www.isca-speech.org/archive/interspeech_2021/lin21_interspeech.html|
|Targeted Keyword Filtering for Accelerated Spoken Topic Identification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wintrode21_interspeech.html|Spoken Language Processing I|https://www.isca-speech.org/archive/interspeech_2021/wintrode21_interspeech.html|
|Multimodal Speech Summarization Through Semantic Concept Learning|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/palaskar21_interspeech.html|Spoken Language Processing I|https://www.isca-speech.org/archive/interspeech_2021/palaskar21_interspeech.html|
|Enhancing Semantic Understanding with Self-Supervised Methods for Abstractive Dialogue Summarization|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lee21_interspeech.html|Spoken Language Processing I|https://www.isca-speech.org/archive/interspeech_2021/lee21_interspeech.html|
|Speaker Transition Patterns in Three-Party Conversation: Evidence from English, Estonian and Swedish|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wodarczak21_interspeech.html|Spoken Language Processing I|https://www.isca-speech.org/archive/interspeech_2021/wodarczak21_interspeech.html|
|Investigating Deep Neural Structures and their Interpretability in the Domain of Voice Conversion|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/broughton21_interspeech.html|Voice Conversion and Adaptation II|https://www.isca-speech.org/archive/interspeech_2021/broughton21_interspeech.html|
|Limited Data Emotional Voice Conversion Leveraging Text-to-Speech: Two-Stage Sequence-to-Sequence Training|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhou21b_interspeech.html|Voice Conversion and Adaptation II|https://www.isca-speech.org/archive/interspeech_2021/zhou21b_interspeech.html|
|Adversarial Voice Conversion Against Neural Spoofing Detectors|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ding21_interspeech.html|Voice Conversion and Adaptation II|https://www.isca-speech.org/archive/interspeech_2021/ding21_interspeech.html|
|An Improved StarGAN for Emotional Voice Conversion: Enhancing Voice Quality and Data Augmentation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/he21b_interspeech.html|Voice Conversion and Adaptation II|https://www.isca-speech.org/archive/interspeech_2021/he21b_interspeech.html|
|TVQVC: Transformer Based Vector Quantized Variational Autoencoder with CTC Loss for Voice Conversion|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chen21e_interspeech.html|Voice Conversion and Adaptation II|https://www.isca-speech.org/archive/interspeech_2021/chen21e_interspeech.html|
|Enriching Source Style Transfer in Recognition-Synthesis Based Non-Parallel Voice Conversion|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21g_interspeech.html|Voice Conversion and Adaptation II|https://www.isca-speech.org/archive/interspeech_2021/wang21g_interspeech.html|
|S2VC: A Framework for Any-to-Any Voice Conversion with Self-Supervised Pretrained Representations|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lin21b_interspeech.html|Voice Conversion and Adaptation II|https://www.isca-speech.org/archive/interspeech_2021/lin21b_interspeech.html|
|An Exemplar Selection Algorithm for Native-Nonnative Voice Conversion|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/liberatore21_interspeech.html|Voice Conversion and Adaptation II|https://www.isca-speech.org/archive/interspeech_2021/liberatore21_interspeech.html|
|Adversarially Learning Disentangled Speech Representations for Robust Multi-Factor Voice Conversion|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21h_interspeech.html|Voice Conversion and Adaptation II|https://www.isca-speech.org/archive/interspeech_2021/wang21h_interspeech.html|
|Many-to-Many Voice Conversion Based Feature Disentanglement Using Variational Autoencoder|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/luong21_interspeech.html|Voice Conversion and Adaptation II|https://www.isca-speech.org/archive/interspeech_2021/luong21_interspeech.html|
|Privacy-Preserving Voice Anti-Spoofing Using Secure Multi-Party Computation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chouchane21_interspeech.html|Privacy-Preserving Machine Learning for Audio & Speech Processing|https://www.isca-speech.org/archive/interspeech_2021/chouchane21_interspeech.html|
|Configurable Privacy-Preserving Automatic Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/aloufi21_interspeech.html|Privacy-Preserving Machine Learning for Audio & Speech Processing|https://www.isca-speech.org/archive/interspeech_2021/aloufi21_interspeech.html|
|Adjunct-Emeritus Distillation for Semi-Supervised Language Model Adaptation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/novotney21_interspeech.html|Privacy-Preserving Machine Learning for Audio & Speech Processing|https://www.isca-speech.org/archive/interspeech_2021/novotney21_interspeech.html|
|Communication-Efficient Agnostic Federated Averaging|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ro21_interspeech.html|Privacy-Preserving Machine Learning for Audio & Speech Processing|https://www.isca-speech.org/archive/interspeech_2021/ro21_interspeech.html|
|Privacy-Preserving Feature Extraction for Cloud-Based Wake Word Verification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/koppelmann21_interspeech.html|Privacy-Preserving Machine Learning for Audio & Speech Processing|https://www.isca-speech.org/archive/interspeech_2021/koppelmann21_interspeech.html|
|PATE-AAE: Incorporating Adversarial Autoencoder into Private Aggregation of Teacher Ensembles for Spoken Command Classification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/yang21_interspeech.html|Privacy-Preserving Machine Learning for Audio & Speech Processing|https://www.isca-speech.org/archive/interspeech_2021/yang21_interspeech.html|
|Continual Learning for Fake Audio Detection|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ma21b_interspeech.html|Privacy-Preserving Machine Learning for Audio & Speech Processing|https://www.isca-speech.org/archive/interspeech_2021/ma21b_interspeech.html|
|Evaluating the Vulnerability of End-to-End Automatic Speech Recognition Models to Membership Inference Attacks|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/shah21_interspeech.html|Privacy-Preserving Machine Learning for Audio & Speech Processing|https://www.isca-speech.org/archive/interspeech_2021/shah21_interspeech.html|
|SynthASR: Unlocking Synthetic Data for Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/fazel21_interspeech.html|Privacy-Preserving Machine Learning for Audio & Speech Processing|https://www.isca-speech.org/archive/interspeech_2021/fazel21_interspeech.html|
|DiCOVA Challenge: Dataset, Task, and Baseline System for COVID-19 Diagnosis Using Acoustics|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/muguli21_interspeech.html|The First DiCOVA Challenge: Diagnosis of COVID-19 Using Acoustics|https://www.isca-speech.org/archive/interspeech_2021/muguli21_interspeech.html|
|PANACEA Cough Sound-Based Diagnosis of COVID-19 for the DiCOVA 2021 Challenge|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kamble21_interspeech.html|The First DiCOVA Challenge: Diagnosis of COVID-19 Using Acoustics|https://www.isca-speech.org/archive/interspeech_2021/kamble21_interspeech.html|
|Recognising Covid-19 from Coughing Using Ensembles of SVMs and LSTMs with Handcrafted and Deep Audio Features|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/karas21_interspeech.html|The First DiCOVA Challenge: Diagnosis of COVID-19 Using Acoustics|https://www.isca-speech.org/archive/interspeech_2021/karas21_interspeech.html|
|Detecting COVID-19 from Audio Recording of Coughs Using Random Forests and Support Vector Machines|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/sodergren21_interspeech.html|The First DiCOVA Challenge: Diagnosis of COVID-19 Using Acoustics|https://www.isca-speech.org/archive/interspeech_2021/sodergren21_interspeech.html|
|Diagnosis of COVID-19 Using Auditory Acoustic Cues|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/das21_interspeech.html|The First DiCOVA Challenge: Diagnosis of COVID-19 Using Acoustics|https://www.isca-speech.org/archive/interspeech_2021/das21_interspeech.html|
|Classification of COVID-19 from Cough Using Autoregressive Predictive Coding Pretraining and Spectral Data Augmentation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/harvill21_interspeech.html|The First DiCOVA Challenge: Diagnosis of COVID-19 Using Acoustics|https://www.isca-speech.org/archive/interspeech_2021/harvill21_interspeech.html|
|The DiCOVA 2021 Challenge — An Encoder-Decoder Approach for COVID-19 Recognition from Coughing Audio|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/deshpande21_interspeech.html|The First DiCOVA Challenge: Diagnosis of COVID-19 Using Acoustics|https://www.isca-speech.org/archive/interspeech_2021/deshpande21_interspeech.html|
|COVID-19 Detection from Spectral Features on the DiCOVA Dataset|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ritwik21_interspeech.html|The First DiCOVA Challenge: Diagnosis of COVID-19 Using Acoustics|https://www.isca-speech.org/archive/interspeech_2021/ritwik21_interspeech.html|
|Cough-Based COVID-19 Detection with Contextual Attention Convolutional Neural Networks and Gender Information|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/mallolragolta21_interspeech.html|The First DiCOVA Challenge: Diagnosis of COVID-19 Using Acoustics|https://www.isca-speech.org/archive/interspeech_2021/mallolragolta21_interspeech.html|
|Contrastive Learning of Cough Descriptors for Automatic COVID-19 Preliminary Diagnosis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/bhosale21_interspeech.html|The First DiCOVA Challenge: Diagnosis of COVID-19 Using Acoustics|https://www.isca-speech.org/archive/interspeech_2021/bhosale21_interspeech.html|
|Investigating Feature Selection and Explainability for COVID-19 Diagnostics from Cough Sounds|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/avila21_interspeech.html|The First DiCOVA Challenge: Diagnosis of COVID-19 Using Acoustics|https://www.isca-speech.org/archive/interspeech_2021/avila21_interspeech.html|
|Application for Detecting Depression, Parkinson’s Disease and Dysphonic Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kiss21_interspeech.html|Show and Tell 1|https://www.isca-speech.org/archive/interspeech_2021/kiss21_interspeech.html|
|Beey: More Than a Speech-to-Text Editor|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/weingartova21_interspeech.html|Show and Tell 1|https://www.isca-speech.org/archive/interspeech_2021/weingartova21_interspeech.html|
|Downsizing of Vocal-Tract Models to Line up Variations and Reduce Manufacturing Costs|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/arai21_interspeech.html|Show and Tell 1|https://www.isca-speech.org/archive/interspeech_2021/arai21_interspeech.html|
|ROXANNE Research Platform: Automate Criminal Investigations|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/fabien21_interspeech.html|Show and Tell 1|https://www.isca-speech.org/archive/interspeech_2021/fabien21_interspeech.html|
|The LIUM Human Active Correction Platform for Speaker Diarization|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/flucha21_interspeech.html|Show and Tell 1|https://www.isca-speech.org/archive/interspeech_2021/flucha21_interspeech.html|
|On-Device Streaming Transformer-Based End-to-End Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/oh21_interspeech.html|Show and Tell 1|https://www.isca-speech.org/archive/interspeech_2021/oh21_interspeech.html|
|Advanced Semi-Blind Speaker Extraction and Tracking Implemented in Experimental Device with Revolving Dense Microphone Array|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/cmejla21_interspeech.html|Show and Tell 1|https://www.isca-speech.org/archive/interspeech_2021/cmejla21_interspeech.html|
|Forty Years of Speech and Language Processing: From Bayes Decision Rule to Deep Learning|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ney21_interspeech.html|Keynote 1: Hermann Ney|https://www.isca-speech.org/archive/interspeech_2021/ney21_interspeech.html|
|Information Retrieval for ZeroSpeech 2021: The Submission by University of Wroclaw|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chorowski21_interspeech.html|ASR Technologies and Systems|https://www.isca-speech.org/archive/interspeech_2021/chorowski21_interspeech.html|
|Aligned Contrastive Predictive Coding|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chorowski21b_interspeech.html|ASR Technologies and Systems|https://www.isca-speech.org/archive/interspeech_2021/chorowski21b_interspeech.html|
|Neural Text Denormalization for Speech Transcripts|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/suter21_interspeech.html|ASR Technologies and Systems|https://www.isca-speech.org/archive/interspeech_2021/suter21_interspeech.html|
|Fearless Steps Challenge Phase-3 (FSC P3): Advancing SLT for Unseen Channel and Mission Data Across NASA Apollo Audio|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/joglekar21_interspeech.html|ASR Technologies and Systems|https://www.isca-speech.org/archive/interspeech_2021/joglekar21_interspeech.html|
|Voice Quality in Verbal Irony: Electroglottographic Analyses of Ironic Utterances in Standard Austrian German|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/leykum21_interspeech.html|Phonation and Voicing|https://www.isca-speech.org/archive/interspeech_2021/leykum21_interspeech.html|
|Synchronic Fortition in Five Romance Languages? A Large Corpus-Based Study of Word-Initial Devoicing|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/hutin21_interspeech.html|Phonation and Voicing|https://www.isca-speech.org/archive/interspeech_2021/hutin21_interspeech.html|
|Glottal Stops in Upper Sorbian: A Data-Driven Approach|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kraljevski21_interspeech.html|Phonation and Voicing|https://www.isca-speech.org/archive/interspeech_2021/kraljevski21_interspeech.html|
|Cue Interaction in the Perception of Prosodic Prominence: The Role of Voice Quality|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ludusan21_interspeech.html|Phonation and Voicing|https://www.isca-speech.org/archive/interspeech_2021/ludusan21_interspeech.html|
|Glottal Sounds in Korebaju|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/rodriguez21_interspeech.html|Phonation and Voicing|https://www.isca-speech.org/archive/interspeech_2021/rodriguez21_interspeech.html|
|Automatic Classification of Phonation Types in Spontaneous Speech: Towards a New Workflow for the Characterization of Speakers’ Voice Quality|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chanclu21_interspeech.html|Phonation and Voicing|https://www.isca-speech.org/archive/interspeech_2021/chanclu21_interspeech.html|
|Measuring Voice Quality Parameters After Speaker Pseudonymization|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/son21_interspeech.html|Health and Affect I|https://www.isca-speech.org/archive/interspeech_2021/son21_interspeech.html|
|Audio-Visual Recognition of Emotional Engagement of People with Dementia|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/steinert21_interspeech.html|Health and Affect I|https://www.isca-speech.org/archive/interspeech_2021/steinert21_interspeech.html|
|Speaking Corona? Human and Machine Recognition of COVID-19 from Voice|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/hecker21_interspeech.html|Health and Affect I|https://www.isca-speech.org/archive/interspeech_2021/hecker21_interspeech.html|
|Acoustic-Prosodic, Lexical and Demographic Cues to Persuasiveness in Competitive Debate Speeches|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/nguyen21b_interspeech.html|Health and Affect I|https://www.isca-speech.org/archive/interspeech_2021/nguyen21b_interspeech.html|
|Unsupervised Bayesian Adaptation of PLDA for Speaker Verification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/borgstrom21_interspeech.html|Robust Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/borgstrom21_interspeech.html|
|The DKU-Duke-Lenovo System Description for the Fearless Steps Challenge Phase III|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21i_interspeech.html|Robust Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/wang21i_interspeech.html|
|Improved Meta-Learning Training for Speaker Verification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chen21f_interspeech.html|Robust Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/chen21f_interspeech.html|
|Variational Information Bottleneck Based Regularization for Speaker Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21j_interspeech.html|Robust Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/wang21j_interspeech.html|
|Out of a Hundred Trials, How Many Errors Does Your Speaker Verifier Make?|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/brummer21_interspeech.html|Robust Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/brummer21_interspeech.html|
|SpeakerStew: Scaling to Many Languages with a Triaged Multilingual Text-Dependent and Text-Independent Speaker Verification System|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chojnacka21_interspeech.html|Robust Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/chojnacka21_interspeech.html|
|AntVoice Neural Speaker Embedding System for FFSVC 2020|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21k_interspeech.html|Robust Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/wang21k_interspeech.html|
|Gradient Regularization for Noise-Robust Speaker Verification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/li21b_interspeech.html|Robust Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/li21b_interspeech.html|
|Deep Feature CycleGANs: Speaker Identity Preserving Non-Parallel Microphone-Telephone Domain Adaptation for Speaker Verification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kataria21_interspeech.html|Robust Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/kataria21_interspeech.html|
|Scaling Effect of Self-Supervised Speech Models|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/pu21_interspeech.html|Robust Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/pu21_interspeech.html|
|Joint Feature Enhancement and Speaker Recognition with Multi-Objective Task-Oriented Network|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wu21c_interspeech.html|Robust Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/wu21c_interspeech.html|
|Multi-Level Transfer Learning from Near-Field to Far-Field Speaker Verification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21g_interspeech.html|Robust Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/zhang21g_interspeech.html|
|Speaker Anonymisation Using the McAdams Coefficient|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/patino21_interspeech.html|Robust Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/patino21_interspeech.html|
|Multi-Stream Gated and Pyramidal Temporal Convolutional Neural Networks for Audio-Visual Speech Separation in Multi-Talker Environments|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/luo21_interspeech.html|Source Separation, Dereverberation and Echo Cancellation|https://www.isca-speech.org/archive/interspeech_2021/luo21_interspeech.html|
|TeCANet: Temporal-Contextual Attention Network for Environment-Aware Speech Dereverberation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21l_interspeech.html|Source Separation, Dereverberation and Echo Cancellation|https://www.isca-speech.org/archive/interspeech_2021/wang21l_interspeech.html|
|Residual Echo and Noise Cancellation with Feature Attention Module and Multi-Domain Loss Function|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/gu21_interspeech.html|Source Separation, Dereverberation and Echo Cancellation|https://www.isca-speech.org/archive/interspeech_2021/gu21_interspeech.html|
|MIMO Self-Attentive RNN Beamformer for Multi-Speaker Speech Separation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/li21c_interspeech.html|Source Separation, Dereverberation and Echo Cancellation|https://www.isca-speech.org/archive/interspeech_2021/li21c_interspeech.html|
|Personalized PercepNet: Real-Time, Low-Complexity Target Voice Separation and Enhancement|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/giri21_interspeech.html|Source Separation, Dereverberation and Echo Cancellation|https://www.isca-speech.org/archive/interspeech_2021/giri21_interspeech.html|
|Scene-Agnostic Multi-Microphone Speech Dereverberation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/yemini21_interspeech.html|Source Separation, Dereverberation and Echo Cancellation|https://www.isca-speech.org/archive/interspeech_2021/yemini21_interspeech.html|
|Manifold-Aware Deep Clustering: Maximizing Angles Between Embedding Vectors Based on Regular Simplex|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/tanaka21_interspeech.html|Source Separation, Dereverberation and Echo Cancellation|https://www.isca-speech.org/archive/interspeech_2021/tanaka21_interspeech.html|
|A Deep Learning Approach to Multi-Channel and Multi-Microphone Acoustic Echo Cancellation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21h_interspeech.html|Source Separation, Dereverberation and Echo Cancellation|https://www.isca-speech.org/archive/interspeech_2021/zhang21h_interspeech.html|
|Joint Online Multichannel Acoustic Echo Cancellation, Speech Dereverberation and Source Separation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/na21_interspeech.html|Source Separation, Dereverberation and Echo Cancellation|https://www.isca-speech.org/archive/interspeech_2021/na21_interspeech.html|
|Should We Always Separate?: Switching Between Enhanced and Observed Signals for Overlapping Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/sato21_interspeech.html|Source Separation, Dereverberation and Echo Cancellation|https://www.isca-speech.org/archive/interspeech_2021/sato21_interspeech.html|
|Estimating Articulatory Movements in Speech Production with Transformer Networks|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/udupa21_interspeech.html|Speech Signal Analysis and Representation I|https://www.isca-speech.org/archive/interspeech_2021/udupa21_interspeech.html|
|Unsupervised Multi-Target Domain Adaptation for Acoustic Scene Classification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/yang21b_interspeech.html|Speech Signal Analysis and Representation I|https://www.isca-speech.org/archive/interspeech_2021/yang21b_interspeech.html|
|Speech Decomposition Based on a Hybrid Speech Model and Optimal Segmentation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/jaramillo21_interspeech.html|Speech Signal Analysis and Representation I|https://www.isca-speech.org/archive/interspeech_2021/jaramillo21_interspeech.html|
|Dropout Regularization for Self-Supervised Learning of Transformer Encoder Speech Representation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/luo21b_interspeech.html|Speech Signal Analysis and Representation I|https://www.isca-speech.org/archive/interspeech_2021/luo21b_interspeech.html|
|Noise Robust Pitch Stylization Using Minimum Mean Absolute Error Criterion|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/yarra21_interspeech.html|Speech Signal Analysis and Representation I|https://www.isca-speech.org/archive/interspeech_2021/yarra21_interspeech.html|
|An Attribute-Aligned Strategy for Learning Speech Representation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/huang21b_interspeech.html|Speech Signal Analysis and Representation I|https://www.isca-speech.org/archive/interspeech_2021/huang21b_interspeech.html|
|Raw Speech-to-Articulatory Inversion by Temporal Filtering and Decimation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/shahrebabaki21_interspeech.html|Speech Signal Analysis and Representation I|https://www.isca-speech.org/archive/interspeech_2021/shahrebabaki21_interspeech.html|
|Unsupervised Training of a DNN-Based Formant Tracker|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lilley21_interspeech.html|Speech Signal Analysis and Representation I|https://www.isca-speech.org/archive/interspeech_2021/lilley21_interspeech.html|
|SUPERB: Speech Processing Universal PERformance Benchmark|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/yang21c_interspeech.html|Speech Signal Analysis and Representation I|https://www.isca-speech.org/archive/interspeech_2021/yang21c_interspeech.html|
|Synchronising Speech Segments with Musical Beats in Mandarin and English Singing|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21i_interspeech.html|Speech Signal Analysis and Representation I|https://www.isca-speech.org/archive/interspeech_2021/zhang21i_interspeech.html|
|FRILL: A Non-Semantic Speech Embedding for Mobile Devices|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/peplinski21_interspeech.html|Speech Signal Analysis and Representation I|https://www.isca-speech.org/archive/interspeech_2021/peplinski21_interspeech.html|
|Pitch Contour Separation from Overlapping Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/mori21_interspeech.html|Speech Signal Analysis and Representation I|https://www.isca-speech.org/archive/interspeech_2021/mori21_interspeech.html|
|Do Sound Event Representations Generalize to Other Audio Tasks? A Case Study in Audio Transfer Learning|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kumar21_interspeech.html|Speech Signal Analysis and Representation I|https://www.isca-speech.org/archive/interspeech_2021/kumar21_interspeech.html|
|Data Augmentation for Spoken Language Understanding via Pretrained Language Models|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/peng21b_interspeech.html|Spoken Language Understanding I|https://www.isca-speech.org/archive/interspeech_2021/peng21b_interspeech.html|
|FANS: Fusing ASR and NLU for On-Device SLU|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/radfar21_interspeech.html|Spoken Language Understanding I|https://www.isca-speech.org/archive/interspeech_2021/radfar21_interspeech.html|
|Sequential End-to-End Intent and Slot Label Classification and Localization|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/cao21c_interspeech.html|Spoken Language Understanding I|https://www.isca-speech.org/archive/interspeech_2021/cao21c_interspeech.html|
|DEXTER: Deep Encoding of External Knowledge for Named Entity Recognition in Virtual Assistants|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/muralidharan21_interspeech.html|Spoken Language Understanding I|https://www.isca-speech.org/archive/interspeech_2021/muralidharan21_interspeech.html|
|A Context-Aware Hierarchical BERT Fusion Network for Multi-Turn Dialog Act Detection|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wu21d_interspeech.html|Spoken Language Understanding I|https://www.isca-speech.org/archive/interspeech_2021/wu21d_interspeech.html|
|Pre-Training for Spoken Language Understanding with Joint Textual and Phonetic Representation Learning|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chen21g_interspeech.html|Spoken Language Understanding I|https://www.isca-speech.org/archive/interspeech_2021/chen21g_interspeech.html|
|Predicting Temporal Performance Drop of Deployed Production Spoken Language Understanding Models|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/do21b_interspeech.html|Spoken Language Understanding I|https://www.isca-speech.org/archive/interspeech_2021/do21b_interspeech.html|
|Integrating Dialog History into End-to-End Spoken Language Understanding Systems|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ganhotra21_interspeech.html|Spoken Language Understanding I|https://www.isca-speech.org/archive/interspeech_2021/ganhotra21_interspeech.html|
|Coreference Augmentation for Multi-Domain Task-Oriented Dialogue State Tracking|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/han21_interspeech.html|Spoken Language Understanding I|https://www.isca-speech.org/archive/interspeech_2021/han21_interspeech.html|
|Rethinking End-to-End Evaluation of Decomposable Tasks: A Case Study on Spoken Language Understanding|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/arora21_interspeech.html|Spoken Language Understanding I|https://www.isca-speech.org/archive/interspeech_2021/arora21_interspeech.html|
|Semantic Data Augmentation for End-to-End Mandarin Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/sun21b_interspeech.html|Topics in ASR: Adaptation, Transfer Learning, Children’s Speech, and Low-Resource Settings|https://www.isca-speech.org/archive/interspeech_2021/sun21b_interspeech.html|
|Layer-Wise Fast Adaptation for End-to-End Multi-Accent Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/gong21c_interspeech.html|Topics in ASR: Adaptation, Transfer Learning, Children’s Speech, and Low-Resource Settings|https://www.isca-speech.org/archive/interspeech_2021/gong21c_interspeech.html|
|Low Resource German ASR with Untranscribed Data Spoken by Non-Native Children — INTERSPEECH 2021 Shared Task SPAPL System|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21m_interspeech.html|Topics in ASR: Adaptation, Transfer Learning, Children’s Speech, and Low-Resource Settings|https://www.isca-speech.org/archive/interspeech_2021/wang21m_interspeech.html|
|Robust Continuous On-Device Personalization for Automatic Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/sim21_interspeech.html|Topics in ASR: Adaptation, Transfer Learning, Children’s Speech, and Low-Resource Settings|https://www.isca-speech.org/archive/interspeech_2021/sim21_interspeech.html|
|Speaker Normalization Using Joint Variational Autoencoder|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kumar21b_interspeech.html|Topics in ASR: Adaptation, Transfer Learning, Children’s Speech, and Low-Resource Settings|https://www.isca-speech.org/archive/interspeech_2021/kumar21b_interspeech.html|
|The TAL System for the INTERSPEECH2021 Shared Task on Automatic Speech Recognition for Non-Native Childrens Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/xu21c_interspeech.html|Topics in ASR: Adaptation, Transfer Learning, Children’s Speech, and Low-Resource Settings|https://www.isca-speech.org/archive/interspeech_2021/xu21c_interspeech.html|
|On-the-Fly Aligned Data Augmentation for Sequence-to-Sequence ASR|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lam21b_interspeech.html|Topics in ASR: Adaptation, Transfer Learning, Children’s Speech, and Low-Resource Settings|https://www.isca-speech.org/archive/interspeech_2021/lam21b_interspeech.html|
|Zero-Shot Cross-Lingual Phonetic Recognition with External Language Embedding|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/gao21_interspeech.html|Topics in ASR: Adaptation, Transfer Learning, Children’s Speech, and Low-Resource Settings|https://www.isca-speech.org/archive/interspeech_2021/gao21_interspeech.html|
|Rapid Speaker Adaptation for Conformer Transducer: Attention and Bias Are All You Need|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/huang21c_interspeech.html|Topics in ASR: Adaptation, Transfer Learning, Children’s Speech, and Low-Resource Settings|https://www.isca-speech.org/archive/interspeech_2021/huang21c_interspeech.html|
|Best of Both Worlds: Robust Accented Speech Recognition with Adversarial Transfer Learning|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/das21b_interspeech.html|Topics in ASR: Adaptation, Transfer Learning, Children’s Speech, and Low-Resource Settings|https://www.isca-speech.org/archive/interspeech_2021/das21b_interspeech.html|
|Extending Pronunciation Dictionary with Automatically Detected Word Mispronunciations to Improve PAII’s System for Interspeech 2021 Non-Native Child English Close Track ASR Challenge|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chu21_interspeech.html|Topics in ASR: Adaptation, Transfer Learning, Children’s Speech, and Low-Resource Settings|https://www.isca-speech.org/archive/interspeech_2021/chu21_interspeech.html|
|CVC: Contrastive Learning for Non-Parallel Voice Conversion|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/li21d_interspeech.html|Voice Conversion and Adaptation I|https://www.isca-speech.org/archive/interspeech_2021/li21d_interspeech.html|
|A Preliminary Study of a Two-Stage Paradigm for Preserving Speaker Identity in Dysarthric Voice Conversion|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/huang21d_interspeech.html|Voice Conversion and Adaptation I|https://www.isca-speech.org/archive/interspeech_2021/huang21d_interspeech.html|
|One-Shot Voice Conversion with Speaker-Agnostic StarGAN|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/eskimez21_interspeech.html|Voice Conversion and Adaptation I|https://www.isca-speech.org/archive/interspeech_2021/eskimez21_interspeech.html|
|Fine-Tuning Pre-Trained Voice Conversion Model for Adding New Target Speakers with Limited Data|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/koshizuka21_interspeech.html|Voice Conversion and Adaptation I|https://www.isca-speech.org/archive/interspeech_2021/koshizuka21_interspeech.html|
|VQMIVC: Vector Quantization and Mutual Information-Based Unsupervised Speech Representation Disentanglement for One-Shot Voice Conversion|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21n_interspeech.html|Voice Conversion and Adaptation I|https://www.isca-speech.org/archive/interspeech_2021/wang21n_interspeech.html|
|StarGANv2-VC: A Diverse, Unsupervised, Non-Parallel Framework for Natural-Sounding Voice Conversion|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/li21e_interspeech.html|Voice Conversion and Adaptation I|https://www.isca-speech.org/archive/interspeech_2021/li21e_interspeech.html|
|Normalization Driven Zero-Shot Multi-Speaker Speech Synthesis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kumar21c_interspeech.html|Voice Conversion and Adaptation I|https://www.isca-speech.org/archive/interspeech_2021/kumar21c_interspeech.html|
|StarGAN-VC+ASR: StarGAN-Based Non-Parallel Voice Conversion Regularized by Automatic Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/sakamoto21_interspeech.html|Voice Conversion and Adaptation I|https://www.isca-speech.org/archive/interspeech_2021/sakamoto21_interspeech.html|
|Two-Pathway Style Embedding for Arbitrary Voice Conversion|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/xu21d_interspeech.html|Voice Conversion and Adaptation I|https://www.isca-speech.org/archive/interspeech_2021/xu21d_interspeech.html|
|Non-Parallel Any-to-Many Voice Conversion by Replacing Speaker Statistics|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/liu21c_interspeech.html|Voice Conversion and Adaptation I|https://www.isca-speech.org/archive/interspeech_2021/liu21c_interspeech.html|
|Cross-Lingual Voice Conversion with a Cycle Consistency Loss on Linguistic Representation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhou21c_interspeech.html|Voice Conversion and Adaptation I|https://www.isca-speech.org/archive/interspeech_2021/zhou21c_interspeech.html|
|Improving Robustness of One-Shot Voice Conversion with Deep Discriminative Speaker Encoder|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/du21_interspeech.html|Voice Conversion and Adaptation I|https://www.isca-speech.org/archive/interspeech_2021/du21_interspeech.html|
|Optimizing an Automatic Creaky Voice Detection Method for Australian English Speaking Females|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/white21_interspeech.html|Voice Quality Characterization for Clinical Voice Assessment: Voice Production, Acoustics, and Auditory Perception|https://www.isca-speech.org/archive/interspeech_2021/white21_interspeech.html|
|A Comparison of Acoustic Correlates of Voice Quality Across Different Recording Devices: A Cautionary Tale|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/penney21_interspeech.html|Voice Quality Characterization for Clinical Voice Assessment: Voice Production, Acoustics, and Auditory Perception|https://www.isca-speech.org/archive/interspeech_2021/penney21_interspeech.html|
|Investigating Voice Function Characteristics of Greek Speakers with Hearing Loss Using Automatic Glottal Source Feature Extraction|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/sfakianaki21_interspeech.html|Voice Quality Characterization for Clinical Voice Assessment: Voice Production, Acoustics, and Auditory Perception|https://www.isca-speech.org/archive/interspeech_2021/sfakianaki21_interspeech.html|
|Automated Detection of Voice Disorder in the Saarbrücken Voice Database: Effects of Pathology Subset and Audio Materials|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/huckvale21_interspeech.html|Voice Quality Characterization for Clinical Voice Assessment: Voice Production, Acoustics, and Auditory Perception|https://www.isca-speech.org/archive/interspeech_2021/huckvale21_interspeech.html|
|Accelerometer-Based Measurements of Voice Quality in Children During Semi-Occluded Vocal Tract Exercise with a Narrow Straw in Air|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lulich21_interspeech.html|Voice Quality Characterization for Clinical Voice Assessment: Voice Production, Acoustics, and Auditory Perception|https://www.isca-speech.org/archive/interspeech_2021/lulich21_interspeech.html|
|Articulatory Coordination for Speech Motor Tracking in Huntington Disease|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/perez21_interspeech.html|Voice Quality Characterization for Clinical Voice Assessment: Voice Production, Acoustics, and Auditory Perception|https://www.isca-speech.org/archive/interspeech_2021/perez21_interspeech.html|
|Modeling Dysphonia Severity as a Function of Roughness and Breathiness Ratings in the GRBAS Scale|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ferrer21_interspeech.html|Voice Quality Characterization for Clinical Voice Assessment: Voice Production, Acoustics, and Auditory Perception|https://www.isca-speech.org/archive/interspeech_2021/ferrer21_interspeech.html|
|Golos: Russian Dataset for Speech Research|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/karpov21_interspeech.html|Miscellanous Topics in ASR|https://www.isca-speech.org/archive/interspeech_2021/karpov21_interspeech.html|
|Radically Old Way of Computing Spectra: Applications in End-to-End ASR|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/sadhu21b_interspeech.html|Miscellanous Topics in ASR|https://www.isca-speech.org/archive/interspeech_2021/sadhu21b_interspeech.html|
|Self-Supervised End-to-End ASR for Low Resource L2 Swedish|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/alghezi21_interspeech.html|Miscellanous Topics in ASR|https://www.isca-speech.org/archive/interspeech_2021/alghezi21_interspeech.html|
|SPGISpeech: 5,000 Hours of Transcribed Financial Audio for Fully Formatted End-to-End Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/oneill21_interspeech.html|Miscellanous Topics in ASR|https://www.isca-speech.org/archive/interspeech_2021/oneill21_interspeech.html|
|LeBenchmark: A Reproducible Framework for Assessing Self-Supervised Representation Learning from Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/evain21_interspeech.html|Miscellanous Topics in ASR|https://www.isca-speech.org/archive/interspeech_2021/evain21_interspeech.html|
|Prosodic Accommodation in Face-to-Face and Telephone Dialogues|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/sturm21_interspeech.html|Phonetics I|https://www.isca-speech.org/archive/interspeech_2021/sturm21_interspeech.html|
|Dialect Features in Heterogeneous and Homogeneous Gheg Speaking Communities|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/riverincoutlee21_interspeech.html|Phonetics I|https://www.isca-speech.org/archive/interspeech_2021/riverincoutlee21_interspeech.html|
|An Exploration of the Acoustic Space of Rhotics and Laterals in Ruruuli|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zellers21_interspeech.html|Phonetics I|https://www.isca-speech.org/archive/interspeech_2021/zellers21_interspeech.html|
|Domain-Initial Strengthening in Turkish: Acoustic Cues to Prosodic Hierarchy in Stop Consonants|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/bodur21_interspeech.html|Phonetics I|https://www.isca-speech.org/archive/interspeech_2021/bodur21_interspeech.html|
|Auxiliary Loss Function for Target Speech Extraction and Recognition with Weak Supervision Based on Speaker Characteristics|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zmolikova21_interspeech.html|Target Speaker Detection, Localization and Separation|https://www.isca-speech.org/archive/interspeech_2021/zmolikova21_interspeech.html|
|Universal Speaker Extraction in the Presence and Absence of Target Speakers for Speech of One and Two Talkers|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/borsdorf21_interspeech.html|Target Speaker Detection, Localization and Separation|https://www.isca-speech.org/archive/interspeech_2021/borsdorf21_interspeech.html|
|Using X-Vectors for Speech Activity Detection in Broadcast Streams|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/mateju21_interspeech.html|Target Speaker Detection, Localization and Separation|https://www.isca-speech.org/archive/interspeech_2021/mateju21_interspeech.html|
|Time Delay Estimation for Speaker Localization Using CNN-Based Parametrized GCC-PHAT Features|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/salvati21_interspeech.html|Target Speaker Detection, Localization and Separation|https://www.isca-speech.org/archive/interspeech_2021/salvati21_interspeech.html|
|Real-Time Speaker Counting in a Cocktail Party Scenario Using Attention-Guided Convolutional Neural Network|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/yousefi21_interspeech.html|Target Speaker Detection, Localization and Separation|https://www.isca-speech.org/archive/interspeech_2021/yousefi21_interspeech.html|
|End-to-End Language Diarization for Bilingual Code-Switching Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/liu21d_interspeech.html|Language and Accent Recognition|https://www.isca-speech.org/archive/interspeech_2021/liu21d_interspeech.html|
|Modeling and Training Strategies for Language Recognition Systems|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/duroselle21_interspeech.html|Language and Accent Recognition|https://www.isca-speech.org/archive/interspeech_2021/duroselle21_interspeech.html|
|A Weight Moving Average Based Alternate Decoupled Learning Algorithm for Long-Tailed Language Identification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21o_interspeech.html|Language and Accent Recognition|https://www.isca-speech.org/archive/interspeech_2021/wang21o_interspeech.html|
|Improving Accent Identification and Accented Speech Recognition Under a Framework of Self-Supervised Learning|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/deng21b_interspeech.html|Language and Accent Recognition|https://www.isca-speech.org/archive/interspeech_2021/deng21b_interspeech.html|
|Exploring wav2vec 2.0 on Speaker Verification and Language Identification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/fan21_interspeech.html|Language and Accent Recognition|https://www.isca-speech.org/archive/interspeech_2021/fan21_interspeech.html|
|Self-Supervised Phonotactic Representations for Language Identification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ramesh21_interspeech.html|Language and Accent Recognition|https://www.isca-speech.org/archive/interspeech_2021/ramesh21_interspeech.html|
|E2E-Based Multi-Task Learning Approach to Joint Speech and Accent Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21j_interspeech.html|Language and Accent Recognition|https://www.isca-speech.org/archive/interspeech_2021/zhang21j_interspeech.html|
|Excitation Source Feature Based Dialect Identification in Ao — A Low Resource Language|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/tzudir21_interspeech.html|Language and Accent Recognition|https://www.isca-speech.org/archive/interspeech_2021/tzudir21_interspeech.html|
|Low Resource ASR: The Surprising Effectiveness of High Resource Transliteration|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/khare21_interspeech.html|Low-Resource Speech Recognition|https://www.isca-speech.org/archive/interspeech_2021/khare21_interspeech.html|
|Unsupervised Acoustic Unit Discovery by Leveraging a Language-Independent Subword Discriminative Feature Representation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/feng21_interspeech.html|Low-Resource Speech Recognition|https://www.isca-speech.org/archive/interspeech_2021/feng21_interspeech.html|
|Towards Unsupervised Phone and Word Segmentation Using Self-Supervised Vector-Quantized Neural Networks|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kamper21_interspeech.html|Low-Resource Speech Recognition|https://www.isca-speech.org/archive/interspeech_2021/kamper21_interspeech.html|
|Speech SimCLR: Combining Contrastive and Reconstruction Objective for Self-Supervised Speech Representation Learning|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/jiang21_interspeech.html|Low-Resource Speech Recognition|https://www.isca-speech.org/archive/interspeech_2021/jiang21_interspeech.html|
|Multilingual Transfer of Acoustic Word Embeddings Improves When Training on Languages Related to the Target Zero-Resource Language|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/jacobs21_interspeech.html|Low-Resource Speech Recognition|https://www.isca-speech.org/archive/interspeech_2021/jacobs21_interspeech.html|
|Analyzing Speaker Information in Self-Supervised Models to Improve Zero-Resource Speech Processing|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/niekerk21_interspeech.html|Low-Resource Speech Recognition|https://www.isca-speech.org/archive/interspeech_2021/niekerk21_interspeech.html|
|Unsupervised Neural-Based Graph Clustering for Variable-Length Speech Representation Discovery of Zero-Resource Languages|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/takahashi21_interspeech.html|Low-Resource Speech Recognition|https://www.isca-speech.org/archive/interspeech_2021/takahashi21_interspeech.html|
|Speech Representation Learning Combining Conformer CPC with Deep Cluster for the ZeroSpeech Challenge 2021|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/maekaku21_interspeech.html|Low-Resource Speech Recognition|https://www.isca-speech.org/archive/interspeech_2021/maekaku21_interspeech.html|
|Identifying Indicators of Vulnerability from Short Speech Segments Using Acoustic and Textual Features|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/cui21_interspeech.html|Low-Resource Speech Recognition|https://www.isca-speech.org/archive/interspeech_2021/cui21_interspeech.html|
|The Zero Resource Speech Challenge 2021: Spoken Language Modelling|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/dunbar21_interspeech.html|Low-Resource Speech Recognition|https://www.isca-speech.org/archive/interspeech_2021/dunbar21_interspeech.html|
|Zero-Shot Federated Learning with New Classes for Audio Classification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/gudur21_interspeech.html|Low-Resource Speech Recognition|https://www.isca-speech.org/archive/interspeech_2021/gudur21_interspeech.html|
|AVLnet: Learning Audio-Visual Language Representations from Instructional Videos|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/rouditchenko21_interspeech.html|Low-Resource Speech Recognition|https://www.isca-speech.org/archive/interspeech_2021/rouditchenko21_interspeech.html|
|N-Singer: A Non-Autoregressive Korean Singing Voice Synthesis System for Pronunciation Enhancement|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lee21b_interspeech.html|Speech Synthesis: Singing, Multimodal, Crosslingual Synthesis|https://www.isca-speech.org/archive/interspeech_2021/lee21b_interspeech.html|
|Cross-Lingual Low Resource Speaker Adaptation Using Phonological Features|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/maniati21_interspeech.html|Speech Synthesis: Singing, Multimodal, Crosslingual Synthesis|https://www.isca-speech.org/archive/interspeech_2021/maniati21_interspeech.html|
|Improve Cross-Lingual Text-To-Speech Synthesis on Monolingual Corpora with Pitch Contour Information|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhan21_interspeech.html|Speech Synthesis: Singing, Multimodal, Crosslingual Synthesis|https://www.isca-speech.org/archive/interspeech_2021/zhan21_interspeech.html|
|Cross-Lingual Voice Conversion with Disentangled Universal Linguistic Representations|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/yang21d_interspeech.html|Speech Synthesis: Singing, Multimodal, Crosslingual Synthesis|https://www.isca-speech.org/archive/interspeech_2021/yang21d_interspeech.html|
|EfficientSing: A Chinese Singing Voice Synthesis System Using Duration-Free Acoustic Model and HiFi-GAN Vocoder|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/liu21e_interspeech.html|Speech Synthesis: Singing, Multimodal, Crosslingual Synthesis|https://www.isca-speech.org/archive/interspeech_2021/liu21e_interspeech.html|
|Cross-Lingual Speaker Adaptation Using Domain Adaptation and Speaker Consistency Loss for Text-To-Speech Synthesis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/xin21_interspeech.html|Speech Synthesis: Singing, Multimodal, Crosslingual Synthesis|https://www.isca-speech.org/archive/interspeech_2021/xin21_interspeech.html|
|Incorporating Cross-Speaker Style Transfer for Multi-Language Text-to-Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/shang21_interspeech.html|Speech Synthesis: Singing, Multimodal, Crosslingual Synthesis|https://www.isca-speech.org/archive/interspeech_2021/shang21_interspeech.html|
|Investigating Contributions of Speech and Facial Landmarks for Talking Head Generation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kesim21_interspeech.html|Speech Synthesis: Singing, Multimodal, Crosslingual Synthesis|https://www.isca-speech.org/archive/interspeech_2021/kesim21_interspeech.html|
|Speech2Video: Cross-Modal Distillation for Speech to Video Generation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/si21b_interspeech.html|Speech Synthesis: Singing, Multimodal, Crosslingual Synthesis|https://www.isca-speech.org/archive/interspeech_2021/si21b_interspeech.html|
|NU-Wave: A Diffusion Probabilistic Model for Neural Audio Upsampling|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lee21c_interspeech.html|Speech Coding and Privacy|https://www.isca-speech.org/archive/interspeech_2021/lee21c_interspeech.html|
|QISTA-Net-Audio: Audio Super-Resolution via Non-Convex ℓ_q-Norm Minimization|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lin21c_interspeech.html|Speech Coding and Privacy|https://www.isca-speech.org/archive/interspeech_2021/lin21c_interspeech.html|
|X-net: A Joint Scale Down and Scale Up Method for Voice Call|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wen21_interspeech.html|Speech Coding and Privacy|https://www.isca-speech.org/archive/interspeech_2021/wen21_interspeech.html|
|WSRGlow: A Glow-Based Waveform Generative Model for Audio Super-Resolution|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21k_interspeech.html|Speech Coding and Privacy|https://www.isca-speech.org/archive/interspeech_2021/zhang21k_interspeech.html|
|Half-Truth: A Partially Fake Audio Detection Dataset|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/yi21_interspeech.html|Speech Coding and Privacy|https://www.isca-speech.org/archive/interspeech_2021/yi21_interspeech.html|
|Data Quality as Predictor of Voice Anti-Spoofing Generalization|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chettri21_interspeech.html|Speech Coding and Privacy|https://www.isca-speech.org/archive/interspeech_2021/chettri21_interspeech.html|
|Coded Speech Enhancement Using Neural Network-Based Vector-Quantized Residual Features|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/cheon21_interspeech.html|Speech Coding and Privacy|https://www.isca-speech.org/archive/interspeech_2021/cheon21_interspeech.html|
|Multi-Channel Opus Compression for Far-Field Automatic Speech Recognition with a Fixed Bitrate Budget|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/drude21_interspeech.html|Speech Coding and Privacy|https://www.isca-speech.org/archive/interspeech_2021/drude21_interspeech.html|
|Effects of Prosodic Variations on Accidental Triggers of a Commercial Voice Assistant|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/siegert21_interspeech.html|Speech Coding and Privacy|https://www.isca-speech.org/archive/interspeech_2021/siegert21_interspeech.html|
|Improving the Expressiveness of Neural Vocoding with Non-Affine Normalizing Flows|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/gabrys21_interspeech.html|Speech Coding and Privacy|https://www.isca-speech.org/archive/interspeech_2021/gabrys21_interspeech.html|
|Voice Privacy Through x-Vector and CycleGAN-Based Anonymization|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/prajapati21_interspeech.html|Speech Coding and Privacy|https://www.isca-speech.org/archive/interspeech_2021/prajapati21_interspeech.html|
|A Two-Stage Approach to Speech Bandwidth Extension|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lin21d_interspeech.html|Speech Coding and Privacy|https://www.isca-speech.org/archive/interspeech_2021/lin21d_interspeech.html|
|Development of a Psychoacoustic Loss Function for the Deep Neural Network	(DNN)-Based Speech Coder|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/byun21_interspeech.html|Speech Coding and Privacy|https://www.isca-speech.org/archive/interspeech_2021/byun21_interspeech.html|
|Protecting Gender and Identity with Disentangled Speech Representations|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/stoidis21_interspeech.html|Speech Coding and Privacy|https://www.isca-speech.org/archive/interspeech_2021/stoidis21_interspeech.html|
|Perception of Standard Arabic Synthetic Speech Rate|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/aldholmi21_interspeech.html|Speech Perception II|https://www.isca-speech.org/archive/interspeech_2021/aldholmi21_interspeech.html|
|The Influence of Parallel Processing on Illusory Vowels|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kishiyama21_interspeech.html|Speech Perception II|https://www.isca-speech.org/archive/interspeech_2021/kishiyama21_interspeech.html|
|Exploring the Potential of Lexical Paraphrases for Mitigating Noise-Induced Comprehension Errors|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chingacham21_interspeech.html|Speech Perception II|https://www.isca-speech.org/archive/interspeech_2021/chingacham21_interspeech.html|
|SpeechAdjuster: A Tool for Investigating Listener Preferences and Speech Intelligibility|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/simantiraki21_interspeech.html|Speech Perception II|https://www.isca-speech.org/archive/interspeech_2021/simantiraki21_interspeech.html|
|VocalTurk: Exploring Feasibility of Crowdsourced Speaker Identification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/saito21_interspeech.html|Speech Perception II|https://www.isca-speech.org/archive/interspeech_2021/saito21_interspeech.html|
|Effects of Aging and Age-Related Hearing Loss on Talker Discrimination|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/xu21e_interspeech.html|Speech Perception II|https://www.isca-speech.org/archive/interspeech_2021/xu21e_interspeech.html|
|Relationships Between Perceptual Distinctiveness, Articulatory Complexity and Functional Load in Speech Communication|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21l_interspeech.html|Speech Perception II|https://www.isca-speech.org/archive/interspeech_2021/zhang21l_interspeech.html|
|Human Spoofing Detection Performance on Degraded Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/terblanche21_interspeech.html|Speech Perception II|https://www.isca-speech.org/archive/interspeech_2021/terblanche21_interspeech.html|
|Reliable Estimates of Interpretable Cue Effects with Active Learning in Psycholinguistic Research|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/einfeldt21_interspeech.html|Speech Perception II|https://www.isca-speech.org/archive/interspeech_2021/einfeldt21_interspeech.html|
|Towards the Explainability of Multimodal Speech Emotion Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kumar21d_interspeech.html|Speech Perception II|https://www.isca-speech.org/archive/interspeech_2021/kumar21d_interspeech.html|
|Primacy of Mouth over Eyes: Eye Movement Evidence from Audiovisual Mandarin Lexical Tones and Vowels|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zeng21_interspeech.html|Speech Perception II|https://www.isca-speech.org/archive/interspeech_2021/zeng21_interspeech.html|
|Investigating the Impact of Spectral and Temporal Degradation on End-to-End Automatic Speech Recognition Performance|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ashihara21_interspeech.html|Speech Perception II|https://www.isca-speech.org/archive/interspeech_2021/ashihara21_interspeech.html|
|Super-Human Performance in Online Low-Latency Recognition of Conversational Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/nguyen21c_interspeech.html|Streaming for ASR/RNN Transducers|https://www.isca-speech.org/archive/interspeech_2021/nguyen21c_interspeech.html|
|Multiple Softmax Architecture for Streaming Multilingual End-to-End ASR Systems|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/joshi21_interspeech.html|Streaming for ASR/RNN Transducers|https://www.isca-speech.org/archive/interspeech_2021/joshi21_interspeech.html|
|Contextualized Streaming End-to-End Speech Recognition with Trie-Based Deep Biasing and Shallow Fusion|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/le21_interspeech.html|Streaming for ASR/RNN Transducers|https://www.isca-speech.org/archive/interspeech_2021/le21_interspeech.html|
|An Efficient Streaming Non-Recurrent On-Device End-to-End Model with Improvements to Rare-Word Modeling|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/sainath21_interspeech.html|Streaming for ASR/RNN Transducers|https://www.isca-speech.org/archive/interspeech_2021/sainath21_interspeech.html|
|Streaming Multi-Talker Speech Recognition with Joint Speaker Identification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lu21_interspeech.html|Streaming for ASR/RNN Transducers|https://www.isca-speech.org/archive/interspeech_2021/lu21_interspeech.html|
|Streaming End-to-End Speech Recognition for Hybrid RNN-T/Attention Architecture|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/moriya21_interspeech.html|Streaming for ASR/RNN Transducers|https://www.isca-speech.org/archive/interspeech_2021/moriya21_interspeech.html|
|Improving RNN-T ASR Accuracy Using Context Audio|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/schwarz21_interspeech.html|Streaming for ASR/RNN Transducers|https://www.isca-speech.org/archive/interspeech_2021/schwarz21_interspeech.html|
|HMM-Free Encoder Pre-Training for Streaming RNN Transducer|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/huang21e_interspeech.html|Streaming for ASR/RNN Transducers|https://www.isca-speech.org/archive/interspeech_2021/huang21e_interspeech.html|
|Reducing Exposure Bias in Training Recurrent Neural Network Transducers|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/cui21b_interspeech.html|Streaming for ASR/RNN Transducers|https://www.isca-speech.org/archive/interspeech_2021/cui21b_interspeech.html|
|Bridging the Gap Between Streaming and Non-Streaming ASR Systems by Distilling Ensembles of CTC and RNN-T Models|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/doutre21_interspeech.html|Streaming for ASR/RNN Transducers|https://www.isca-speech.org/archive/interspeech_2021/doutre21_interspeech.html|
|Mixture Model Attention: Flexible Streaming and Non-Streaming Automatic Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/audhkhasi21_interspeech.html|Streaming for ASR/RNN Transducers|https://www.isca-speech.org/archive/interspeech_2021/audhkhasi21_interspeech.html|
|StableEmit: Selection Probability Discount for Reducing Emission Latency of Streaming Monotonic Attention ASR|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/inaguma21_interspeech.html|Streaming for ASR/RNN Transducers|https://www.isca-speech.org/archive/interspeech_2021/inaguma21_interspeech.html|
|Dual Causal/Non-Causal Self-Attention for Streaming End-to-End Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/moritz21_interspeech.html|Streaming for ASR/RNN Transducers|https://www.isca-speech.org/archive/interspeech_2021/moritz21_interspeech.html|
|Multi-Mode Transformer Transducer with Stochastic Future Context|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kim21d_interspeech.html|Streaming for ASR/RNN Transducers|https://www.isca-speech.org/archive/interspeech_2021/kim21d_interspeech.html|
|A Causal U-Net Based Neural Beamforming Network for Real-Time Multi-Channel Speech Enhancement|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ren21_interspeech.html|ConferencingSpeech 2021 Challenge: Far-Field Multi-Channel Speech Enhancement for Video Conferencing|https://www.isca-speech.org/archive/interspeech_2021/ren21_interspeech.html|
|A Partitioned-Block Frequency-Domain Adaptive Kalman Filter for Stereophonic Acoustic Echo Cancellation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhu21d_interspeech.html|ConferencingSpeech 2021 Challenge: Far-Field Multi-Channel Speech Enhancement for Video Conferencing|https://www.isca-speech.org/archive/interspeech_2021/zhu21d_interspeech.html|
|Real-Time Independent Vector Analysis Using Semi-Supervised Nonnegative Matrix Factorization as a Source Model|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21p_interspeech.html|ConferencingSpeech 2021 Challenge: Far-Field Multi-Channel Speech Enhancement for Video Conferencing|https://www.isca-speech.org/archive/interspeech_2021/wang21p_interspeech.html|
|Improving Channel Decorrelation for Multi-Channel Target Speech Extraction|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/han21b_interspeech.html|ConferencingSpeech 2021 Challenge: Far-Field Multi-Channel Speech Enhancement for Video Conferencing|https://www.isca-speech.org/archive/interspeech_2021/han21b_interspeech.html|
|Inplace Gated Convolutional Recurrent Neural Network for Dual-Channel Speech Enhancement|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/liu21f_interspeech.html|ConferencingSpeech 2021 Challenge: Far-Field Multi-Channel Speech Enhancement for Video Conferencing|https://www.isca-speech.org/archive/interspeech_2021/liu21f_interspeech.html|
|SRIB-LEAP Submission to Far-Field Multi-Channel Speech Enhancement Challenge for Video Conferencing|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/raj21_interspeech.html|ConferencingSpeech 2021 Challenge: Far-Field Multi-Channel Speech Enhancement for Video Conferencing|https://www.isca-speech.org/archive/interspeech_2021/raj21_interspeech.html|
|Real-Time Multi-Channel Speech Enhancement Based on Neural Network Masking with Attention Model|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/xue21_interspeech.html|ConferencingSpeech 2021 Challenge: Far-Field Multi-Channel Speech Enhancement for Video Conferencing|https://www.isca-speech.org/archive/interspeech_2021/xue21_interspeech.html|
|Uncovering the Acoustic Cues of COVID-19 Infection|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ganapathy21_interspeech.html|Survey Talk 2: Sriram Ganapathy|https://www.isca-speech.org/archive/interspeech_2021/ganapathy21_interspeech.html|
|Ethical and Technological Challenges of Conversational AI|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/fung21_interspeech.html|Keynote 2: Pascale Fung|https://www.isca-speech.org/archive/interspeech_2021/fung21_interspeech.html|
|BERT-Based Semantic Model for Rescoring N-Best Speech Recognition List|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/fohr21_interspeech.html|Language Modeling and Text-Based Innovations for ASR|https://www.isca-speech.org/archive/interspeech_2021/fohr21_interspeech.html|
|Text Augmentation for Language Models in High Error Recognition Scenario|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/benes21_interspeech.html|Language Modeling and Text-Based Innovations for ASR|https://www.isca-speech.org/archive/interspeech_2021/benes21_interspeech.html|
|On Sampling-Based Training Criteria for Neural Language Modeling|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/gao21b_interspeech.html|Language Modeling and Text-Based Innovations for ASR|https://www.isca-speech.org/archive/interspeech_2021/gao21b_interspeech.html|
|Fast Text-Only Domain Adaptation of RNN-Transducer Prediction Network|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/pylkkonen21_interspeech.html|Language Modeling and Text-Based Innovations for ASR|https://www.isca-speech.org/archive/interspeech_2021/pylkkonen21_interspeech.html|
|Using Games to Augment Corpora for Language Recognition and Confusability|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/cieri21_interspeech.html|Speaker, Language, and Privacy|https://www.isca-speech.org/archive/interspeech_2021/cieri21_interspeech.html|
|Fair Voice Biometrics: Impact of Demographic Imbalance on Group Fairness in Speaker Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/fenu21_interspeech.html|Speaker, Language, and Privacy|https://www.isca-speech.org/archive/interspeech_2021/fenu21_interspeech.html|
|Knowledge Distillation from Multi-Modality to Single-Modality for Person Verification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21m_interspeech.html|Speaker, Language, and Privacy|https://www.isca-speech.org/archive/interspeech_2021/zhang21m_interspeech.html|
|Adversarial Disentanglement of Speaker Representation for Attribute-Driven Privacy Preservation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/noe21_interspeech.html|Speaker, Language, and Privacy|https://www.isca-speech.org/archive/interspeech_2021/noe21_interspeech.html|
|Automatically Detecting Errors and Disfluencies in Read Speech to Predict Cognitive Impairment in People with Parkinson’s Disease|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/romana21_interspeech.html|Assessment of Pathological Speech and Language I|https://www.isca-speech.org/archive/interspeech_2021/romana21_interspeech.html|
|Automatic Extraction of Speech Rhythm Descriptors for Speech Intelligibility Assessment in the Context of Head and Neck Cancers|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/vaysse21_interspeech.html|Assessment of Pathological Speech and Language I|https://www.isca-speech.org/archive/interspeech_2021/vaysse21_interspeech.html|
|Speech Disorder Classification Using Extended Factorized Hierarchical Variational Auto-Encoders|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/qi21b_interspeech.html|Assessment of Pathological Speech and Language I|https://www.isca-speech.org/archive/interspeech_2021/qi21b_interspeech.html|
|The Impact of Forced-Alignment Errors on Automatic Pronunciation Evaluation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/mathad21_interspeech.html|Assessment of Pathological Speech and Language I|https://www.isca-speech.org/archive/interspeech_2021/mathad21_interspeech.html|
|Late Fusion of the Available Lexicon and Raw Waveform-Based Acoustic Modeling for Depression and Dementia Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/villatorotello21_interspeech.html|Assessment of Pathological Speech and Language I|https://www.isca-speech.org/archive/interspeech_2021/villatorotello21_interspeech.html|
|Neural Speaker Embeddings for Ultrasound-Based Silent Speech Interfaces|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/shandiz21_interspeech.html|Assessment of Pathological Speech and Language I|https://www.isca-speech.org/archive/interspeech_2021/shandiz21_interspeech.html|
|Cross-Modal Learning for Audio-Visual Video Parsing|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lamba21_interspeech.html|Communication and Interaction, Multimodality|https://www.isca-speech.org/archive/interspeech_2021/lamba21_interspeech.html|
|A Psychology-Driven Computational Analysis of Political Interviews|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/cook21_interspeech.html|Communication and Interaction, Multimodality|https://www.isca-speech.org/archive/interspeech_2021/cook21_interspeech.html|
|Speech Emotion Recognition Based on Attention Weight Correction Using Word-Level Confidence Measure|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/santoso21_interspeech.html|Communication and Interaction, Multimodality|https://www.isca-speech.org/archive/interspeech_2021/santoso21_interspeech.html|
|Effects of Voice Type and Task on L2 Learners’ Awareness of Pronunciation Errors|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/silpachai21_interspeech.html|Communication and Interaction, Multimodality|https://www.isca-speech.org/archive/interspeech_2021/silpachai21_interspeech.html|
|Lexical Entrainment and Intra-Speaker Variability in Cooperative Dialogues|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/menshikova21_interspeech.html|Communication and Interaction, Multimodality|https://www.isca-speech.org/archive/interspeech_2021/menshikova21_interspeech.html|
|Detecting Alzheimer’s Disease Using Interactional and Acoustic Features from Spontaneous Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/nasreen21_interspeech.html|Communication and Interaction, Multimodality|https://www.isca-speech.org/archive/interspeech_2021/nasreen21_interspeech.html|
|Investigating the Interplay Between Affective, Phonatory and Motoric Subsystems in Autism Spectrum Disorder Using a Multimodal Dialogue Agent|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kothare21_interspeech.html|Communication and Interaction, Multimodality|https://www.isca-speech.org/archive/interspeech_2021/kothare21_interspeech.html|
|Analysis of Eye Gaze Reasons and Gaze Aversions During Three-Party Conversations|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ishi21_interspeech.html|Communication and Interaction, Multimodality|https://www.isca-speech.org/archive/interspeech_2021/ishi21_interspeech.html|
|Semantic Distance: A New Metric for ASR Performance Analysis Towards Spoken Language Understanding|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kim21e_interspeech.html|Language and Lexical Modeling for ASR|https://www.isca-speech.org/archive/interspeech_2021/kim21e_interspeech.html|
|A Light-Weight Contextual Spelling Correction Model for Customizing Transducer-Based Speech Recognition Systems|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21q_interspeech.html|Language and Lexical Modeling for ASR|https://www.isca-speech.org/archive/interspeech_2021/wang21q_interspeech.html|
|Incorporating External POS Tagger for Punctuation Restoration|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/shi21_interspeech.html|Language and Lexical Modeling for ASR|https://www.isca-speech.org/archive/interspeech_2021/shi21_interspeech.html|
|Phonetically Induced Subwords for End-to-End Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/papadourakis21_interspeech.html|Language and Lexical Modeling for ASR|https://www.isca-speech.org/archive/interspeech_2021/papadourakis21_interspeech.html|
|Revisiting Parity of Human vs. Machine Conversational Speech Transcription|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/mansfield21_interspeech.html|Language and Lexical Modeling for ASR|https://www.isca-speech.org/archive/interspeech_2021/mansfield21_interspeech.html|
|Lookup-Table Recurrent Language Models for Long Tail Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/huang21f_interspeech.html|Language and Lexical Modeling for ASR|https://www.isca-speech.org/archive/interspeech_2021/huang21f_interspeech.html|
|Contextual Density Ratio for Language Model Biasing of Sequence to Sequence ASR Systems|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/andresferrer21_interspeech.html|Language and Lexical Modeling for ASR|https://www.isca-speech.org/archive/interspeech_2021/andresferrer21_interspeech.html|
|Token-Level Supervised Contrastive Learning for Punctuation Restoration|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/huang21g_interspeech.html|Language and Lexical Modeling for ASR|https://www.isca-speech.org/archive/interspeech_2021/huang21g_interspeech.html|
|BART Based Semantic Correction for Mandarin Automatic Speech Recognition System|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhao21_interspeech.html|Language and Lexical Modeling for ASR|https://www.isca-speech.org/archive/interspeech_2021/zhao21_interspeech.html|
|Class-Based Neural Network Language Model for Second-Pass Rescoring in ASR|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/dai21b_interspeech.html|Language and Lexical Modeling for ASR|https://www.isca-speech.org/archive/interspeech_2021/dai21b_interspeech.html|
|Improving Customization of Neural Transducers by Mitigating Acoustic Mismatch of Synthesized Audio|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kurata21_interspeech.html|Language and Lexical Modeling for ASR|https://www.isca-speech.org/archive/interspeech_2021/kurata21_interspeech.html|
|A Discriminative Entity-Aware Language Model for Virtual Assistants|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/saebi21_interspeech.html|Language and Lexical Modeling for ASR|https://www.isca-speech.org/archive/interspeech_2021/saebi21_interspeech.html|
|Correcting Automated and Manual Speech Transcription Errors Using Warped Language Models|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/namazifar21_interspeech.html|Language and Lexical Modeling for ASR|https://www.isca-speech.org/archive/interspeech_2021/namazifar21_interspeech.html|
|Dynamic Encoder Transducer: A Flexible Solution for Trading Off Accuracy for Latency|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/shi21b_interspeech.html|Novel Neural Network Architectures for ASR|https://www.isca-speech.org/archive/interspeech_2021/shi21b_interspeech.html|
|Domain-Aware Self-Attention for Multi-Domain Neural Machine Translation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21n_interspeech.html|Novel Neural Network Architectures for ASR|https://www.isca-speech.org/archive/interspeech_2021/zhang21n_interspeech.html|
|Librispeech Transducer Model with Internal Language Model Prior Correction|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zeyer21_interspeech.html|Novel Neural Network Architectures for ASR|https://www.isca-speech.org/archive/interspeech_2021/zeyer21_interspeech.html|
|A Deliberation-Based Joint Acoustic and Text Decoder|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/mavandadi21_interspeech.html|Novel Neural Network Architectures for ASR|https://www.isca-speech.org/archive/interspeech_2021/mavandadi21_interspeech.html|
|On the Limit of English Conversational Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/tuske21_interspeech.html|Novel Neural Network Architectures for ASR|https://www.isca-speech.org/archive/interspeech_2021/tuske21_interspeech.html|
|Deformable TDNN with Adaptive Receptive Fields for Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/an21_interspeech.html|Novel Neural Network Architectures for ASR|https://www.isca-speech.org/archive/interspeech_2021/an21_interspeech.html|
|SpeechMoE: Scaling to Large Acoustic Models with Dynamic Routing Mixture of Experts|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/you21_interspeech.html|Novel Neural Network Architectures for ASR|https://www.isca-speech.org/archive/interspeech_2021/you21_interspeech.html|
|Online Compressive Transformer for End-to-End Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/leong21_interspeech.html|Novel Neural Network Architectures for ASR|https://www.isca-speech.org/archive/interspeech_2021/leong21_interspeech.html|
|End to End Transformer-Based Contextual Speech Recognition Based on Pointer Network|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lin21e_interspeech.html|Novel Neural Network Architectures for ASR|https://www.isca-speech.org/archive/interspeech_2021/lin21e_interspeech.html|
|A Comparative Study on Neural Architectures and Training Methods for Japanese Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/karita21_interspeech.html|Novel Neural Network Architectures for ASR|https://www.isca-speech.org/archive/interspeech_2021/karita21_interspeech.html|
|Advanced Long-Context End-to-End Speech Recognition Using Context-Expanded Transformers|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/hori21b_interspeech.html|Novel Neural Network Architectures for ASR|https://www.isca-speech.org/archive/interspeech_2021/hori21b_interspeech.html|
|Transformer-Based ASR Incorporating Time-Reduction Layer and Fine-Tuning with Self-Knowledge Distillation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/haidar21_interspeech.html|Novel Neural Network Architectures for ASR|https://www.isca-speech.org/archive/interspeech_2021/haidar21_interspeech.html|
|Flexi-Transducer: Optimizing Latency, Accuracy and Compute for Multi-Domain On-Device Scenarios|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/mahadeokar21_interspeech.html|Novel Neural Network Architectures for ASR|https://www.isca-speech.org/archive/interspeech_2021/mahadeokar21_interspeech.html|
|Difference in Perceived Speech Signal Quality Assessment Among Monolingual and Bilingual Teenage Students|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/falkowskigilski21_interspeech.html|Speech Localization, Enhancement, and Quality Assessment|https://www.isca-speech.org/archive/interspeech_2021/falkowskigilski21_interspeech.html|
|PILOT: Introducing Transformers for Probabilistic Sound Event Localization|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/schymura21_interspeech.html|Speech Localization, Enhancement, and Quality Assessment|https://www.isca-speech.org/archive/interspeech_2021/schymura21_interspeech.html|
|Sound Source Localization with Majorization Minimization|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/togami21_interspeech.html|Speech Localization, Enhancement, and Quality Assessment|https://www.isca-speech.org/archive/interspeech_2021/togami21_interspeech.html|
|NISQA: A Deep CNN-Self-Attention Model for Multidimensional Speech Quality Prediction with Crowdsourced Datasets|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/mittag21_interspeech.html|Speech Localization, Enhancement, and Quality Assessment|https://www.isca-speech.org/archive/interspeech_2021/mittag21_interspeech.html|
|Subjective Evaluation of Noise Suppression Algorithms in Crowdsourcing|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/naderi21_interspeech.html|Speech Localization, Enhancement, and Quality Assessment|https://www.isca-speech.org/archive/interspeech_2021/naderi21_interspeech.html|
|Reliable Intensity Vector Selection for Multi-Source Direction-of-Arrival Estimation Using a Single Acoustic Vector Sensor|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/geng21_interspeech.html|Speech Localization, Enhancement, and Quality Assessment|https://www.isca-speech.org/archive/interspeech_2021/geng21_interspeech.html|
|MetricNet: Towards Improved Modeling For Non-Intrusive Speech Quality Assessment|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/yu21_interspeech.html|Speech Localization, Enhancement, and Quality Assessment|https://www.isca-speech.org/archive/interspeech_2021/yu21_interspeech.html|
|CNN-Based Processing of Acoustic and Radio Frequency Signals for Speaker Localization from MAVs|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/toma21_interspeech.html|Speech Localization, Enhancement, and Quality Assessment|https://www.isca-speech.org/archive/interspeech_2021/toma21_interspeech.html|
|Assessment of von Mises-Bernoulli Deep Neural Network in Sound Source Localization|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/itoyama21_interspeech.html|Speech Localization, Enhancement, and Quality Assessment|https://www.isca-speech.org/archive/interspeech_2021/itoyama21_interspeech.html|
|Feature Fusion by Attention Networks for Robust DOA Estimation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/liu21g_interspeech.html|Speech Localization, Enhancement, and Quality Assessment|https://www.isca-speech.org/archive/interspeech_2021/liu21g_interspeech.html|
|Far-Field Speaker Localization and Adaptive GLMB Tracking|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lin21f_interspeech.html|Speech Localization, Enhancement, and Quality Assessment|https://www.isca-speech.org/archive/interspeech_2021/lin21f_interspeech.html|
|On the Design of Deep Priors for Unsupervised Audio Restoration|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/narayanaswamy21_interspeech.html|Speech Localization, Enhancement, and Quality Assessment|https://www.isca-speech.org/archive/interspeech_2021/narayanaswamy21_interspeech.html|
|Cramér-Rao Lower Bound for DOA Estimation with an Array of Directional Microphones in Reverberant Environments|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chen21h_interspeech.html|Speech Localization, Enhancement, and Quality Assessment|https://www.isca-speech.org/archive/interspeech_2021/chen21h_interspeech.html|
|GAN Vocoder: Multi-Resolution Discriminator Is All You Need|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/you21b_interspeech.html|Speech Synthesis: Neural Waveform Generation|https://www.isca-speech.org/archive/interspeech_2021/you21b_interspeech.html|
|Glow-WaveGAN: Learning Speech Representations from GAN-Based Variational Auto-Encoder for High Fidelity Flow-Based Speech Synthesis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/cong21_interspeech.html|Speech Synthesis: Neural Waveform Generation|https://www.isca-speech.org/archive/interspeech_2021/cong21_interspeech.html|
|Unified Source-Filter GAN: Unified Source-Filter Network Based On Factorization of Quasi-Periodic Parallel WaveGAN|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/yoneyama21_interspeech.html|Speech Synthesis: Neural Waveform Generation|https://www.isca-speech.org/archive/interspeech_2021/yoneyama21_interspeech.html|
|Harmonic WaveGAN: GAN-Based Speech Waveform Generation Model with Harmonic Structure Discriminator|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/mizuta21_interspeech.html|Speech Synthesis: Neural Waveform Generation|https://www.isca-speech.org/archive/interspeech_2021/mizuta21_interspeech.html|
|Fre-GAN: Adversarial Frequency-Consistent Audio Synthesis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kim21f_interspeech.html|Speech Synthesis: Neural Waveform Generation|https://www.isca-speech.org/archive/interspeech_2021/kim21f_interspeech.html|
|GANSpeech: Adversarial Training for High-Fidelity Multi-Speaker Speech Synthesis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/yang21e_interspeech.html|Speech Synthesis: Neural Waveform Generation|https://www.isca-speech.org/archive/interspeech_2021/yang21e_interspeech.html|
|UnivNet: A Neural Vocoder with Multi-Resolution Spectrogram Discriminators for High-Fidelity Waveform Generation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/jang21_interspeech.html|Speech Synthesis: Neural Waveform Generation|https://www.isca-speech.org/archive/interspeech_2021/jang21_interspeech.html|
|Continuous Wavelet Vocoder-Based Decomposition of Parametric Speech Waveform Synthesis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/alradhi21_interspeech.html|Speech Synthesis: Neural Waveform Generation|https://www.isca-speech.org/archive/interspeech_2021/alradhi21_interspeech.html|
|High-Fidelity and Low-Latency Universal Neural Vocoder Based on Multiband WaveRNN with Data-Driven Linear Prediction for Discrete Waveform Modeling|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/tobing21_interspeech.html|Speech Synthesis: Neural Waveform Generation|https://www.isca-speech.org/archive/interspeech_2021/tobing21_interspeech.html|
|Basis-MelGAN: Efficient Neural Vocoder Based on Audio Decomposition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/liu21h_interspeech.html|Speech Synthesis: Neural Waveform Generation|https://www.isca-speech.org/archive/interspeech_2021/liu21h_interspeech.html|
|High-Fidelity Parallel WaveGAN with Multi-Band Harmonic-Plus-Noise Model|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/hwang21_interspeech.html|Speech Synthesis: Neural Waveform Generation|https://www.isca-speech.org/archive/interspeech_2021/hwang21_interspeech.html|
|SpecRec: An Alternative Solution for Improving End-to-End Speech-to-Text Translation via Spectrogram Reconstruction|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chen21i_interspeech.html|Spoken Machine Translation|https://www.isca-speech.org/archive/interspeech_2021/chen21i_interspeech.html|
|Subtitle Translation as Markup Translation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/cherry21_interspeech.html|Spoken Machine Translation|https://www.isca-speech.org/archive/interspeech_2021/cherry21_interspeech.html|
|Large-Scale Self- and Semi-Supervised Learning for Speech Translation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21r_interspeech.html|Spoken Machine Translation|https://www.isca-speech.org/archive/interspeech_2021/wang21r_interspeech.html|
|CoVoST 2 and Massively Multilingual Speech Translation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21s_interspeech.html|Spoken Machine Translation|https://www.isca-speech.org/archive/interspeech_2021/wang21s_interspeech.html|
|AlloST: Low-Resource Speech Translation Without Source Transcription|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/cheng21_interspeech.html|Spoken Machine Translation|https://www.isca-speech.org/archive/interspeech_2021/cheng21_interspeech.html|
|Weakly-Supervised Speech-to-Text Mapping with Visually Connected Non-Parallel Speech-Text Data Using Cyclic Partially-Aligned Transformer|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/effendi21_interspeech.html|Spoken Machine Translation|https://www.isca-speech.org/archive/interspeech_2021/effendi21_interspeech.html|
|Transcribing Paralinguistic Acoustic Cues to Target Language Text in Transformer-Based Speech-to-Text Translation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/tokuyama21_interspeech.html|Spoken Machine Translation|https://www.isca-speech.org/archive/interspeech_2021/tokuyama21_interspeech.html|
|End-to-End Speech Translation via Cross-Modal Progressive Training|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ye21_interspeech.html|Spoken Machine Translation|https://www.isca-speech.org/archive/interspeech_2021/ye21_interspeech.html|
|ASR Posterior-Based Loss for Multi-Task End-to-End Speech Translation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ko21_interspeech.html|Spoken Machine Translation|https://www.isca-speech.org/archive/interspeech_2021/ko21_interspeech.html|
|Towards Simultaneous Machine Interpretation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/perezgonzalezdemartos21_interspeech.html|Spoken Machine Translation|https://www.isca-speech.org/archive/interspeech_2021/perezgonzalezdemartos21_interspeech.html|
|Lexical Modeling of ASR Errors for Robust Speech Translation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/martucci21_interspeech.html|Spoken Machine Translation|https://www.isca-speech.org/archive/interspeech_2021/martucci21_interspeech.html|
|Optimally Encoding Inductive Biases into the Transformer Improves End-to-End Speech Translation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/vyas21_interspeech.html|Spoken Machine Translation|https://www.isca-speech.org/archive/interspeech_2021/vyas21_interspeech.html|
|Effects of Feature Scaling and Fusion on Sign Language Translation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ananthanarayana21_interspeech.html|Spoken Machine Translation|https://www.isca-speech.org/archive/interspeech_2021/ananthanarayana21_interspeech.html|
|The ID R&D System Description for Short-Duration Speaker Verification Challenge 2021|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/alenin21_interspeech.html|SdSV Challenge 2021: Analysis and Exploration of New Ideas on Short-Duration Speaker Verification|https://www.isca-speech.org/archive/interspeech_2021/alenin21_interspeech.html|
|Integrating Frequency Translational Invariance in TDNNs and Frequency Positional Information in 2D ResNets to Enhance Speaker Verification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/thienpondt21_interspeech.html|SdSV Challenge 2021: Analysis and Exploration of New Ideas on Short-Duration Speaker Verification|https://www.isca-speech.org/archive/interspeech_2021/thienpondt21_interspeech.html|
|SdSVC Challenge 2021: Tips and Tricks to Boost the Short-Duration Speaker Verification System Performance|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/gusev21_interspeech.html|SdSV Challenge 2021: Analysis and Exploration of New Ideas on Short-Duration Speaker Verification|https://www.isca-speech.org/archive/interspeech_2021/gusev21_interspeech.html|
|Team02 Text-Independent Speaker Verification System for SdSV Challenge 2021|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kang21_interspeech.html|SdSV Challenge 2021: Analysis and Exploration of New Ideas on Short-Duration Speaker Verification|https://www.isca-speech.org/archive/interspeech_2021/kang21_interspeech.html|
|Our Learned Lessons from Cross-Lingual Speaker Verification: The CRMI-DKU System Description for the Short-Duration Speaker Verification Challenge 2021|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/qin21_interspeech.html|SdSV Challenge 2021: Analysis and Exploration of New Ideas on Short-Duration Speaker Verification|https://www.isca-speech.org/archive/interspeech_2021/qin21_interspeech.html|
|Investigation of IMU&Elevoc Submission for the Short-Duration Speaker Verification Challenge 2021|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21o_interspeech.html|SdSV Challenge 2021: Analysis and Exploration of New Ideas on Short-Duration Speaker Verification|https://www.isca-speech.org/archive/interspeech_2021/zhang21o_interspeech.html|
|The Sogou System for Short-Duration Speaker Verification Challenge 2021|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/yan21_interspeech.html|SdSV Challenge 2021: Analysis and Exploration of New Ideas on Short-Duration Speaker Verification|https://www.isca-speech.org/archive/interspeech_2021/yan21_interspeech.html|
|The SJTU System for Short-Duration Speaker Verification Challenge 2021|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/han21c_interspeech.html|SdSV Challenge 2021: Analysis and Exploration of New Ideas on Short-Duration Speaker Verification|https://www.isca-speech.org/archive/interspeech_2021/han21c_interspeech.html|
|Multi-Speaker Emotional Text-to-Speech Synthesizer|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/cho21_interspeech.html|Show and Tell 2|https://www.isca-speech.org/archive/interspeech_2021/cho21_interspeech.html|
|Live TV Subtitling Through Respeaking|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/prazak21_interspeech.html|Show and Tell 2|https://www.isca-speech.org/archive/interspeech_2021/prazak21_interspeech.html|
|Autonomous Robot for Measuring Room Impulse Responses|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/fragner21_interspeech.html|Show and Tell 2|https://www.isca-speech.org/archive/interspeech_2021/fragner21_interspeech.html|
|Expressive Robot Performance Based on Facial Motion Capture|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/beskow21_interspeech.html|Show and Tell 2|https://www.isca-speech.org/archive/interspeech_2021/beskow21_interspeech.html|
|ThemePro 2.0: Showcasing the Role of Thematic Progression in Engaging Human-Computer Interaction|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/dominguez21_interspeech.html|Show and Tell 2|https://www.isca-speech.org/archive/interspeech_2021/dominguez21_interspeech.html|
|Addressing Compliance in Call Centers with Entity Extraction|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/guruju21_interspeech.html|Show and Tell 2|https://www.isca-speech.org/archive/interspeech_2021/guruju21_interspeech.html|
|Audio Segmentation Based Conversational Silence Detection for Contact Center Calls|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/gogineni21_interspeech.html|Show and Tell 2|https://www.isca-speech.org/archive/interspeech_2021/gogineni21_interspeech.html|
|Reformulating DOVER-Lap Label Mapping as a Graph Partitioning Problem|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/raj21b_interspeech.html|Graph and End-to-End Learning for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/raj21b_interspeech.html|
|Graph Attention Networks for Anti-Spoofing|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/tak21_interspeech.html|Graph and End-to-End Learning for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/tak21_interspeech.html|
|Log-Likelihood-Ratio Cost Function as Objective Loss for Speaker Verification Systems|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/mingote21_interspeech.html|Graph and End-to-End Learning for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/mingote21_interspeech.html|
|Effective Phase Encoding for End-To-End Speaker Verification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/peng21c_interspeech.html|Graph and End-to-End Learning for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2021/peng21c_interspeech.html|
|Impact of Encoding and Segmentation Strategies on End-to-End Simultaneous Speech Translation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/nguyen21d_interspeech.html|Spoken Language Processing II|https://www.isca-speech.org/archive/interspeech_2021/nguyen21d_interspeech.html|
|Lost in Interpreting: Speech Translation from Source or Interpreter?|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/machacek21_interspeech.html|Spoken Language Processing II|https://www.isca-speech.org/archive/interspeech_2021/machacek21_interspeech.html|
|Active Speaker Detection as a Multi-Objective Optimization with Uncertainty-Based Multimodal Fusion|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/pouthier21_interspeech.html|Spoken Language Processing II|https://www.isca-speech.org/archive/interspeech_2021/pouthier21_interspeech.html|
|It’s Not What You Said, it’s How You Said it: Discriminative Perception of Speech as a Multichannel Communication System|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wallbridge21_interspeech.html|Spoken Language Processing II|https://www.isca-speech.org/archive/interspeech_2021/wallbridge21_interspeech.html|
|Extending the Fullband E-Model Towards Background Noise, Bursty Packet Loss, and Conversational Degradations|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/michael21_interspeech.html|Speech and Audio Analysis|https://www.isca-speech.org/archive/interspeech_2021/michael21_interspeech.html|
|ORCA-SLANG: An Automatic Multi-Stage Semi-Supervised Deep Learning Framework for Large-Scale Killer Whale Call Type Identification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/bergler21_interspeech.html|Speech and Audio Analysis|https://www.isca-speech.org/archive/interspeech_2021/bergler21_interspeech.html|
|Audiovisual Transfer Learning for Audio Tagging and Sound Event Detection|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/boes21_interspeech.html|Speech and Audio Analysis|https://www.isca-speech.org/archive/interspeech_2021/boes21_interspeech.html|
|Non-Intrusive Speech Quality Assessment with Transfer Learning and Subject-Specific Scaling|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/nessler21_interspeech.html|Speech and Audio Analysis|https://www.isca-speech.org/archive/interspeech_2021/nessler21_interspeech.html|
|Audio Retrieval with Natural Language Queries|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/oncescu21_interspeech.html|Speech and Audio Analysis|https://www.isca-speech.org/archive/interspeech_2021/oncescu21_interspeech.html|
|Bootstrap an End-to-End ASR System by Multilingual Training, Transfer Learning, Text-to-Text Mapping and Synthetic Audio|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/giollo21_interspeech.html|Cross/Multi-Lingual and Code-Switched ASR|https://www.isca-speech.org/archive/interspeech_2021/giollo21_interspeech.html|
|Efficient Weight Factorization for Multilingual Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/pham21_interspeech.html|Cross/Multi-Lingual and Code-Switched ASR|https://www.isca-speech.org/archive/interspeech_2021/pham21_interspeech.html|
|Unsupervised Cross-Lingual Representation Learning for Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/conneau21_interspeech.html|Cross/Multi-Lingual and Code-Switched ASR|https://www.isca-speech.org/archive/interspeech_2021/conneau21_interspeech.html|
|Language and Speaker-Independent Feature Transformation for End-to-End Multilingual Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/hayakawa21_interspeech.html|Cross/Multi-Lingual and Code-Switched ASR|https://www.isca-speech.org/archive/interspeech_2021/hayakawa21_interspeech.html|
|Using Large Self-Supervised Models for Low-Resource Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/n21_interspeech.html|Cross/Multi-Lingual and Code-Switched ASR|https://www.isca-speech.org/archive/interspeech_2021/n21_interspeech.html|
|Dual Script E2E Framework for Multilingual and Code-Switching ASR|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kumar21e_interspeech.html|Cross/Multi-Lingual and Code-Switched ASR|https://www.isca-speech.org/archive/interspeech_2021/kumar21e_interspeech.html|
|MUCS 2021: Multilingual and Code-Switching ASR Challenges for Low Resource Indian Languages|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/diwan21_interspeech.html|Cross/Multi-Lingual and Code-Switched ASR|https://www.isca-speech.org/archive/interspeech_2021/diwan21_interspeech.html|
|Adapt-and-Adjust: Overcoming the Long-Tail Problem of Multilingual Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/winata21_interspeech.html|Cross/Multi-Lingual and Code-Switched ASR|https://www.isca-speech.org/archive/interspeech_2021/winata21_interspeech.html|
|SRI-B End-to-End System for Multilingual and Code-Switching ASR Challenges for Low Resource Indian Languages|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/sailor21_interspeech.html|Cross/Multi-Lingual and Code-Switched ASR|https://www.isca-speech.org/archive/interspeech_2021/sailor21_interspeech.html|
|Hierarchical Phone Recognition with Compositional Phonetics|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/li21f_interspeech.html|Cross/Multi-Lingual and Code-Switched ASR|https://www.isca-speech.org/archive/interspeech_2021/li21f_interspeech.html|
|Towards One Model to Rule All: Multilingual Strategy for Dialectal Code-Switching Arabic ASR|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chowdhury21_interspeech.html|Cross/Multi-Lingual and Code-Switched ASR|https://www.isca-speech.org/archive/interspeech_2021/chowdhury21_interspeech.html|
|Differentiable Allophone Graphs for Language-Universal Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/yan21b_interspeech.html|Cross/Multi-Lingual and Code-Switched ASR|https://www.isca-speech.org/archive/interspeech_2021/yan21b_interspeech.html|
|Automatic Speech Recognition Systems Errors for Objective Sleepiness Detection Through Voice|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/martin21_interspeech.html|Health and Affect II|https://www.isca-speech.org/archive/interspeech_2021/martin21_interspeech.html|
|Robust Laughter Detection in Noisy Environments|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/gillick21_interspeech.html|Health and Affect II|https://www.isca-speech.org/archive/interspeech_2021/gillick21_interspeech.html|
|Impact of Emotional State on Estimation of Willingness to Buy from Advertising Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/nagano21_interspeech.html|Health and Affect II|https://www.isca-speech.org/archive/interspeech_2021/nagano21_interspeech.html|
|Stacked Recurrent Neural Networks for Speech-Based Inference of Attachment Condition in School Age Children|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/alsofyani21_interspeech.html|Health and Affect II|https://www.isca-speech.org/archive/interspeech_2021/alsofyani21_interspeech.html|
|Language or Paralanguage, This is the Problem: Comparing Depressed and Non-Depressed Speakers Through the Analysis of Gated Multimodal Units|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/aloshban21_interspeech.html|Health and Affect II|https://www.isca-speech.org/archive/interspeech_2021/aloshban21_interspeech.html|
|Emotion Carrier Recognition from Personal Narratives|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/tammewar21_interspeech.html|Health and Affect II|https://www.isca-speech.org/archive/interspeech_2021/tammewar21_interspeech.html|
|Non-Verbal Vocalisation and Laughter Detection Using Sequence-to-Sequence Models and Multi-Label Training|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/condron21_interspeech.html|Health and Affect II|https://www.isca-speech.org/archive/interspeech_2021/condron21_interspeech.html|
|TDCA-Net: Time-Domain Channel Attention Network for Depression Detection|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/cai21_interspeech.html|Health and Affect II|https://www.isca-speech.org/archive/interspeech_2021/cai21_interspeech.html|
|Visual Speech for Obstructive Sleep Apnea Detection|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/botelho21_interspeech.html|Health and Affect II|https://www.isca-speech.org/archive/interspeech_2021/botelho21_interspeech.html|
|Analysis of Contextual Voice Changes in Remote Meetings|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/maruri21_interspeech.html|Health and Affect II|https://www.isca-speech.org/archive/interspeech_2021/maruri21_interspeech.html|
|Speech Based Depression Severity Level Classification Using a Multi-Stage Dilated CNN-LSTM Model|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/seneviratne21_interspeech.html|Health and Affect II|https://www.isca-speech.org/archive/interspeech_2021/seneviratne21_interspeech.html|
|Multi-Domain Knowledge Distillation via Uncertainty-Matching for End-to-End ASR Models|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kim21g_interspeech.html|Neural Network Training Methods for ASR|https://www.isca-speech.org/archive/interspeech_2021/kim21g_interspeech.html|
|Learning a Neural Diff for Speech Models|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/macoskey21_interspeech.html|Neural Network Training Methods for ASR|https://www.isca-speech.org/archive/interspeech_2021/macoskey21_interspeech.html|
|Stochastic Attention Head Removal: A Simple and Effective Method for Improving Transformer Based ASR Models|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21p_interspeech.html|Neural Network Training Methods for ASR|https://www.isca-speech.org/archive/interspeech_2021/zhang21p_interspeech.html|
|Model-Agnostic Fast Adaptive Multi-Objective Balancing Algorithm for Multilingual Automatic Speech Recognition Model Training|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/xue21b_interspeech.html|Neural Network Training Methods for ASR|https://www.isca-speech.org/archive/interspeech_2021/xue21b_interspeech.html|
|Towards Lifelong Learning of End-to-End ASR|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chang21b_interspeech.html|Neural Network Training Methods for ASR|https://www.isca-speech.org/archive/interspeech_2021/chang21b_interspeech.html|
|Self-Adaptive Distillation for Multilingual Speech Recognition: Leveraging Student Independence|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/leal21_interspeech.html|Neural Network Training Methods for ASR|https://www.isca-speech.org/archive/interspeech_2021/leal21_interspeech.html|
|Regularizing Word Segmentation by Creating Misspellings|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/xu21f_interspeech.html|Neural Network Training Methods for ASR|https://www.isca-speech.org/archive/interspeech_2021/xu21f_interspeech.html|
|Multitask Training with Text Data for End-to-End Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21t_interspeech.html|Neural Network Training Methods for ASR|https://www.isca-speech.org/archive/interspeech_2021/wang21t_interspeech.html|
|Emitting Word Timings with HMM-Free End-to-End System in Automatic Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chen21j_interspeech.html|Neural Network Training Methods for ASR|https://www.isca-speech.org/archive/interspeech_2021/chen21j_interspeech.html|
|Scaling Laws for Acoustic Models|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/droppo21_interspeech.html|Neural Network Training Methods for ASR|https://www.isca-speech.org/archive/interspeech_2021/droppo21_interspeech.html|
|Leveraging Non-Target Language Resources to Improve ASR Performance in a Target Language|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/billa21_interspeech.html|Neural Network Training Methods for ASR|https://www.isca-speech.org/archive/interspeech_2021/billa21_interspeech.html|
|4-Bit Quantization of LSTM-Based Speech Recognition Models|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/fasoli21_interspeech.html|Neural Network Training Methods for ASR|https://www.isca-speech.org/archive/interspeech_2021/fasoli21_interspeech.html|
|Unified Autoregressive Modeling for Joint End-to-End Multi-Talker Overlapped Speech Recognition and Speaker Attribute Estimation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/masumura21_interspeech.html|Neural Network Training Methods for ASR|https://www.isca-speech.org/archive/interspeech_2021/masumura21_interspeech.html|
|Minimum Word Error Rate Training with Language Model Fusion for End-to-End Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/meng21_interspeech.html|Neural Network Training Methods for ASR|https://www.isca-speech.org/archive/interspeech_2021/meng21_interspeech.html|
|Variable Frame Rate Acoustic Models Using Minimum Error Reinforcement Learning|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/jiang21b_interspeech.html|Neural Network Training Methods for ASR|https://www.isca-speech.org/archive/interspeech_2021/jiang21b_interspeech.html|
|How f0 and Phrase Position Affect Papuan Malay Word Identification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kaland21_interspeech.html|Prosodic Features and Structure|https://www.isca-speech.org/archive/interspeech_2021/kaland21_interspeech.html|
|On the Feasibility of the Danish Model of Intonational Transcription: Phonetic Evidence from Jutlandic Danish|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/jespersen21_interspeech.html|Prosodic Features and Structure|https://www.isca-speech.org/archive/interspeech_2021/jespersen21_interspeech.html|
|An Experiment in Paratone Detection in a Prosodically Annotated EAP Spoken Corpus|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/meli21_interspeech.html|Prosodic Features and Structure|https://www.isca-speech.org/archive/interspeech_2021/meli21_interspeech.html|
|ProsoBeast Prosody Annotation Tool|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/gerazov21_interspeech.html|Prosodic Features and Structure|https://www.isca-speech.org/archive/interspeech_2021/gerazov21_interspeech.html|
|Assessing the Use of Prosody in Constituency Parsing of Imperfect Transcripts|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/tran21_interspeech.html|Prosodic Features and Structure|https://www.isca-speech.org/archive/interspeech_2021/tran21_interspeech.html|
|Targeted and Targetless Neutral Tones in Taiwanese Southern Min|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/liu21i_interspeech.html|Prosodic Features and Structure|https://www.isca-speech.org/archive/interspeech_2021/liu21i_interspeech.html|
|The Interaction of Word Complexity and Word Duration in an Agglutinative Language|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/gosy21_interspeech.html|Prosodic Features and Structure|https://www.isca-speech.org/archive/interspeech_2021/gosy21_interspeech.html|
|Taiwan Min Nan (Taiwanese) Checked Tones Sound Change|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/pan21b_interspeech.html|Prosodic Features and Structure|https://www.isca-speech.org/archive/interspeech_2021/pan21b_interspeech.html|
|In-Group Advantage in the Perception of Emotions: Evidence from Three Varieties of German|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/jakob21_interspeech.html|Prosodic Features and Structure|https://www.isca-speech.org/archive/interspeech_2021/jakob21_interspeech.html|
|The LF Model in the Frequency Domain for Glottal Airflow Modelling Without Aliasing Distortion|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/gobl21_interspeech.html|Prosodic Features and Structure|https://www.isca-speech.org/archive/interspeech_2021/gobl21_interspeech.html|
|Parsing Speech for Grouping and Prominence, and the Typology of Rhythm|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wagner21_interspeech.html|Prosodic Features and Structure|https://www.isca-speech.org/archive/interspeech_2021/wagner21_interspeech.html|
|Prosody of Case Markers in Urdu|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/mumtaz21_interspeech.html|Prosodic Features and Structure|https://www.isca-speech.org/archive/interspeech_2021/mumtaz21_interspeech.html|
|Articulatory Characteristics of Icelandic Voiced Fricative Lenition: Gradience, Categoricity, and Speaker/Gesture-Specific Effects|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/stefansdottir21_interspeech.html|Prosodic Features and Structure|https://www.isca-speech.org/archive/interspeech_2021/stefansdottir21_interspeech.html|
|Leveraging the Uniformity Framework to Examine Crosslinguistic Similarity for Long-Lag Stops in Spontaneous Cantonese-English Bilingual Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/johnson21_interspeech.html|Prosodic Features and Structure|https://www.isca-speech.org/archive/interspeech_2021/johnson21_interspeech.html|
|Personalized Speech Enhancement Through Self-Supervised Data Augmentation and Purification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/sivaraman21_interspeech.html|Single-Channel Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2021/sivaraman21_interspeech.html|
|Speech Denoising with Auditory Models|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/saddler21_interspeech.html|Single-Channel Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2021/saddler21_interspeech.html|
|Human Listening and Live Captioning: Multi-Task Training for Speech Enhancement|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/eskimez21b_interspeech.html|Single-Channel Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2021/eskimez21b_interspeech.html|
|Multi-Stage Progressive Speech Enhancement Network|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/xu21g_interspeech.html|Single-Channel Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2021/xu21g_interspeech.html|
|Single-Channel Speech Enhancement Using Learnable Loss Mixup|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chang21c_interspeech.html|Single-Channel Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2021/chang21c_interspeech.html|
|A Maximum Likelihood Approach to SNR-Progressive Learning Using Generalized Gaussian Distribution for LSTM-Based Speech Enhancement|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21q_interspeech.html|Single-Channel Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2021/zhang21q_interspeech.html|
|Whisper Speech Enhancement Using Joint Variational Autoencoder for Improved Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/agrawal21_interspeech.html|Single-Channel Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2021/agrawal21_interspeech.html|
|DEMUCS-Mobile : On-Device Lightweight Speech Enhancement|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lee21d_interspeech.html|Single-Channel Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2021/lee21d_interspeech.html|
|Speech Denoising Without Clean Training Data: A Noise2Noise Approach|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kashyap21_interspeech.html|Single-Channel Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2021/kashyap21_interspeech.html|
|Improved Speech Enhancement Using a Complex-Domain GAN with Fused Time-Domain and Time-Frequency Domain Constraints|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/dang21_interspeech.html|Single-Channel Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2021/dang21_interspeech.html|
|Speech Enhancement with Topology-Enhanced Generative Adversarial Networks (GANs)|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21r_interspeech.html|Single-Channel Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2021/zhang21r_interspeech.html|
|Learning Speech Structure to Improve Time-Frequency Masks|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/bu21_interspeech.html|Single-Channel Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2021/bu21_interspeech.html|
|SE-Conformer: Time-Domain Speech Enhancement Using Conformer|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kim21h_interspeech.html|Single-Channel Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2021/kim21h_interspeech.html|
|Spectral and Latent Speech Representation Distortion for TTS Evaluation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kongthaworn21_interspeech.html|Speech Synthesis: Tools, Data, Evaluation|https://www.isca-speech.org/archive/interspeech_2021/kongthaworn21_interspeech.html|
|Detection and Analysis of Attention Errors in Sequence-to-Sequence Text-to-Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/valentinibotinhao21_interspeech.html|Speech Synthesis: Tools, Data, Evaluation|https://www.isca-speech.org/archive/interspeech_2021/valentinibotinhao21_interspeech.html|
|RyanSpeech: A Corpus for Conversational Text-to-Speech Synthesis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zandie21_interspeech.html|Speech Synthesis: Tools, Data, Evaluation|https://www.isca-speech.org/archive/interspeech_2021/zandie21_interspeech.html|
|AISHELL-3: A Multi-Speaker Mandarin TTS Corpus|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/shi21c_interspeech.html|Speech Synthesis: Tools, Data, Evaluation|https://www.isca-speech.org/archive/interspeech_2021/shi21c_interspeech.html|
|Comparing Speech Enhancement Techniques for Voice Adaptation-Based Speech Synthesis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/eng21_interspeech.html|Speech Synthesis: Tools, Data, Evaluation|https://www.isca-speech.org/archive/interspeech_2021/eng21_interspeech.html|
|EMOVIE: A Mandarin Emotion Speech Dataset with a Simple Emotional Text-to-Speech Model|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/cui21c_interspeech.html|Speech Synthesis: Tools, Data, Evaluation|https://www.isca-speech.org/archive/interspeech_2021/cui21c_interspeech.html|
|Perception of Social Speaker Characteristics in Synthetic Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/rallabandi21_interspeech.html|Speech Synthesis: Tools, Data, Evaluation|https://www.isca-speech.org/archive/interspeech_2021/rallabandi21_interspeech.html|
|Hi-Fi Multi-Speaker English TTS Dataset|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/bakhturina21_interspeech.html|Speech Synthesis: Tools, Data, Evaluation|https://www.isca-speech.org/archive/interspeech_2021/bakhturina21_interspeech.html|
|Utilizing Self-Supervised Representations for MOS Prediction|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/tseng21b_interspeech.html|Speech Synthesis: Tools, Data, Evaluation|https://www.isca-speech.org/archive/interspeech_2021/tseng21b_interspeech.html|
|KazakhTTS: An Open-Source Kazakh Text-to-Speech Synthesis Dataset|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/mussakhojayeva21_interspeech.html|Speech Synthesis: Tools, Data, Evaluation|https://www.isca-speech.org/archive/interspeech_2021/mussakhojayeva21_interspeech.html|
|Confidence Intervals for ASR-Based TTS Evaluation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/taylor21_interspeech.html|Speech Synthesis: Tools, Data, Evaluation|https://www.isca-speech.org/archive/interspeech_2021/taylor21_interspeech.html|
|INTERSPEECH 2021 Deep Noise Suppression Challenge|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/reddy21_interspeech.html|INTERSPEECH 2021 Deep Noise Suppression Challenge|https://www.isca-speech.org/archive/interspeech_2021/reddy21_interspeech.html|
|A Simultaneous Denoising and Dereverberation Framework with Target Decoupling|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/li21g_interspeech.html|INTERSPEECH 2021 Deep Noise Suppression Challenge|https://www.isca-speech.org/archive/interspeech_2021/li21g_interspeech.html|
|Deep Noise Suppression with Non-Intrusive PESQNet Supervision Enabling the Use of Real Training Data|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/xu21h_interspeech.html|INTERSPEECH 2021 Deep Noise Suppression Challenge|https://www.isca-speech.org/archive/interspeech_2021/xu21h_interspeech.html|
|DPCRN: Dual-Path Convolution Recurrent Network for Single Channel Speech Enhancement|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/le21b_interspeech.html|INTERSPEECH 2021 Deep Noise Suppression Challenge|https://www.isca-speech.org/archive/interspeech_2021/le21b_interspeech.html|
|DCCRN+: Channel-Wise Subband DCCRN with SNR Estimation for Speech Enhancement|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lv21_interspeech.html|INTERSPEECH 2021 Deep Noise Suppression Challenge|https://www.isca-speech.org/archive/interspeech_2021/lv21_interspeech.html|
|DBNet: A Dual-Branch Network Architecture Processing on Spectrum and Waveform for Single-Channel Speech Enhancement|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21s_interspeech.html|INTERSPEECH 2021 Deep Noise Suppression Challenge|https://www.isca-speech.org/archive/interspeech_2021/zhang21s_interspeech.html|
|Low-Delay Speech Enhancement Using Perceptually Motivated Target and Loss|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21t_interspeech.html|INTERSPEECH 2021 Deep Noise Suppression Challenge|https://www.isca-speech.org/archive/interspeech_2021/zhang21t_interspeech.html|
|Lightweight Causal Transformer with Local Self-Attention for Real-Time Speech Enhancement|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/oostermeijer21_interspeech.html|INTERSPEECH 2021 Deep Noise Suppression Challenge|https://www.isca-speech.org/archive/interspeech_2021/oostermeijer21_interspeech.html|
|Self-Paced Ensemble Learning for Speech and Audio Classification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ristea21_interspeech.html|Neural Network Training Methods and Architectures for ASR|https://www.isca-speech.org/archive/interspeech_2021/ristea21_interspeech.html|
|Knowledge Distillation for Streaming Transformer–Transducer|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kojima21_interspeech.html|Neural Network Training Methods and Architectures for ASR|https://www.isca-speech.org/archive/interspeech_2021/kojima21_interspeech.html|
|Multi-Encoder Learning and Stream Fusion for Transformer-Based End-to-End Automatic Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lohrenz21_interspeech.html|Neural Network Training Methods and Architectures for ASR|https://www.isca-speech.org/archive/interspeech_2021/lohrenz21_interspeech.html|
|Conditional Independence for Pretext Task Selection in Self-Supervised Speech Representation Learning|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zaiem21_interspeech.html|Neural Network Training Methods and Architectures for ASR|https://www.isca-speech.org/archive/interspeech_2021/zaiem21_interspeech.html|
|Investigating Methods to Improve Language Model Integration for Attention-Based Encoder-Decoder ASR Models|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zeineldeen21_interspeech.html|Neural Network Training Methods and Architectures for ASR|https://www.isca-speech.org/archive/interspeech_2021/zeineldeen21_interspeech.html|
|Comparing CTC and LFMMI for Out-of-Domain Adaptation of wav2vec 2.0 Acoustic Model|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/vyas21b_interspeech.html|Neural Network Training Methods and Architectures for ASR|https://www.isca-speech.org/archive/interspeech_2021/vyas21b_interspeech.html|
|Speaker Attentive Speech Emotion Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/moine21_interspeech.html|Emotion and Sentiment Analysis I|https://www.isca-speech.org/archive/interspeech_2021/moine21_interspeech.html|
|Separation of Emotional and Reconstruction Embeddings on Ladder Network to Improve Speech Emotion Recognition Robustness in Noisy Conditions|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/leem21_interspeech.html|Emotion and Sentiment Analysis I|https://www.isca-speech.org/archive/interspeech_2021/leem21_interspeech.html|
|M3: MultiModal Masking Applied to Sentiment Analysis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/georgiou21_interspeech.html|Emotion and Sentiment Analysis I|https://www.isca-speech.org/archive/interspeech_2021/georgiou21_interspeech.html|
|The CSTR System for Multilingual and Code-Switching ASR Challenges for Low Resource Indian Languages|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/klejch21_interspeech.html|Linguistic Components in End-to-End ASR|https://www.isca-speech.org/archive/interspeech_2021/klejch21_interspeech.html|
|Acoustic Data-Driven Subword Modeling for End-to-End Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhou21d_interspeech.html|Linguistic Components in End-to-End ASR|https://www.isca-speech.org/archive/interspeech_2021/zhou21d_interspeech.html|
|Equivalence of Segmental and Neural Transducer Modeling: A Proof of Concept|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhou21e_interspeech.html|Linguistic Components in End-to-End ASR|https://www.isca-speech.org/archive/interspeech_2021/zhou21e_interspeech.html|
|Modeling Dialectal Variation for Swiss German Automatic Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/khosravani21_interspeech.html|Linguistic Components in End-to-End ASR|https://www.isca-speech.org/archive/interspeech_2021/khosravani21_interspeech.html|
|Out-of-Vocabulary Words Detection with Attention and CTC Alignments in an End-to-End ASR System|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/egorova21_interspeech.html|Linguistic Components in End-to-End ASR|https://www.isca-speech.org/archive/interspeech_2021/egorova21_interspeech.html|
|Training Hybrid Models on Noisy Transliterated Transcripts for Code-Switched Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wiesner21_interspeech.html|Linguistic Components in End-to-End ASR|https://www.isca-speech.org/archive/interspeech_2021/wiesner21_interspeech.html|
|Speech Intelligibility of Dysarthric Speech: Human Scores and Acoustic-Phonetic Features|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/xue21c_interspeech.html|Assessment of Pathological Speech and Language II|https://www.isca-speech.org/archive/interspeech_2021/xue21c_interspeech.html|
|Analyzing Short Term Dynamic Speech Features for Understanding Behavioral Traits of Children with Autism Spectrum Disorder|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kim21i_interspeech.html|Assessment of Pathological Speech and Language II|https://www.isca-speech.org/archive/interspeech_2021/kim21i_interspeech.html|
|Vocalization Recognition of People with Profound Intellectual and Multiple Disabilities (PIMD) Using Machine Learning Algorithms|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/jesko21_interspeech.html|Assessment of Pathological Speech and Language II|https://www.isca-speech.org/archive/interspeech_2021/jesko21_interspeech.html|
|Phonetic Complexity, Speech Accuracy and Intelligibility Assessment of Italian Dysarthric Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/fivela21_interspeech.html|Assessment of Pathological Speech and Language II|https://www.isca-speech.org/archive/interspeech_2021/fivela21_interspeech.html|
|Detection of Consonant Errors in Disordered Speech Based on Consonant-Vowel Segment Embedding|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ng21_interspeech.html|Assessment of Pathological Speech and Language II|https://www.isca-speech.org/archive/interspeech_2021/ng21_interspeech.html|
|Assessing Posterior-Based Mispronunciation Detection on Field-Collected Recordings from Child Speech Therapy Sessions|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/hair21_interspeech.html|Assessment of Pathological Speech and Language II|https://www.isca-speech.org/archive/interspeech_2021/hair21_interspeech.html|
|Identifying Cognitive Impairment Using Sentence Representation Vectors|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/mirheidari21_interspeech.html|Assessment of Pathological Speech and Language II|https://www.isca-speech.org/archive/interspeech_2021/mirheidari21_interspeech.html|
|Parental Spoken Scaffolding and Narrative Skills in Crowd-Sourced Storytelling Samples of Young Children|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/yue21b_interspeech.html|Assessment of Pathological Speech and Language II|https://www.isca-speech.org/archive/interspeech_2021/yue21b_interspeech.html|
|Uncertainty-Aware COVID-19 Detection from Imbalanced Sound Data|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/xia21_interspeech.html|Assessment of Pathological Speech and Language II|https://www.isca-speech.org/archive/interspeech_2021/xia21_interspeech.html|
|Unsupervised Domain Adaptation for Dysarthric Speech Detection via Domain Adversarial Training and Mutual Information Minimization|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21u_interspeech.html|Assessment of Pathological Speech and Language II|https://www.isca-speech.org/archive/interspeech_2021/wang21u_interspeech.html|
|Source and Vocal Tract Cues for Speech-Based Classification of Patients with Parkinson’s Disease and Healthy Subjects|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/bhattacharjee21_interspeech.html|Assessment of Pathological Speech and Language II|https://www.isca-speech.org/archive/interspeech_2021/bhattacharjee21_interspeech.html|
|CLAC: A Speech Corpus of Healthy English Speakers|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/haulcy21_interspeech.html|Assessment of Pathological Speech and Language II|https://www.isca-speech.org/archive/interspeech_2021/haulcy21_interspeech.html|
|Direct Multimodal Few-Shot Learning of Speech and Images|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/nortje21_interspeech.html|Multimodal Systems|https://www.isca-speech.org/archive/interspeech_2021/nortje21_interspeech.html|
|Talk, Don’t Write: A Study of Direct Speech-Based Image Retrieval|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/sanabria21_interspeech.html|Multimodal Systems|https://www.isca-speech.org/archive/interspeech_2021/sanabria21_interspeech.html|
|A Fast Discrete Two-Step Learning Hashing for Scalable Cross-Modal Retrieval|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhao21b_interspeech.html|Multimodal Systems|https://www.isca-speech.org/archive/interspeech_2021/zhao21b_interspeech.html|
|Cross-Modal Knowledge Distillation Method for Automatic Cued Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21v_interspeech.html|Multimodal Systems|https://www.isca-speech.org/archive/interspeech_2021/wang21v_interspeech.html|
|Attention-Based Keyword Localisation in Speech Using Visual Grounding|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/olaleye21_interspeech.html|Multimodal Systems|https://www.isca-speech.org/archive/interspeech_2021/olaleye21_interspeech.html|
|Evaluation of Audio-Visual Alignments in Visually Grounded Speech Models|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/khorrami21_interspeech.html|Multimodal Systems|https://www.isca-speech.org/archive/interspeech_2021/khorrami21_interspeech.html|
|Automatic Lip-Reading with Hierarchical Pyramidal Convolution and Self-Attention for Image Sequences with No Word Boundaries|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chen21k_interspeech.html|Multimodal Systems|https://www.isca-speech.org/archive/interspeech_2021/chen21k_interspeech.html|
|Cascaded Multilingual Audio-Visual Learning from Videos|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/rouditchenko21b_interspeech.html|Multimodal Systems|https://www.isca-speech.org/archive/interspeech_2021/rouditchenko21b_interspeech.html|
|LiRA: Learning Visual Speech Representations from Audio Through Self-Supervision|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ma21c_interspeech.html|Multimodal Systems|https://www.isca-speech.org/archive/interspeech_2021/ma21c_interspeech.html|
|End-to-End Audio-Visual Speech Recognition for Overlapping Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/rose21_interspeech.html|Multimodal Systems|https://www.isca-speech.org/archive/interspeech_2021/rose21_interspeech.html|
|Audio-Visual Multi-Talker Speech Recognition in a Cocktail Party|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wu21e_interspeech.html|Multimodal Systems|https://www.isca-speech.org/archive/interspeech_2021/wu21e_interspeech.html|
|Ultra Fast Speech Separation Model with Teacher Student Learning|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chen21l_interspeech.html|Source Separation I|https://www.isca-speech.org/archive/interspeech_2021/chen21l_interspeech.html|
|Group Delay Based Re-Weighted Sparse Recovery Algorithms for Robust and High-Resolution Source Separation in DOA Framework|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ali21_interspeech.html|Source Separation I|https://www.isca-speech.org/archive/interspeech_2021/ali21_interspeech.html|
|Continuous Speech Separation Using Speaker Inventory for Long Recording|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/han21d_interspeech.html|Source Separation I|https://www.isca-speech.org/archive/interspeech_2021/han21d_interspeech.html|
|Crossfire Conditional Generative Adversarial Networks for Singing Voice Extraction|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/yuan21_interspeech.html|Source Separation I|https://www.isca-speech.org/archive/interspeech_2021/yuan21_interspeech.html|
|End-to-End Speech Separation Using Orthogonal Representation in Complex and Real Time-Frequency Domain|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21w_interspeech.html|Source Separation I|https://www.isca-speech.org/archive/interspeech_2021/wang21w_interspeech.html|
|Efficient and Stable Adversarial Learning Using Unpaired Data for Unsupervised Multichannel Speech Separation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/nakagome21_interspeech.html|Source Separation I|https://www.isca-speech.org/archive/interspeech_2021/nakagome21_interspeech.html|
|Stabilizing Label Assignment for Speech Separation by Self-Supervised Pre-Training|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/huang21h_interspeech.html|Source Separation I|https://www.isca-speech.org/archive/interspeech_2021/huang21h_interspeech.html|
|Dual-Path Filter Network: Speaker-Aware Modeling for Speech Separation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21x_interspeech.html|Source Separation I|https://www.isca-speech.org/archive/interspeech_2021/wang21x_interspeech.html|
|Investigation of Practical Aspects of Single Channel Speech Separation for ASR|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wu21f_interspeech.html|Source Separation I|https://www.isca-speech.org/archive/interspeech_2021/wu21f_interspeech.html|
|Implicit Filter-and-Sum Network for End-to-End Multi-Channel Speech Separation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/luo21c_interspeech.html|Source Separation I|https://www.isca-speech.org/archive/interspeech_2021/luo21c_interspeech.html|
|Generalized Spatio-Temporal RNN Beamformer for Target Speech Separation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/xu21i_interspeech.html|Source Separation I|https://www.isca-speech.org/archive/interspeech_2021/xu21i_interspeech.html|
|End-to-End Neural Diarization: From Transformer to Conformer|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/liu21j_interspeech.html|Speaker Diarization I|https://www.isca-speech.org/archive/interspeech_2021/liu21j_interspeech.html|
|Three-Class Overlapped Speech Detection Using a Convolutional Recurrent Neural Network|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/jung21_interspeech.html|Speaker Diarization I|https://www.isca-speech.org/archive/interspeech_2021/jung21_interspeech.html|
|Online Speaker Diarization Equipped with Discriminative Modeling and Guided Inference|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wan21_interspeech.html|Speaker Diarization I|https://www.isca-speech.org/archive/interspeech_2021/wan21_interspeech.html|
|Semi-Supervised Training with Pseudo-Labeling for End-To-End Neural Diarization|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/takashima21_interspeech.html|Speaker Diarization I|https://www.isca-speech.org/archive/interspeech_2021/takashima21_interspeech.html|
|Adapting Speaker Embeddings for Speaker Diarisation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kwon21b_interspeech.html|Speaker Diarization I|https://www.isca-speech.org/archive/interspeech_2021/kwon21b_interspeech.html|
|Scenario-Dependent Speaker Diarization for DIHARD-III Challenge|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21y_interspeech.html|Speaker Diarization I|https://www.isca-speech.org/archive/interspeech_2021/wang21y_interspeech.html|
|End-To-End Speaker Segmentation for Overlap-Aware Resegmentation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/bredin21_interspeech.html|Speaker Diarization I|https://www.isca-speech.org/archive/interspeech_2021/bredin21_interspeech.html|
|Online Streaming End-to-End Neural Diarization Handling Overlapping Speech and Flexible Numbers of Speakers|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/xue21d_interspeech.html|Speaker Diarization I|https://www.isca-speech.org/archive/interspeech_2021/xue21d_interspeech.html|
|A Thousand Words are Worth More Than One Recording: Word-Embedding Based Speaker Change Detection|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/anidjar21_interspeech.html|Speaker Diarization I|https://www.isca-speech.org/archive/interspeech_2021/anidjar21_interspeech.html|
|Phrase Break Prediction with Bidirectional Encoder Representations in Japanese Text-to-Speech Synthesis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/futamata21_interspeech.html|Speech Synthesis: Prosody Modeling I|https://www.isca-speech.org/archive/interspeech_2021/futamata21_interspeech.html|
|Improving Multi-Speaker TTS Prosody Variance with a Residual Encoder and Normalizing Flows|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/vallesperez21_interspeech.html|Speech Synthesis: Prosody Modeling I|https://www.isca-speech.org/archive/interspeech_2021/vallesperez21_interspeech.html|
|Rich Prosody Diversity Modelling with Phone-Level Mixture Density Network|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/du21b_interspeech.html|Speech Synthesis: Prosody Modeling I|https://www.isca-speech.org/archive/interspeech_2021/du21b_interspeech.html|
|Phoneme Duration Modeling Using Speech Rhythm-Based Speaker Embeddings for Multi-Speaker Speech Synthesis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/fujita21_interspeech.html|Speech Synthesis: Prosody Modeling I|https://www.isca-speech.org/archive/interspeech_2021/fujita21_interspeech.html|
|Fine-Grained Prosody Modeling in Neural Speech Synthesis Using ToBI Representation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zou21_interspeech.html|Speech Synthesis: Prosody Modeling I|https://www.isca-speech.org/archive/interspeech_2021/zou21_interspeech.html|
|Intra-Sentential Speaking Rate Control in Neural Text-To-Speech for Automatic Dubbing|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/sharma21b_interspeech.html|Speech Synthesis: Prosody Modeling I|https://www.isca-speech.org/archive/interspeech_2021/sharma21b_interspeech.html|
|Applying the Information Bottleneck Principle to Prosodic Representation Learning|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21u_interspeech.html|Speech Synthesis: Prosody Modeling I|https://www.isca-speech.org/archive/interspeech_2021/zhang21u_interspeech.html|
|A Prototypical Network Approach for Evaluating Generated Emotional Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/baird21_interspeech.html|Speech Synthesis: Prosody Modeling I|https://www.isca-speech.org/archive/interspeech_2021/baird21_interspeech.html|
|A Simplified Model for the Vocal Tract of [s] with Inclined Incisors|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/yoshinaga21_interspeech.html|Speech Production II|https://www.isca-speech.org/archive/interspeech_2021/yoshinaga21_interspeech.html|
|Vocal-Tract Models to Visualize the Airstream of Human Breath and Droplets While Producing Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/arai21b_interspeech.html|Speech Production II|https://www.isca-speech.org/archive/interspeech_2021/arai21b_interspeech.html|
|Using Transposed Convolution for Articulatory-to-Acoustic Conversion from Real-Time MRI Data|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/tanji21_interspeech.html|Speech Production II|https://www.isca-speech.org/archive/interspeech_2021/tanji21_interspeech.html|
|Comparison Between Lumped-Mass Modeling and Flow Simulation of the Reed-Type Artificial Vocal Fold|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/inaam21_interspeech.html|Speech Production II|https://www.isca-speech.org/archive/interspeech_2021/inaam21_interspeech.html|
|Inhalations in Speech: Acoustic and Physiological Characteristics|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/werner21_interspeech.html|Speech Production II|https://www.isca-speech.org/archive/interspeech_2021/werner21_interspeech.html|
|Model-Based Exploration of Linking Between Vowel Articulatory Space and Acoustic Space|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/xu21j_interspeech.html|Speech Production II|https://www.isca-speech.org/archive/interspeech_2021/xu21j_interspeech.html|
|Take a Breath: Respiratory Sounds Improve Recollection in Synthetic Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/elmers21_interspeech.html|Speech Production II|https://www.isca-speech.org/archive/interspeech_2021/elmers21_interspeech.html|
|Modeling Sensorimotor Adaptation in Speech Through Alterations to Forward and Inverse Models|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chen21m_interspeech.html|Speech Production II|https://www.isca-speech.org/archive/interspeech_2021/chen21m_interspeech.html|
|Mixture of Orthogonal Sequences Made from Extended Time-Stretched Pulses Enables Measurement of Involuntary Voice Fundamental Frequency Response to Pitch Perturbation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kawahara21_interspeech.html|Speech Production II|https://www.isca-speech.org/archive/interspeech_2021/kawahara21_interspeech.html|
|Contextualized Attention-Based Knowledge Transfer for Spoken Conversational Question Answering|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/you21c_interspeech.html|Spoken Dialogue Systems II|https://www.isca-speech.org/archive/interspeech_2021/you21c_interspeech.html|
|Injecting Descriptive Meta-Information into Pre-Trained Language Models with Hypernetworks|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/duan21_interspeech.html|Spoken Dialogue Systems II|https://www.isca-speech.org/archive/interspeech_2021/duan21_interspeech.html|
|Causal Confusion Reduction for Robust Multi-Domain Dialogue Policy|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/rohmatillah21_interspeech.html|Spoken Dialogue Systems II|https://www.isca-speech.org/archive/interspeech_2021/rohmatillah21_interspeech.html|
|Timing Generating Networks: Neural Network Based Precise Turn-Taking Timing Prediction in Multiparty Conversation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/fujie21_interspeech.html|Spoken Dialogue Systems II|https://www.isca-speech.org/archive/interspeech_2021/fujie21_interspeech.html|
|Human-to-Human Conversation Dataset for Learning Fine-Grained Turn-Taking Action|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chen21n_interspeech.html|Spoken Dialogue Systems II|https://www.isca-speech.org/archive/interspeech_2021/chen21n_interspeech.html|
|PhonemeBERT: Joint Language Modelling of Phoneme Sequence and ASR Transcript|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/sundararaman21_interspeech.html|Spoken Dialogue Systems II|https://www.isca-speech.org/archive/interspeech_2021/sundararaman21_interspeech.html|
|Joint Retrieval-Extraction Training for Evidence-Aware Dialog Response Selection|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/luo21d_interspeech.html|Spoken Dialogue Systems II|https://www.isca-speech.org/archive/interspeech_2021/luo21d_interspeech.html|
|Adapting Long Context NLM for ASR Rescoring in Conversational Agents|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/shenoy21_interspeech.html|Spoken Dialogue Systems II|https://www.isca-speech.org/archive/interspeech_2021/shenoy21_interspeech.html|
|Oriental Language Recognition (OLR) 2020: Summary and Analysis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/li21h_interspeech.html|Oriental Language Recognition|https://www.isca-speech.org/archive/interspeech_2021/li21h_interspeech.html|
|Language Recognition on Unknown Conditions: The LORIA-Inria-MULTISPEECH System for AP20-OLR Challenge|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/duroselle21b_interspeech.html|Oriental Language Recognition|https://www.isca-speech.org/archive/interspeech_2021/duroselle21b_interspeech.html|
|Dynamic Multi-Scale Convolution for Dialect Identification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kong21b_interspeech.html|Oriental Language Recognition|https://www.isca-speech.org/archive/interspeech_2021/kong21b_interspeech.html|
|An End-to-End Dialect Identification System with Transfer Learning from a Multilingual Automatic Speech Recognition Model|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21z_interspeech.html|Oriental Language Recognition|https://www.isca-speech.org/archive/interspeech_2021/wang21z_interspeech.html|
|Language Recognition Based on Unsupervised Pretrained Models|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/yu21b_interspeech.html|Oriental Language Recognition|https://www.isca-speech.org/archive/interspeech_2021/yu21b_interspeech.html|
|Additive Phoneme-Aware Margin Softmax Loss for Language Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/li21i_interspeech.html|Oriental Language Recognition|https://www.isca-speech.org/archive/interspeech_2021/li21i_interspeech.html|
|Towards an Accent-Robust Approach for ATC Communications Transcription|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/jahchan21_interspeech.html|Automatic Speech Recognition in Air Traffic Management|https://www.isca-speech.org/archive/interspeech_2021/jahchan21_interspeech.html|
|Detecting English Speech in the Air Traffic Control Voice Communication|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/szoke21_interspeech.html|Automatic Speech Recognition in Air Traffic Management|https://www.isca-speech.org/archive/interspeech_2021/szoke21_interspeech.html|
|Robust Command Recognition for Lithuanian Air Traffic Control Tower Utterances|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ohneiser21_interspeech.html|Automatic Speech Recognition in Air Traffic Management|https://www.isca-speech.org/archive/interspeech_2021/ohneiser21_interspeech.html|
|Contextual Semi-Supervised Learning: An Approach to Leverage Air-Surveillance and Untranscribed ATC Data in ASR Systems|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zuluagagomez21_interspeech.html|Automatic Speech Recognition in Air Traffic Management|https://www.isca-speech.org/archive/interspeech_2021/zuluagagomez21_interspeech.html|
|Boosting of Contextual Information in ASR for Air-Traffic Call-Sign Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kocour21_interspeech.html|Automatic Speech Recognition in Air Traffic Management|https://www.isca-speech.org/archive/interspeech_2021/kocour21_interspeech.html|
|Modeling the Effect of Military Oxygen Masks on Speech Characteristics|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/elie21_interspeech.html|Automatic Speech Recognition in Air Traffic Management|https://www.isca-speech.org/archive/interspeech_2021/elie21_interspeech.html|
|MoM: Minutes of Meeting Bot|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/milde21_interspeech.html|Show and Tell 3|https://www.isca-speech.org/archive/interspeech_2021/milde21_interspeech.html|
|Articulatory Data Recorder: A Framework for Real-Time Articulatory Data Recording|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wilbrandt21_interspeech.html|Show and Tell 3|https://www.isca-speech.org/archive/interspeech_2021/wilbrandt21_interspeech.html|
|The INGENIOUS Multilingual Operations App|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/codinafilba21_interspeech.html|Show and Tell 3|https://www.isca-speech.org/archive/interspeech_2021/codinafilba21_interspeech.html|
|Digital Einstein Experience: Fast Text-to-Speech for Conversational AI|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/rownicka21_interspeech.html|Show and Tell 3|https://www.isca-speech.org/archive/interspeech_2021/rownicka21_interspeech.html|
|Live Subtitling for BigBlueButton with Open-Source Software|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/geislinger21_interspeech.html|Show and Tell 3|https://www.isca-speech.org/archive/interspeech_2021/geislinger21_interspeech.html|
|Expressive Latvian Speech Synthesis for Dialog Systems|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/nicmanis21_interspeech.html|Show and Tell 3|https://www.isca-speech.org/archive/interspeech_2021/nicmanis21_interspeech.html|
|ViSTAFAE: A Visual Speech-Training Aid with Feedback of Articulatory Efforts|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kachare21_interspeech.html|Show and Tell 3|https://www.isca-speech.org/archive/interspeech_2021/kachare21_interspeech.html|
|Learning Speech Models from Multi-Modal Data|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/livescu21_interspeech.html|Survey Talk 3: Karen Livescu|https://www.isca-speech.org/archive/interspeech_2021/livescu21_interspeech.html|
|Adaptive Listening to Everyday Soundscapes|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/elhilali21_interspeech.html|Keynote 3: Mounya Elhilali|https://www.isca-speech.org/archive/interspeech_2021/elhilali21_interspeech.html|
|Towards the Prediction of the Vocal Tract Shape from the Sequence of Phonemes to be Articulated|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ribeiro21b_interspeech.html|Speech Production I|https://www.isca-speech.org/archive/interspeech_2021/ribeiro21b_interspeech.html|
|Comparison of the Finite Element Method, the Multimodal Method and the Transmission-Line Model for the Computation of Vocal Tract Transfer Functions|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/blandin21_interspeech.html|Speech Production I|https://www.isca-speech.org/archive/interspeech_2021/blandin21_interspeech.html|
|Effects of Time Pressure and Spontaneity on Phonotactic Innovations in German Dialogues|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wagner21b_interspeech.html|Speech Production I|https://www.isca-speech.org/archive/interspeech_2021/wagner21b_interspeech.html|
|Importance of Parasagittal Sensor Information in Tongue Motion Capture Through a Diphonic Analysis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/medina21_interspeech.html|Speech Production I|https://www.isca-speech.org/archive/interspeech_2021/medina21_interspeech.html|
|Learning Robust Speech Representation with an Articulatory-Regularized Variational Autoencoder|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/georges21_interspeech.html|Speech Production I|https://www.isca-speech.org/archive/interspeech_2021/georges21_interspeech.html|
|Changes in Glottal Source Parameter Values with Light to Moderate Physical Load|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/weston21_interspeech.html|Speech Production I|https://www.isca-speech.org/archive/interspeech_2021/weston21_interspeech.html|
|End-to-End Optimized Multi-Stage Vector Quantization of Spectral Envelopes for Speech and Audio Coding|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/vali21_interspeech.html|Speech Enhancement and Coding|https://www.isca-speech.org/archive/interspeech_2021/vali21_interspeech.html|
|Fusion-Net: Time-Frequency Information Fusion Y-Network for Speech Enhancement|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/nareddula21_interspeech.html|Speech Enhancement and Coding|https://www.isca-speech.org/archive/interspeech_2021/nareddula21_interspeech.html|
|N-MTTL SI Model: Non-Intrusive Multi-Task Transfer Learning-Based Speech Intelligibility Prediction Model with Scenery Classification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/marcinek21_interspeech.html|Speech Enhancement and Coding|https://www.isca-speech.org/archive/interspeech_2021/marcinek21_interspeech.html|
|Temporal Context in Speech Emotion Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/xia21b_interspeech.html|Emotion and Sentiment Analysis II|https://www.isca-speech.org/archive/interspeech_2021/xia21b_interspeech.html|
|Learning Fine-Grained Cross Modality Excitement for Speech Emotion Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/li21j_interspeech.html|Emotion and Sentiment Analysis II|https://www.isca-speech.org/archive/interspeech_2021/li21j_interspeech.html|
|Automatic Analysis of the Emotional Content of Speech in Daylong Child-Centered Recordings from a Neonatal Intensive Care Unit|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/vaaras21_interspeech.html|Emotion and Sentiment Analysis II|https://www.isca-speech.org/archive/interspeech_2021/vaaras21_interspeech.html|
|Multimodal Sentiment Analysis with Temporal Modality Attention|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/qian21_interspeech.html|Emotion and Sentiment Analysis II|https://www.isca-speech.org/archive/interspeech_2021/qian21_interspeech.html|
|Stochastic Process Regression for Cross-Cultural Speech Emotion Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/t21_interspeech.html|Emotion and Sentiment Analysis II|https://www.isca-speech.org/archive/interspeech_2021/t21_interspeech.html|
|Acted vs. Improvised: Domain Adaptation for Elicitation Approaches in Audio-Visual Emotion Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/li21k_interspeech.html|Emotion and Sentiment Analysis II|https://www.isca-speech.org/archive/interspeech_2021/li21k_interspeech.html|
|Emotion Recognition from Speech Using wav2vec 2.0 Embeddings|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/pepino21_interspeech.html|Emotion and Sentiment Analysis II|https://www.isca-speech.org/archive/interspeech_2021/pepino21_interspeech.html|
|Graph Isomorphism Network for Speech Emotion Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/liu21k_interspeech.html|Emotion and Sentiment Analysis II|https://www.isca-speech.org/archive/interspeech_2021/liu21k_interspeech.html|
|Applying TDNN Architectures for Analyzing Duration Dependencies on Speech Emotion Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kumawat21_interspeech.html|Emotion and Sentiment Analysis II|https://www.isca-speech.org/archive/interspeech_2021/kumawat21_interspeech.html|
|Acoustic Features and Neural Representations for Categorical Emotion Recognition from Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/keesing21_interspeech.html|Emotion and Sentiment Analysis II|https://www.isca-speech.org/archive/interspeech_2021/keesing21_interspeech.html|
|Leveraging Pre-Trained Language Model for Speech Sentiment Analysis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/shon21_interspeech.html|Emotion and Sentiment Analysis II|https://www.isca-speech.org/archive/interspeech_2021/shon21_interspeech.html|
|Cross-Domain Speech Recognition with Unsupervised Character-Level Distribution Matching|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/hou21b_interspeech.html|Multi- and Cross-Lingual ASR, Other Topics in ASR|https://www.isca-speech.org/archive/interspeech_2021/hou21b_interspeech.html|
|Large-Scale Pre-Training of End-to-End Multi-Talker ASR for Meeting Transcription with Single Distant Microphone|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kanda21_interspeech.html|Multi- and Cross-Lingual ASR, Other Topics in ASR|https://www.isca-speech.org/archive/interspeech_2021/kanda21_interspeech.html|
|On Minimum Word Error Rate Training of the Hybrid Autoregressive Transducer|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lu21b_interspeech.html|Multi- and Cross-Lingual ASR, Other Topics in ASR|https://www.isca-speech.org/archive/interspeech_2021/lu21b_interspeech.html|
|Reducing Streaming ASR Model Delay with Self Alignment|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kim21j_interspeech.html|Multi- and Cross-Lingual ASR, Other Topics in ASR|https://www.isca-speech.org/archive/interspeech_2021/kim21j_interspeech.html|
|Reduce and Reconstruct: ASR for Low-Resource Phonetic Languages|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/diwan21b_interspeech.html|Multi- and Cross-Lingual ASR, Other Topics in ASR|https://www.isca-speech.org/archive/interspeech_2021/diwan21b_interspeech.html|
|Knowledge Distillation Based Training of Universal ASR Source Models for Cross-Lingual Transfer|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/fukuda21_interspeech.html|Multi- and Cross-Lingual ASR, Other Topics in ASR|https://www.isca-speech.org/archive/interspeech_2021/fukuda21_interspeech.html|
|Listen with Intent: Improving Speech Recognition with Audio-to-Intent Front-End|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ray21_interspeech.html|Multi- and Cross-Lingual ASR, Other Topics in ASR|https://www.isca-speech.org/archive/interspeech_2021/ray21_interspeech.html|
|Exploring Targeted Universal Adversarial Perturbations to End-to-End ASR Models|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lu21c_interspeech.html|Multi- and Cross-Lingual ASR, Other Topics in ASR|https://www.isca-speech.org/archive/interspeech_2021/lu21c_interspeech.html|
|Earnings-21: A Practical Benchmark for ASR in the Wild|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/delrio21_interspeech.html|Multi- and Cross-Lingual ASR, Other Topics in ASR|https://www.isca-speech.org/archive/interspeech_2021/delrio21_interspeech.html|
|Improving Multilingual Transformer Transducer Models by Reducing Language Confusions|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/sun21c_interspeech.html|Multi- and Cross-Lingual ASR, Other Topics in ASR|https://www.isca-speech.org/archive/interspeech_2021/sun21c_interspeech.html|
|Arabic Code-Switching Speech Recognition Using Monolingual Data|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ali21b_interspeech.html|Multi- and Cross-Lingual ASR, Other Topics in ASR|https://www.isca-speech.org/archive/interspeech_2021/ali21b_interspeech.html|
|Online Blind Audio Source Separation Using Recursive Expectation-Maximization|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/eisenberg21_interspeech.html|Source Separation II|https://www.isca-speech.org/archive/interspeech_2021/eisenberg21_interspeech.html|
|Empirical Analysis of Generalized Iterative Speech Separation Networks|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/luo21e_interspeech.html|Source Separation II|https://www.isca-speech.org/archive/interspeech_2021/luo21e_interspeech.html|
|Graph-PIT: Generalized Permutation Invariant Training for Continuous Separation of Arbitrary Numbers of Speakers|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/neumann21_interspeech.html|Source Separation II|https://www.isca-speech.org/archive/interspeech_2021/neumann21_interspeech.html|
|Teacher-Student MixIT for Unsupervised and Semi-Supervised Speech Separation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21v_interspeech.html|Source Separation II|https://www.isca-speech.org/archive/interspeech_2021/zhang21v_interspeech.html|
|Few-Shot Learning of New Sound Classes for Target Sound Extraction|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/delcroix21_interspeech.html|Source Separation II|https://www.isca-speech.org/archive/interspeech_2021/delcroix21_interspeech.html|
|Binaural Speech Separation of Moving Speakers With Preserved Spatial Cues|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/han21e_interspeech.html|Source Separation II|https://www.isca-speech.org/archive/interspeech_2021/han21e_interspeech.html|
|AvaTr: One-Shot Speaker Extraction with Transformers|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/hu21_interspeech.html|Source Separation II|https://www.isca-speech.org/archive/interspeech_2021/hu21_interspeech.html|
|Vocal Harmony Separation Using Time-Domain Neural Networks|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/sarkar21_interspeech.html|Source Separation II|https://www.isca-speech.org/archive/interspeech_2021/sarkar21_interspeech.html|
|Speaker Verification-Based Evaluation of Single-Channel Speech Separation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/maciejewski21_interspeech.html|Source Separation II|https://www.isca-speech.org/archive/interspeech_2021/maciejewski21_interspeech.html|
|Improved Speech Separation with Time-and-Frequency Cross-Domain Feature Selection|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lan21_interspeech.html|Source Separation II|https://www.isca-speech.org/archive/interspeech_2021/lan21_interspeech.html|
|Robust Speaker Extraction Network Based on Iterative Refined Adaptation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/deng21c_interspeech.html|Source Separation II|https://www.isca-speech.org/archive/interspeech_2021/deng21c_interspeech.html|
|Neural Speaker Extraction with Speaker-Speech Cross-Attention Network|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21aa_interspeech.html|Source Separation II|https://www.isca-speech.org/archive/interspeech_2021/wang21aa_interspeech.html|
|Deep Audio-Visual Speech Separation Based on Facial Motion|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/rigal21_interspeech.html|Source Separation II|https://www.isca-speech.org/archive/interspeech_2021/rigal21_interspeech.html|
|LEAP Submission for the Third DIHARD Diarization Challenge|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/singh21_interspeech.html|Speaker Diarization II|https://www.isca-speech.org/archive/interspeech_2021/singh21_interspeech.html|
|Investigation of Spatial-Acoustic Features for Overlapping Speech Detection in Multiparty Meetings|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21w_interspeech.html|Speaker Diarization II|https://www.isca-speech.org/archive/interspeech_2021/zhang21w_interspeech.html|
|Target-Speaker Voice Activity Detection with Improved i-Vector Estimation for Unknown Number of Speaker|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/he21c_interspeech.html|Speaker Diarization II|https://www.isca-speech.org/archive/interspeech_2021/he21c_interspeech.html|
|ECAPA-TDNN Embeddings for Speaker Diarization|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/dawalatabad21_interspeech.html|Speaker Diarization II|https://www.isca-speech.org/archive/interspeech_2021/dawalatabad21_interspeech.html|
|Advances in Integration of End-to-End Neural and Clustering-Based Diarization for Real Conversational Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kinoshita21_interspeech.html|Speaker Diarization II|https://www.isca-speech.org/archive/interspeech_2021/kinoshita21_interspeech.html|
|The Third DIHARD Diarization Challenge|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ryant21_interspeech.html|Speaker Diarization II|https://www.isca-speech.org/archive/interspeech_2021/ryant21_interspeech.html|
|Robust End-to-End Speaker Diarization with Conformer and Additive Margin Penalty|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/leung21_interspeech.html|Speaker Diarization II|https://www.isca-speech.org/archive/interspeech_2021/leung21_interspeech.html|
|Anonymous Speaker Clusters: Making Distinctions Between Anonymised Speech Recordings with Clustering Interface|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/obrien21_interspeech.html|Speaker Diarization II|https://www.isca-speech.org/archive/interspeech_2021/obrien21_interspeech.html|
|Speaker Diarization Using Two-Pass Leave-One-Out Gaussian PLDA Clustering of DNN Embeddings|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/karra21_interspeech.html|Speaker Diarization II|https://www.isca-speech.org/archive/interspeech_2021/karra21_interspeech.html|
|Federated Learning with Dynamic Transformer for Text to Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/hong21_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis I|https://www.isca-speech.org/archive/interspeech_2021/hong21_interspeech.html|
|LiteTTS: A Lightweight Mel-Spectrogram-Free Text-to-Wave Synthesizer Based on Generative Adversarial Networks|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/nguyen21e_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis I|https://www.isca-speech.org/archive/interspeech_2021/nguyen21e_interspeech.html|
|Zero-Shot Text-to-Speech for Text-Based Insertion in Audio Narration|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/tang21b_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis I|https://www.isca-speech.org/archive/interspeech_2021/tang21b_interspeech.html|
|Diff-TTS: A Denoising Diffusion Model for Text-to-Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/jeong21_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis I|https://www.isca-speech.org/archive/interspeech_2021/jeong21_interspeech.html|
|Hierarchical Context-Aware Transformers for Non-Autoregressive Text to Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/bae21_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis I|https://www.isca-speech.org/archive/interspeech_2021/bae21_interspeech.html|
|Speech Resynthesis from Discrete Disentangled Self-Supervised Representations|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/polyak21_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis I|https://www.isca-speech.org/archive/interspeech_2021/polyak21_interspeech.html|
|A Learned Conditional Prior for the VAE Acoustic Space of a TTS System|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/karanasou21_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis I|https://www.isca-speech.org/archive/interspeech_2021/karanasou21_interspeech.html|
|A Universal Multi-Speaker Multi-Style Text-to-Speech via Disentangled Representation Learning Based on Rényi Divergence Minimization|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/paul21_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis I|https://www.isca-speech.org/archive/interspeech_2021/paul21_interspeech.html|
|Relational Data Selection for Data Augmentation of Speaker-Dependent Multi-Band MelGAN Vocoder|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wu21g_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis I|https://www.isca-speech.org/archive/interspeech_2021/wu21g_interspeech.html|
|Reinforce-Aligner: Reinforcement Alignment Search for Robust End-to-End Text-to-Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chung21_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis I|https://www.isca-speech.org/archive/interspeech_2021/chung21_interspeech.html|
|Triple M: A Practical Text-to-Speech Synthesis System with Multi-Guidance Attention and Multi-Band Multi-Time LPCNet|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lin21g_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis I|https://www.isca-speech.org/archive/interspeech_2021/lin21g_interspeech.html|
|SC-GlowTTS: An Efficient Zero-Shot Multi-Speaker Text-To-Speech Model|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/casanova21b_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis I|https://www.isca-speech.org/archive/interspeech_2021/casanova21b_interspeech.html|
|Spoken ObjectNet: A Bias-Controlled Spoken Caption Dataset|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/palmer21_interspeech.html|Tools, Corpora and Resources|https://www.isca-speech.org/archive/interspeech_2021/palmer21_interspeech.html|
|The Multilingual TEDx Corpus for Speech Recognition and Translation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/salesky21_interspeech.html|Tools, Corpora and Resources|https://www.isca-speech.org/archive/interspeech_2021/salesky21_interspeech.html|
|Tusom2021: A Phonetically Transcribed Speech Dataset from an Endangered Language for Universal Phone Recognition Experiments|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/mortensen21_interspeech.html|Tools, Corpora and Resources|https://www.isca-speech.org/archive/interspeech_2021/mortensen21_interspeech.html|
|AISHELL-4: An Open Source Dataset for Speech Enhancement, Separation, Recognition and Speaker Diarization in Conference Scenario|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/fu21b_interspeech.html|Tools, Corpora and Resources|https://www.isca-speech.org/archive/interspeech_2021/fu21b_interspeech.html|
|GigaSpeech: An Evolving, Multi-Domain ASR Corpus with 10,000 Hours of Transcribed Audio|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chen21o_interspeech.html|Tools, Corpora and Resources|https://www.isca-speech.org/archive/interspeech_2021/chen21o_interspeech.html|
|Look Who’s Talking: Active Speaker Detection in the Wild|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kim21k_interspeech.html|Tools, Corpora and Resources|https://www.isca-speech.org/archive/interspeech_2021/kim21k_interspeech.html|
|AusKidTalk: An Auditory-Visual Corpus of 3- to 12-Year-Old Australian Children’s Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ahmed21_interspeech.html|Tools, Corpora and Resources|https://www.isca-speech.org/archive/interspeech_2021/ahmed21_interspeech.html|
|Human-in-the-Loop Efficiency Analysis for Binary Classification in Edyson|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/fallgren21_interspeech.html|Tools, Corpora and Resources|https://www.isca-speech.org/archive/interspeech_2021/fallgren21_interspeech.html|
|Annotation Confidence vs. Training Sample Size: Trade-Off Solution for Partially-Continuous Categorical Emotion Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ryumina21_interspeech.html|Tools, Corpora and Resources|https://www.isca-speech.org/archive/interspeech_2021/ryumina21_interspeech.html|
|Europarl-ASR: A Large Corpus of Parliamentary Debates for Streaming ASR Benchmarking and Speech Data Filtering/Verbatimization|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/garcesdiazmunio21_interspeech.html|Tools, Corpora and Resources|https://www.isca-speech.org/archive/interspeech_2021/garcesdiazmunio21_interspeech.html|
|Towards Automatic Speech to Sign Language Generation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kapoor21_interspeech.html|Tools, Corpora and Resources|https://www.isca-speech.org/archive/interspeech_2021/kapoor21_interspeech.html|
|kosp2e: Korean Speech to English Translation Corpus|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/cho21b_interspeech.html|Tools, Corpora and Resources|https://www.isca-speech.org/archive/interspeech_2021/cho21b_interspeech.html|
|speechocean762: An Open-Source Non-Native English Speech Corpus for Pronunciation Assessment|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21x_interspeech.html|Tools, Corpora and Resources|https://www.isca-speech.org/archive/interspeech_2021/zhang21x_interspeech.html|
|An Improved Single Step Non-Autoregressive Transformer for Automatic Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/fan21b_interspeech.html|Non-Autoregressive Sequential Modeling for Speech Processing|https://www.isca-speech.org/archive/interspeech_2021/fan21b_interspeech.html|
|Multi-Speaker ASR Combining Non-Autoregressive Conformer CTC and Conditional Speaker Chain|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/guo21_interspeech.html|Non-Autoregressive Sequential Modeling for Speech Processing|https://www.isca-speech.org/archive/interspeech_2021/guo21_interspeech.html|
|Pushing the Limits of Non-Autoregressive Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ng21b_interspeech.html|Non-Autoregressive Sequential Modeling for Speech Processing|https://www.isca-speech.org/archive/interspeech_2021/ng21b_interspeech.html|
|Non-Autoregressive Predictive Coding for Learning Speech Representations from Local Dependencies|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/liu21l_interspeech.html|Non-Autoregressive Sequential Modeling for Speech Processing|https://www.isca-speech.org/archive/interspeech_2021/liu21l_interspeech.html|
|Relaxing the Conditional Independence Assumption of CTC-Based ASR by Conditioning on Intermediate Predictions|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/nozaki21_interspeech.html|Non-Autoregressive Sequential Modeling for Speech Processing|https://www.isca-speech.org/archive/interspeech_2021/nozaki21_interspeech.html|
|Toward Streaming ASR with Non-Autoregressive Insertion-Based Model|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/fujita21b_interspeech.html|Non-Autoregressive Sequential Modeling for Speech Processing|https://www.isca-speech.org/archive/interspeech_2021/fujita21b_interspeech.html|
|Layer Pruning on Demand with Intermediate CTC|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lee21e_interspeech.html|Non-Autoregressive Sequential Modeling for Speech Processing|https://www.isca-speech.org/archive/interspeech_2021/lee21e_interspeech.html|
|Real-Time End-to-End Monaural Multi-Speaker Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/li21l_interspeech.html|Non-Autoregressive Sequential Modeling for Speech Processing|https://www.isca-speech.org/archive/interspeech_2021/li21l_interspeech.html|
|Streaming End-to-End ASR Based on Blockwise Non-Autoregressive Models|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21ba_interspeech.html|Non-Autoregressive Sequential Modeling for Speech Processing|https://www.isca-speech.org/archive/interspeech_2021/wang21ba_interspeech.html|
|TalkNet: Non-Autoregressive Depth-Wise Separable Convolutional Model for Speech Synthesis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/beliaev21_interspeech.html|Non-Autoregressive Sequential Modeling for Speech Processing|https://www.isca-speech.org/archive/interspeech_2021/beliaev21_interspeech.html|
|WaveGrad 2: Iterative Refinement for Text-to-Speech Synthesis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chen21p_interspeech.html|Non-Autoregressive Sequential Modeling for Speech Processing|https://www.isca-speech.org/archive/interspeech_2021/chen21p_interspeech.html|
|Align-Denoise: Single-Pass Non-Autoregressive Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chen21q_interspeech.html|Non-Autoregressive Sequential Modeling for Speech Processing|https://www.isca-speech.org/archive/interspeech_2021/chen21q_interspeech.html|
|VAENAR-TTS: Variational Auto-Encoder Based Non-AutoRegressive Text-to-Speech Synthesis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lu21d_interspeech.html|Non-Autoregressive Sequential Modeling for Speech Processing|https://www.isca-speech.org/archive/interspeech_2021/lu21d_interspeech.html|
|Detecting Cognitive Decline Using Speech Only: The ADReSSo Challenge|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/luz21_interspeech.html|The ADReSSo Challenge: Detecting Cognitive Decline Using Speech Only|https://www.isca-speech.org/archive/interspeech_2021/luz21_interspeech.html|
|Influence of the Interviewer on the Automatic Assessment of Alzheimer’s Disease in the Context of the ADReSSo Challenge|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/pereztoro21_interspeech.html|The ADReSSo Challenge: Detecting Cognitive Decline Using Speech Only|https://www.isca-speech.org/archive/interspeech_2021/pereztoro21_interspeech.html|
|WavBERT: Exploiting Semantic and Non-Semantic Speech Using Wav2vec and BERT for Dementia Detection|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhu21e_interspeech.html|The ADReSSo Challenge: Detecting Cognitive Decline Using Speech Only|https://www.isca-speech.org/archive/interspeech_2021/zhu21e_interspeech.html|
|Alzheimer Disease Recognition Using Speech-Based Embeddings From Pre-Trained Models|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/gauder21_interspeech.html|The ADReSSo Challenge: Detecting Cognitive Decline Using Speech Only|https://www.isca-speech.org/archive/interspeech_2021/gauder21_interspeech.html|
|Comparing Acoustic-Based Approaches for Alzheimer’s Disease Detection|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/balagopalan21_interspeech.html|The ADReSSo Challenge: Detecting Cognitive Decline Using Speech Only|https://www.isca-speech.org/archive/interspeech_2021/balagopalan21_interspeech.html|
|Alzheimer’s Disease Detection from Spontaneous Speech Through Combining Linguistic Complexity and (Dis)Fluency Features with Pretrained Language Models|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/qiao21_interspeech.html|The ADReSSo Challenge: Detecting Cognitive Decline Using Speech Only|https://www.isca-speech.org/archive/interspeech_2021/qiao21_interspeech.html|
|Using the Outputs of Different Automatic Speech Recognition Paradigms for Acoustic- and BERT-Based Alzheimer’s Dementia Detection Through Spontaneous Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/pan21c_interspeech.html|The ADReSSo Challenge: Detecting Cognitive Decline Using Speech Only|https://www.isca-speech.org/archive/interspeech_2021/pan21c_interspeech.html|
|Tackling the ADRESSO Challenge 2021: The MUET-RMIT System for Alzheimer’s Dementia Recognition from Spontaneous Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/syed21_interspeech.html|The ADReSSo Challenge: Detecting Cognitive Decline Using Speech Only|https://www.isca-speech.org/archive/interspeech_2021/syed21_interspeech.html|
|Alzheimer’s Dementia Recognition Using Acoustic, Lexical, Disfluency and Speech Pause Features Robust to Noisy Inputs|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/rohanian21_interspeech.html|The ADReSSo Challenge: Detecting Cognitive Decline Using Speech Only|https://www.isca-speech.org/archive/interspeech_2021/rohanian21_interspeech.html|
|Automatic Detection and Assessment of Alzheimer Disease Using Speech and Language Technologies in Low-Resource Scenarios|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/pappagari21_interspeech.html|The ADReSSo Challenge: Detecting Cognitive Decline Using Speech Only|https://www.isca-speech.org/archive/interspeech_2021/pappagari21_interspeech.html|
|Automatic Detection of Alzheimer’s Disease Using Spontaneous Speech Only|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chen21r_interspeech.html|The ADReSSo Challenge: Detecting Cognitive Decline Using Speech Only|https://www.isca-speech.org/archive/interspeech_2021/chen21r_interspeech.html|
|Modular Multi-Modal Attention Network for Alzheimer’s Disease Detection Using Patient Audio and Language Data|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21ca_interspeech.html|The ADReSSo Challenge: Detecting Cognitive Decline Using Speech Only|https://www.isca-speech.org/archive/interspeech_2021/wang21ca_interspeech.html|
|Self-Attention Channel Combinator Frontend for End-to-End Multichannel Far-Field Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/gong21d_interspeech.html|Robust and Far-Field ASR|https://www.isca-speech.org/archive/interspeech_2021/gong21d_interspeech.html|
|ETLT 2021: Shared Task on Automatic Speech Recognition for Non-Native Children’s Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/gretter21_interspeech.html|Robust and Far-Field ASR|https://www.isca-speech.org/archive/interspeech_2021/gretter21_interspeech.html|
|Age-Invariant Training for End-to-End Child Speech Recognition Using Adversarial Multi-Task Learning|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/rumberg21_interspeech.html|Robust and Far-Field ASR|https://www.isca-speech.org/archive/interspeech_2021/rumberg21_interspeech.html|
|Learning to Rank Microphones for Distant Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/cornell21_interspeech.html|Robust and Far-Field ASR|https://www.isca-speech.org/archive/interspeech_2021/cornell21_interspeech.html|
|Simulating Reading Mistakes for Child Speech Transformer-Based Phone Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/gelin21_interspeech.html|Robust and Far-Field ASR|https://www.isca-speech.org/archive/interspeech_2021/gelin21_interspeech.html|
|Alternate Endings: Improving Prosody for Incremental Neural TTS with Predicted Future Text Input|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/stephenson21_interspeech.html|Speech Synthesis: Prosody Modeling II|https://www.isca-speech.org/archive/interspeech_2021/stephenson21_interspeech.html|
|Exploring Emotional Prototypes in a High Dimensional TTS Latent Space|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/rijn21_interspeech.html|Speech Synthesis: Prosody Modeling II|https://www.isca-speech.org/archive/interspeech_2021/rijn21_interspeech.html|
|Ctrl-P: Temporal Control of Prosodic Variation for Speech Synthesis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/mohan21_interspeech.html|Speech Synthesis: Prosody Modeling II|https://www.isca-speech.org/archive/interspeech_2021/mohan21_interspeech.html|
|ADEPT: A Dataset for Evaluating Prosody Transfer|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/torresquintero21_interspeech.html|Speech Synthesis: Prosody Modeling II|https://www.isca-speech.org/archive/interspeech_2021/torresquintero21_interspeech.html|
|Prosodic Boundary Prediction Model for Vietnamese Text-To-Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/trang21_interspeech.html|Speech Synthesis: Prosody Modeling II|https://www.isca-speech.org/archive/interspeech_2021/trang21_interspeech.html|
|Many-Speakers Single Channel Speech Separation with Optimal Permutation Training|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/dovrat21_interspeech.html|Source Separation III|https://www.isca-speech.org/archive/interspeech_2021/dovrat21_interspeech.html|
|Combating Reverberation in NTF-Based Speech Separation Using a Sub-Source Weighted Multichannel Wiener Filter and Linear Prediction|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/fras21_interspeech.html|Source Separation III|https://www.isca-speech.org/archive/interspeech_2021/fras21_interspeech.html|
|A Hands-On Comparison of DNNs for Dialog Separation Using Transfer Learning from Music Source Separation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/strauss21_interspeech.html|Source Separation III|https://www.isca-speech.org/archive/interspeech_2021/strauss21_interspeech.html|
|GlobalPhone Mix-To-Separate Out of 2: A Multilingual 2000 Speakers Mixtures Database for Speech Separation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/borsdorf21b_interspeech.html|Source Separation III|https://www.isca-speech.org/archive/interspeech_2021/borsdorf21b_interspeech.html|
|Cross-Linguistic Perception of the Japanese Singleton/Geminate Contrast: Korean, Mandarin and Mongolian Compared|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/tsukada21_interspeech.html|Non-Native Speech|https://www.isca-speech.org/archive/interspeech_2021/tsukada21_interspeech.html|
|Detection of Lexical Stress Errors in Non-Native (L2) English with Data Augmentation and Attention|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/korzekwa21_interspeech.html|Non-Native Speech|https://www.isca-speech.org/archive/interspeech_2021/korzekwa21_interspeech.html|
|Testing Acoustic Voice Quality Classification Across Languages and Speech Styles|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/braun21_interspeech.html|Non-Native Speech|https://www.isca-speech.org/archive/interspeech_2021/braun21_interspeech.html|
|Acquisition of Prosodic Focus Marking by Three- to Six-Year-Old Children Learning Mandarin Chinese|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21y_interspeech.html|Non-Native Speech|https://www.isca-speech.org/archive/interspeech_2021/zhang21y_interspeech.html|
|Adaptive Listening Difficulty Detection for L2 Learners Through Moderating ASR Resources|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/mirzaei21_interspeech.html|Non-Native Speech|https://www.isca-speech.org/archive/interspeech_2021/mirzaei21_interspeech.html|
|F0 Patterns of L2 English Speech by Mandarin Chinese Learners|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ding21b_interspeech.html|Non-Native Speech|https://www.isca-speech.org/archive/interspeech_2021/ding21b_interspeech.html|
|A Neural Network-Based Noise Compensation Method for Pronunciation Assessment|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lin21h_interspeech.html|Non-Native Speech|https://www.isca-speech.org/archive/interspeech_2021/lin21h_interspeech.html|
|Phonetic Distance and Surprisal in Multilingual Priming: Evidence from Slavic|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kudera21_interspeech.html|Non-Native Speech|https://www.isca-speech.org/archive/interspeech_2021/kudera21_interspeech.html|
|A Preliminary Study on Discourse Prosody Encoding in L1 and L2 English Spontaneous Narratives|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21z_interspeech.html|Non-Native Speech|https://www.isca-speech.org/archive/interspeech_2021/zhang21z_interspeech.html|
|Transformer Based End-to-End Mispronunciation Detection and Diagnosis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wu21h_interspeech.html|Non-Native Speech|https://www.isca-speech.org/archive/interspeech_2021/wu21h_interspeech.html|
|L1 Identification from L2 Speech Using Neural Spectrogram Analysis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/graham21_interspeech.html|Non-Native Speech|https://www.isca-speech.org/archive/interspeech_2021/graham21_interspeech.html|
|Leveraging Real-Time MRI for Illuminating Linguistic Velum Action|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/oh21b_interspeech.html|Phonetics II|https://www.isca-speech.org/archive/interspeech_2021/oh21b_interspeech.html|
|Segmental Alignment of English Syllables with Singleton and Cluster Onsets|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/liu21m_interspeech.html|Phonetics II|https://www.isca-speech.org/archive/interspeech_2021/liu21m_interspeech.html|
|Exploration of Welsh English Pre-Aspiration: How Wide-Spread is it?|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/hejna21_interspeech.html|Phonetics II|https://www.isca-speech.org/archive/interspeech_2021/hejna21_interspeech.html|
|Revisiting Recall Effects of Filler Particles in German and English|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/muhlack21_interspeech.html|Phonetics II|https://www.isca-speech.org/archive/interspeech_2021/muhlack21_interspeech.html|
|How Reliable Are Phonetic Data Collected Remotely? Comparison of Recording Devices and Environments on Acoustic Measurements|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ge21b_interspeech.html|Phonetics II|https://www.isca-speech.org/archive/interspeech_2021/ge21b_interspeech.html|
|A Cross-Dialectal Comparison of Apical Vowels in Beijing Mandarin, Northeastern Mandarin and Southwestern Mandarin: An EMA and Ultrasound Study|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/huang21i_interspeech.html|Phonetics II|https://www.isca-speech.org/archive/interspeech_2021/huang21i_interspeech.html|
|Dissecting the Aero-Acoustic Parameters of Open Articulatory Transitions|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/gibson21_interspeech.html|Phonetics II|https://www.isca-speech.org/archive/interspeech_2021/gibson21_interspeech.html|
|Quantifying Vocal Tract Shape Variation and its Acoustic Impact: A Geometric Morphometric Approach|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/gully21_interspeech.html|Phonetics II|https://www.isca-speech.org/archive/interspeech_2021/gully21_interspeech.html|
|Speech Perception and Loanword Adaptations: The Case of Copy-Vowel Epenthesis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/guevararukoz21_interspeech.html|Phonetics II|https://www.isca-speech.org/archive/interspeech_2021/guevararukoz21_interspeech.html|
|Speakers Coarticulate Less When Facing Real and Imagined Communicative Difficulties: An Analysis of Read and Spontaneous Speech from the LUCID Corpus|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/guo21b_interspeech.html|Phonetics II|https://www.isca-speech.org/archive/interspeech_2021/guo21b_interspeech.html|
|Developmental Changes of Vowel Acoustics in Adolescents|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/meister21_interspeech.html|Phonetics II|https://www.isca-speech.org/archive/interspeech_2021/meister21_interspeech.html|
|Context and Co-Text Influence on the Accuracy Production of Italian L2 Non-Native Sounds|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/dapolito21_interspeech.html|Phonetics II|https://www.isca-speech.org/archive/interspeech_2021/dapolito21_interspeech.html|
|A New Vowel Normalization for Sociophonetics|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/heeringa21_interspeech.html|Phonetics II|https://www.isca-speech.org/archive/interspeech_2021/heeringa21_interspeech.html|
|The Pacific Expansion: Optimizing Phonetic Transcription of Archival Corpora|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/billington21_interspeech.html|Phonetics II|https://www.isca-speech.org/archive/interspeech_2021/billington21_interspeech.html|
|FSR: Accelerating the Inference Process of Transducer-Based Models by Applying Fast-Skip Regularization|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/tian21_interspeech.html|Search/Decoding Techniques and Confidence Measures for ASR|https://www.isca-speech.org/archive/interspeech_2021/tian21_interspeech.html|
|LT-LM: A Novel Non-Autoregressive Language Model for Single-Shot Lattice Rescoring|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/mitrofanov21_interspeech.html|Search/Decoding Techniques and Confidence Measures for ASR|https://www.isca-speech.org/archive/interspeech_2021/mitrofanov21_interspeech.html|
|A Hybrid Seq-2-Seq ASR Design for On-Device and Server Applications|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/allauzen21_interspeech.html|Search/Decoding Techniques and Confidence Measures for ASR|https://www.isca-speech.org/archive/interspeech_2021/allauzen21_interspeech.html|
|VAD-Free Streaming Hybrid CTC/Attention ASR for Unsegmented Recording|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/inaguma21b_interspeech.html|Search/Decoding Techniques and Confidence Measures for ASR|https://www.isca-speech.org/archive/interspeech_2021/inaguma21b_interspeech.html|
|WeNet: Production Oriented Streaming and Non-Streaming End-to-End Speech Recognition Toolkit|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/yao21_interspeech.html|Search/Decoding Techniques and Confidence Measures for ASR|https://www.isca-speech.org/archive/interspeech_2021/yao21_interspeech.html|
|Cross-Modal Transformer-Based Neural Correction Models for Automatic Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/tanaka21b_interspeech.html|Search/Decoding Techniques and Confidence Measures for ASR|https://www.isca-speech.org/archive/interspeech_2021/tanaka21b_interspeech.html|
|Deep Neural Network Calibration for E2E Speech Recognition System|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lee21f_interspeech.html|Search/Decoding Techniques and Confidence Measures for ASR|https://www.isca-speech.org/archive/interspeech_2021/lee21f_interspeech.html|
|Residual Energy-Based Models for End-to-End Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/li21m_interspeech.html|Search/Decoding Techniques and Confidence Measures for ASR|https://www.isca-speech.org/archive/interspeech_2021/li21m_interspeech.html|
|Multi-Task Learning for End-to-End ASR Word and Utterance Confidence with Deletion Prediction|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/qiu21b_interspeech.html|Search/Decoding Techniques and Confidence Measures for ASR|https://www.isca-speech.org/archive/interspeech_2021/qiu21b_interspeech.html|
|Insights on Neural Representations for End-to-End Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ollerenshaw21_interspeech.html|Search/Decoding Techniques and Confidence Measures for ASR|https://www.isca-speech.org/archive/interspeech_2021/ollerenshaw21_interspeech.html|
|Sequence-Level Confidence Classifier for ASR Utterance Accuracy and Application to Acoustic Models|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/afshan21_interspeech.html|Search/Decoding Techniques and Confidence Measures for ASR|https://www.isca-speech.org/archive/interspeech_2021/afshan21_interspeech.html|
|Unsupervised Learning of Disentangled Speech Content and Style Representation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/tjandra21_interspeech.html|Speech Synthesis: Linguistic Processing, Paradigms and Other Topics|https://www.isca-speech.org/archive/interspeech_2021/tjandra21_interspeech.html|
|Label Embedding for Chinese Grapheme-to-Phoneme Conversion|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/choi21_interspeech.html|Speech Synthesis: Linguistic Processing, Paradigms and Other Topics|https://www.isca-speech.org/archive/interspeech_2021/choi21_interspeech.html|
|PDF: Polyphone Disambiguation in Chinese by Using FLAT|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21aa_interspeech.html|Speech Synthesis: Linguistic Processing, Paradigms and Other Topics|https://www.isca-speech.org/archive/interspeech_2021/zhang21aa_interspeech.html|
|Improving Polyphone Disambiguation for Mandarin Chinese by Combining Mix-Pooling Strategy and Window-Based Attention|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/li21n_interspeech.html|Speech Synthesis: Linguistic Processing, Paradigms and Other Topics|https://www.isca-speech.org/archive/interspeech_2021/li21n_interspeech.html|
|Polyphone Disambiguation in Mandarin Chinese with Semi-Supervised Learning|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/shi21d_interspeech.html|Speech Synthesis: Linguistic Processing, Paradigms and Other Topics|https://www.isca-speech.org/archive/interspeech_2021/shi21d_interspeech.html|
|A Neural-Network-Based Approach to Identifying Speakers in Novels|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chen21s_interspeech.html|Speech Synthesis: Linguistic Processing, Paradigms and Other Topics|https://www.isca-speech.org/archive/interspeech_2021/chen21s_interspeech.html|
|UnitNet-Based Hybrid Speech Synthesis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhou21f_interspeech.html|Speech Synthesis: Linguistic Processing, Paradigms and Other Topics|https://www.isca-speech.org/archive/interspeech_2021/zhou21f_interspeech.html|
|Dynamically Adaptive Machine Speech Chain Inference for TTS in Noisy Environment: Listen and Speak Louder|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/novitasari21_interspeech.html|Speech Synthesis: Linguistic Processing, Paradigms and Other Topics|https://www.isca-speech.org/archive/interspeech_2021/novitasari21_interspeech.html|
|LinearSpeech: Parallel Text-to-Speech with Linear Complexity|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21ba_interspeech.html|Speech Synthesis: Linguistic Processing, Paradigms and Other Topics|https://www.isca-speech.org/archive/interspeech_2021/zhang21ba_interspeech.html|
|An Agent for Competing with Humans in a Deceptive Game Based on Vocal Cues|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/mansbach21_interspeech.html|Speech Type Classification and Diagnosis|https://www.isca-speech.org/archive/interspeech_2021/mansbach21_interspeech.html|
|A Multi-Branch Deep Learning Network for Automated Detection of COVID-19|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/fakhry21_interspeech.html|Speech Type Classification and Diagnosis|https://www.isca-speech.org/archive/interspeech_2021/fakhry21_interspeech.html|
|RW-Resnet: A Novel Speech Anti-Spoofing Model Using Raw Waveform|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ma21d_interspeech.html|Speech Type Classification and Diagnosis|https://www.isca-speech.org/archive/interspeech_2021/ma21d_interspeech.html|
|Fake Audio Detection in Resource-Constrained Settings Using Microfeatures|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/dhamyal21_interspeech.html|Speech Type Classification and Diagnosis|https://www.isca-speech.org/archive/interspeech_2021/dhamyal21_interspeech.html|
|Coughing-Based Recognition of Covid-19 with Spatial Attentive ConvLSTM Recurrent Neural Networks|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/yan21c_interspeech.html|Speech Type Classification and Diagnosis|https://www.isca-speech.org/archive/interspeech_2021/yan21c_interspeech.html|
|Knowledge Distillation for Singing Voice Detection|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/paul21b_interspeech.html|Speech Type Classification and Diagnosis|https://www.isca-speech.org/archive/interspeech_2021/paul21b_interspeech.html|
|Age Estimation with Speech-Age Model for Heterogeneous Speech Datasets|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/takeda21_interspeech.html|Speech Type Classification and Diagnosis|https://www.isca-speech.org/archive/interspeech_2021/takeda21_interspeech.html|
|Open-Set Audio Classification with Limited Training Resources Based on Augmentation Enhanced Variational Auto-Encoder GAN with Detection-Classification Joint Training|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/teh21_interspeech.html|Speech Type Classification and Diagnosis|https://www.isca-speech.org/archive/interspeech_2021/teh21_interspeech.html|
|Deep Spectral-Cepstral Fusion for Shouted and Normal Speech Classification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/fukumori21_interspeech.html|Speech Type Classification and Diagnosis|https://www.isca-speech.org/archive/interspeech_2021/fukumori21_interspeech.html|
|Automatic Detection of Shouted Speech Segments in Indian News Debates|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/baghel21_interspeech.html|Speech Type Classification and Diagnosis|https://www.isca-speech.org/archive/interspeech_2021/baghel21_interspeech.html|
|Generalized Spoofing Detection Inspired from Audio Generation Artifacts|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/gao21c_interspeech.html|Speech Type Classification and Diagnosis|https://www.isca-speech.org/archive/interspeech_2021/gao21c_interspeech.html|
|Overlapped Speech Detection Based on Spectral and Spatial Feature Fusion|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chen21t_interspeech.html|Speech Type Classification and Diagnosis|https://www.isca-speech.org/archive/interspeech_2021/chen21t_interspeech.html|
|Do Acoustic Word Embeddings Capture Phonological Similarity? An Empirical Study|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/abdullah21_interspeech.html|Spoken Term Detection & Voice Search|https://www.isca-speech.org/archive/interspeech_2021/abdullah21_interspeech.html|
|Paraphrase Label Alignment for Voice Application Retrieval in Spoken Language Understanding|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/gao21d_interspeech.html|Spoken Term Detection & Voice Search|https://www.isca-speech.org/archive/interspeech_2021/gao21d_interspeech.html|
|Personalized Keyphrase Detection Using Speaker and Environment Information|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/rikhye21_interspeech.html|Spoken Term Detection & Voice Search|https://www.isca-speech.org/archive/interspeech_2021/rikhye21_interspeech.html|
|Streaming Transformer for Hardware Efficient Voice Trigger Detection and False Trigger Mitigation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/garg21_interspeech.html|Spoken Term Detection & Voice Search|https://www.isca-speech.org/archive/interspeech_2021/garg21_interspeech.html|
|Few-Shot Keyword Spotting in Any Language|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/mazumder21_interspeech.html|Spoken Term Detection & Voice Search|https://www.isca-speech.org/archive/interspeech_2021/mazumder21_interspeech.html|
|Text Anchor Based Metric Learning for Small-Footprint Keyword Spotting|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21da_interspeech.html|Spoken Term Detection & Voice Search|https://www.isca-speech.org/archive/interspeech_2021/wang21da_interspeech.html|
|A Meta-Learning Approach for User-Defined Spoken Term Classification with Varying Classes and Examples|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chen21u_interspeech.html|Spoken Term Detection & Voice Search|https://www.isca-speech.org/archive/interspeech_2021/chen21u_interspeech.html|
|Auxiliary Sequence Labeling Tasks for Disfluency Detection|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lee21g_interspeech.html|Spoken Term Detection & Voice Search|https://www.isca-speech.org/archive/interspeech_2021/lee21g_interspeech.html|
|Energy-Friendly Keyword Spotting System Using Add-Based Convolution|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhou21g_interspeech.html|Spoken Term Detection & Voice Search|https://www.isca-speech.org/archive/interspeech_2021/zhou21g_interspeech.html|
|The 2020 Personalized Voice Trigger Challenge: Open Datasets, Evaluation Metrics, Baseline System and Results|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/jia21b_interspeech.html|Spoken Term Detection & Voice Search|https://www.isca-speech.org/archive/interspeech_2021/jia21b_interspeech.html|
|Auto-KWS 2021 Challenge: Task, Datasets, and Baselines|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21ea_interspeech.html|Spoken Term Detection & Voice Search|https://www.isca-speech.org/archive/interspeech_2021/wang21ea_interspeech.html|
|Keyword Transformer: A Self-Attention Model for Keyword Spotting|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/berg21_interspeech.html|Spoken Term Detection & Voice Search|https://www.isca-speech.org/archive/interspeech_2021/berg21_interspeech.html|
|Teaching Keyword Spotters to Spot New Keywords with Limited Examples|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/awasthi21_interspeech.html|Spoken Term Detection & Voice Search|https://www.isca-speech.org/archive/interspeech_2021/awasthi21_interspeech.html|
|A Comparative Study on Recent Neural Spoofing Countermeasures for Synthetic Speech Detection|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21fa_interspeech.html|Voice Anti-Spoofing and Countermeasure|https://www.isca-speech.org/archive/interspeech_2021/wang21fa_interspeech.html|
|An Initial Investigation for Detecting Partially Spoofed Audio|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21ca_interspeech.html|Voice Anti-Spoofing and Countermeasure|https://www.isca-speech.org/archive/interspeech_2021/zhang21ca_interspeech.html|
|Siamese Network with wav2vec Feature for Spoofing Speech Detection|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/xie21_interspeech.html|Voice Anti-Spoofing and Countermeasure|https://www.isca-speech.org/archive/interspeech_2021/xie21_interspeech.html|
|Cross-Database Replay Detection in Terminal-Dependent Speaker Verification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/cheng21b_interspeech.html|Voice Anti-Spoofing and Countermeasure|https://www.isca-speech.org/archive/interspeech_2021/cheng21b_interspeech.html|
|The Effect of Silence and Dual-Band Fusion in Anti-Spoofing System|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21da_interspeech.html|Voice Anti-Spoofing and Countermeasure|https://www.isca-speech.org/archive/interspeech_2021/zhang21da_interspeech.html|
|Pairing Weak with Strong: Twin Models for Defending Against Adversarial Attack on Speaker Verification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/peng21d_interspeech.html|Voice Anti-Spoofing and Countermeasure|https://www.isca-speech.org/archive/interspeech_2021/peng21d_interspeech.html|
|Attention-Based Convolutional Neural Network for ASV Spoofing Detection|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ling21_interspeech.html|Voice Anti-Spoofing and Countermeasure|https://www.isca-speech.org/archive/interspeech_2021/ling21_interspeech.html|
|Voting for the Right Answer: Adversarial Defense for Speaker Verification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wu21i_interspeech.html|Voice Anti-Spoofing and Countermeasure|https://www.isca-speech.org/archive/interspeech_2021/wu21i_interspeech.html|
|Visualizing Classifier Adjacency Relations: A Case Study in Speaker Verification and Voice Anti-Spoofing|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kinnunen21_interspeech.html|Voice Anti-Spoofing and Countermeasure|https://www.isca-speech.org/archive/interspeech_2021/kinnunen21_interspeech.html|
|Representation Learning to Classify and Detect Adversarial Attacks Against Speaker and Speech Recognition Systems|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/villalba21_interspeech.html|Voice Anti-Spoofing and Countermeasure|https://www.isca-speech.org/archive/interspeech_2021/villalba21_interspeech.html|
|An Empirical Study on Channel Effects for Synthetic Voice Spoofing Countermeasure Systems|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21ea_interspeech.html|Voice Anti-Spoofing and Countermeasure|https://www.isca-speech.org/archive/interspeech_2021/zhang21ea_interspeech.html|
|Channel-Wise Gated Res2Net: Towards Robust Detection of Synthetic Speech Attacks|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/li21o_interspeech.html|Voice Anti-Spoofing and Countermeasure|https://www.isca-speech.org/archive/interspeech_2021/li21o_interspeech.html|
|Partially-Connected Differentiable Architecture Search for Deepfake and Spoofing Detection|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ge21c_interspeech.html|Voice Anti-Spoofing and Countermeasure|https://www.isca-speech.org/archive/interspeech_2021/ge21c_interspeech.html|
|OpenASR20: An Open Challenge for Automatic Speech Recognition of Conversational Telephone Speech in Low-Resource Languages|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/peterson21_interspeech.html|OpenASR20 and Low Resource ASR Development|https://www.isca-speech.org/archive/interspeech_2021/peterson21_interspeech.html|
|Multitask Adaptation with Lattice-Free MMI for Multi-Genre Speech Recognition of Low Resource Languages|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/madikeri21_interspeech.html|OpenASR20 and Low Resource ASR Development|https://www.isca-speech.org/archive/interspeech_2021/madikeri21_interspeech.html|
|An Improved Wav2Vec 2.0 Pre-Training Approach Using Enhanced Local Dependency Modeling for Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhu21f_interspeech.html|OpenASR20 and Low Resource ASR Development|https://www.isca-speech.org/archive/interspeech_2021/zhu21f_interspeech.html|
|Systems for Low-Resource Speech Recognition Tasks in Open Automatic Speech Recognition and Formosa Speech Recognition Challenges|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lin21i_interspeech.html|OpenASR20 and Low Resource ASR Development|https://www.isca-speech.org/archive/interspeech_2021/lin21i_interspeech.html|
|The TNT Team System Descriptions of Cantonese and Mongolian for IARPA OpenASR20|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhao21c_interspeech.html|OpenASR20 and Low Resource ASR Development|https://www.isca-speech.org/archive/interspeech_2021/zhao21c_interspeech.html|
|Combining Hybrid and End-to-End Approaches for the OpenASR20 Challenge|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/alumae21_interspeech.html|OpenASR20 and Low Resource ASR Development|https://www.isca-speech.org/archive/interspeech_2021/alumae21_interspeech.html|
|One Size Does Not Fit All in Resource-Constrained ASR|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/morris21_interspeech.html|OpenASR20 and Low Resource ASR Development|https://www.isca-speech.org/archive/interspeech_2021/morris21_interspeech.html|
|Child Language Acquisition Studied with Wearables|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/cristia21_interspeech.html|Survey Talk 4: Alejandrina Cristia|https://www.isca-speech.org/archive/interspeech_2021/cristia21_interspeech.html|
|Language Modeling and Artificial Intelligence|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/mikolov21_interspeech.html|Keynote 4: Tomáš Mikolov|https://www.isca-speech.org/archive/interspeech_2021/mikolov21_interspeech.html|
|Unsupervised Representation Learning for Speech Activity Detection in the Fearless Steps Challenge 2021|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/gimeno21_interspeech.html|Voice Activity Detection|https://www.isca-speech.org/archive/interspeech_2021/gimeno21_interspeech.html|
|The Application of Learnable STRF Kernels to the 2021 Fearless Steps Phase-03 SAD Challenge|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/vuong21_interspeech.html|Voice Activity Detection|https://www.isca-speech.org/archive/interspeech_2021/vuong21_interspeech.html|
|Speech Activity Detection Based on Multilingual Speech Recognition System|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/sarfjoo21_interspeech.html|Voice Activity Detection|https://www.isca-speech.org/archive/interspeech_2021/sarfjoo21_interspeech.html|
|Voice Activity Detection with Teacher-Student Domain Emulation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/luckenbaugh21_interspeech.html|Voice Activity Detection|https://www.isca-speech.org/archive/interspeech_2021/luckenbaugh21_interspeech.html|
|EML Online Speech Activity Detection for the Fearless Steps Challenge Phase-III|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ghahabi21_interspeech.html|Voice Activity Detection|https://www.isca-speech.org/archive/interspeech_2021/ghahabi21_interspeech.html|
|Device Playback Augmentation with Echo Cancellation for Keyword Spotting|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/opatka21_interspeech.html|Keyword Search and Spoken Language Processing|https://www.isca-speech.org/archive/interspeech_2021/opatka21_interspeech.html|
|End-to-End Open Vocabulary Keyword Search|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/yusuf21_interspeech.html|Keyword Search and Spoken Language Processing|https://www.isca-speech.org/archive/interspeech_2021/yusuf21_interspeech.html|
|Semantic Sentence Similarity: Size does not Always Matter|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/merkx21_interspeech.html|Keyword Search and Spoken Language Processing|https://www.isca-speech.org/archive/interspeech_2021/merkx21_interspeech.html|
|Spoken Term Detection and Relevance Score Estimation Using Dot-Product of Pronunciation Embeddings|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/svec21_interspeech.html|Keyword Search and Spoken Language Processing|https://www.isca-speech.org/archive/interspeech_2021/svec21_interspeech.html|
|Toward Genre Adapted Closed Captioning|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/buet21_interspeech.html|Keyword Search and Spoken Language Processing|https://www.isca-speech.org/archive/interspeech_2021/buet21_interspeech.html|
|Weakly-Supervised Word-Level Pronunciation Error Detection in Non-Native English Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/korzekwa21b_interspeech.html|Applications in Transcription, Education and Learning|https://www.isca-speech.org/archive/interspeech_2021/korzekwa21b_interspeech.html|
|End-to-End Speaker-Attributed ASR with Transformer|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kanda21b_interspeech.html|Applications in Transcription, Education and Learning|https://www.isca-speech.org/archive/interspeech_2021/kanda21b_interspeech.html|
|Understanding Medical Conversations: Rich Transcription, Confidence Scores & Information Extraction|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/soltau21_interspeech.html|Applications in Transcription, Education and Learning|https://www.isca-speech.org/archive/interspeech_2021/soltau21_interspeech.html|
|Phone-Level Pronunciation Scoring for Spanish Speakers Learning English Using a GOP-DNN System|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/vidal21_interspeech.html|Applications in Transcription, Education and Learning|https://www.isca-speech.org/archive/interspeech_2021/vidal21_interspeech.html|
|Explore wav2vec 2.0 for Mispronunciation Detection|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/xu21k_interspeech.html|Applications in Transcription, Education and Learning|https://www.isca-speech.org/archive/interspeech_2021/xu21k_interspeech.html|
|Lexical Density Analysis of Word Productions in Japanese English Using Acoustic Word Embeddings|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ando21_interspeech.html|Applications in Transcription, Education and Learning|https://www.isca-speech.org/archive/interspeech_2021/ando21_interspeech.html|
|Deep Feature Transfer Learning for Automatic Pronunciation Assessment|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lin21j_interspeech.html|Applications in Transcription, Education and Learning|https://www.isca-speech.org/archive/interspeech_2021/lin21j_interspeech.html|
|Multilingual Speech Evaluation: Case Studies on English, Malay and Tamil|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21fa_interspeech.html|Applications in Transcription, Education and Learning|https://www.isca-speech.org/archive/interspeech_2021/zhang21fa_interspeech.html|
|A Study on Fine-Tuning wav2vec2.0 Model for the Task of Mispronunciation Detection and Diagnosis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/peng21e_interspeech.html|Applications in Transcription, Education and Learning|https://www.isca-speech.org/archive/interspeech_2021/peng21e_interspeech.html|
|The Impact of ASR on the Automatic Analysis of Linguistic Complexity and Sophistication in Spontaneous L2 Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/qiao21b_interspeech.html|Applications in Transcription, Education and Learning|https://www.isca-speech.org/archive/interspeech_2021/qiao21b_interspeech.html|
|End-to-End Rich Transcription-Style Automatic Speech Recognition with Semi-Supervised Learning|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/tanaka21c_interspeech.html|Applications in Transcription, Education and Learning|https://www.isca-speech.org/archive/interspeech_2021/tanaka21c_interspeech.html|
|“You don’t understand me!”: Comparing ASR Results for L1 and L2 Speakers of Swedish|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/cumbal21_interspeech.html|Applications in Transcription, Education and Learning|https://www.isca-speech.org/archive/interspeech_2021/cumbal21_interspeech.html|
|NeMo Inverse Text Normalization: From Development to Production|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21ga_interspeech.html|Applications in Transcription, Education and Learning|https://www.isca-speech.org/archive/interspeech_2021/zhang21ga_interspeech.html|
|Improvement of Automatic English Pronunciation Assessment with Small Number of Utterances Using Sentence Speakability|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/naijo21_interspeech.html|Applications in Transcription, Education and Learning|https://www.isca-speech.org/archive/interspeech_2021/naijo21_interspeech.html|
|Affect Recognition Through Scalogram and Multi-Resolution Cochleagram Features|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/haider21_interspeech.html|Emotion and Sentiment Analysis III|https://www.isca-speech.org/archive/interspeech_2021/haider21_interspeech.html|
|A Speech Emotion Recognition Framework for Better Discrimination of Confusions|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/liu21n_interspeech.html|Emotion and Sentiment Analysis III|https://www.isca-speech.org/archive/interspeech_2021/liu21n_interspeech.html|
|Speech Emotion Recognition via Multi-Level Cross-Modal Distillation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/li21p_interspeech.html|Emotion and Sentiment Analysis III|https://www.isca-speech.org/archive/interspeech_2021/li21p_interspeech.html|
|Audio-Visual Speech Emotion Recognition by Disentangling Emotion and Identity Attributes|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ito21_interspeech.html|Emotion and Sentiment Analysis III|https://www.isca-speech.org/archive/interspeech_2021/ito21_interspeech.html|
|Parametric Distributions to Model Numerical Emotion Labels|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/bose21_interspeech.html|Emotion and Sentiment Analysis III|https://www.isca-speech.org/archive/interspeech_2021/bose21_interspeech.html|
|Metric Learning Based Feature Representation with Gated Fusion Model for Speech Emotion Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/gao21e_interspeech.html|Emotion and Sentiment Analysis III|https://www.isca-speech.org/archive/interspeech_2021/gao21e_interspeech.html|
|Speech Emotion Recognition with Multi-Task Learning|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/cai21b_interspeech.html|Emotion and Sentiment Analysis III|https://www.isca-speech.org/archive/interspeech_2021/cai21b_interspeech.html|
|Generalized Dilated CNN Models for Depression Detection Using Inverted Vocal Tract Variables|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/seneviratne21b_interspeech.html|Emotion and Sentiment Analysis III|https://www.isca-speech.org/archive/interspeech_2021/seneviratne21b_interspeech.html|
|Learning Mutual Correlation in Multimodal Transformer for Speech Emotion Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21ga_interspeech.html|Emotion and Sentiment Analysis III|https://www.isca-speech.org/archive/interspeech_2021/wang21ga_interspeech.html|
|Time-Frequency Representation Learning with Graph Convolutional Network for Dialogue-Level Speech Emotion Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/liu21o_interspeech.html|Emotion and Sentiment Analysis III|https://www.isca-speech.org/archive/interspeech_2021/liu21o_interspeech.html|
|Compressing 1D Time-Channel Separable Convolutions Using Sparse Random Ternary Matrices|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/mordido21_interspeech.html|Resource-Constrained ASR|https://www.isca-speech.org/archive/interspeech_2021/mordido21_interspeech.html|
|Weakly Supervised Construction of ASR Systems from Massive Video Data|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/cheng21c_interspeech.html|Resource-Constrained ASR|https://www.isca-speech.org/archive/interspeech_2021/cheng21c_interspeech.html|
|Broadcasted Residual Learning for Efficient Keyword Spotting|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kim21l_interspeech.html|Resource-Constrained ASR|https://www.isca-speech.org/archive/interspeech_2021/kim21l_interspeech.html|
|CoDERT: Distilling Encoder Representations with Co-Learning for Transducer-Based Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/swaminathan21_interspeech.html|Resource-Constrained ASR|https://www.isca-speech.org/archive/interspeech_2021/swaminathan21_interspeech.html|
|Extremely Low Footprint End-to-End ASR System for Smart Device|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/gao21f_interspeech.html|Resource-Constrained ASR|https://www.isca-speech.org/archive/interspeech_2021/gao21f_interspeech.html|
|Dissecting User-Perceived Latency of On-Device E2E Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/shangguan21_interspeech.html|Resource-Constrained ASR|https://www.isca-speech.org/archive/interspeech_2021/shangguan21_interspeech.html|
|Amortized Neural Networks for Low-Latency Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/macoskey21b_interspeech.html|Resource-Constrained ASR|https://www.isca-speech.org/archive/interspeech_2021/macoskey21b_interspeech.html|
|Tied & Reduced RNN-T Decoder|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/botros21_interspeech.html|Resource-Constrained ASR|https://www.isca-speech.org/archive/interspeech_2021/botros21_interspeech.html|
|PQK: Model Compression via Pruning, Quantization, and Knowledge Distillation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kim21m_interspeech.html|Resource-Constrained ASR|https://www.isca-speech.org/archive/interspeech_2021/kim21m_interspeech.html|
|Collaborative Training of Acoustic Encoders for Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/nagaraja21_interspeech.html|Resource-Constrained ASR|https://www.isca-speech.org/archive/interspeech_2021/nagaraja21_interspeech.html|
|Efficient Conformer with Prob-Sparse Attention Mechanism for End-to-End Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21ha_interspeech.html|Resource-Constrained ASR|https://www.isca-speech.org/archive/interspeech_2021/wang21ha_interspeech.html|
|The Energy and Carbon Footprint of Training End-to-End Speech Recognizers|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/parcollet21_interspeech.html|Resource-Constrained ASR|https://www.isca-speech.org/archive/interspeech_2021/parcollet21_interspeech.html|
|Graph-Based Label Propagation for Semi-Supervised Speaker Identification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chen21v_interspeech.html|Speaker Recognition: Applications|https://www.isca-speech.org/archive/interspeech_2021/chen21v_interspeech.html|
|Fusion of Embeddings Networks for Robust Combination of Text Dependent and Independent Speaker Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/li21q_interspeech.html|Speaker Recognition: Applications|https://www.isca-speech.org/archive/interspeech_2021/li21q_interspeech.html|
|A Generative Model for Duration-Dependent Score Calibration|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/cumani21_interspeech.html|Speaker Recognition: Applications|https://www.isca-speech.org/archive/interspeech_2021/cumani21_interspeech.html|
|Dr-Vectors: Decision Residual Networks and an Improved Loss for Speaker Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/pelecanos21_interspeech.html|Speaker Recognition: Applications|https://www.isca-speech.org/archive/interspeech_2021/pelecanos21_interspeech.html|
|Multi-Channel Speaker Verification for Single and Multi-Talker Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kataria21b_interspeech.html|Speaker Recognition: Applications|https://www.isca-speech.org/archive/interspeech_2021/kataria21b_interspeech.html|
|Chronological Self-Training for Real-Time Speaker Diarization|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/padfield21_interspeech.html|Speaker Recognition: Applications|https://www.isca-speech.org/archive/interspeech_2021/padfield21_interspeech.html|
|Adaptive Margin Circle Loss for Speaker Verification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/xiao21b_interspeech.html|Speaker Recognition: Applications|https://www.isca-speech.org/archive/interspeech_2021/xiao21b_interspeech.html|
|Presentation Matters: Evaluating Speaker Identification Tasks|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/obrien21b_interspeech.html|Speaker Recognition: Applications|https://www.isca-speech.org/archive/interspeech_2021/obrien21b_interspeech.html|
|Automatic Error Correction for Speaker Embedding Learning with Noisy Labels|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/tong21_interspeech.html|Speaker Recognition: Applications|https://www.isca-speech.org/archive/interspeech_2021/tong21_interspeech.html|
|An Integrated Framework for Two-Pass Personalized Voice Trigger|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/liao21_interspeech.html|Speaker Recognition: Applications|https://www.isca-speech.org/archive/interspeech_2021/liao21_interspeech.html|
|Masked Proxy Loss for Text-Independent Speaker Verification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lian21_interspeech.html|Speaker Recognition: Applications|https://www.isca-speech.org/archive/interspeech_2021/lian21_interspeech.html|
|STYLER: Style Factor Modeling with Rapidity and Robustness via Speech Decomposition for Expressive and Controllable Neural Text to Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lee21h_interspeech.html|Speech Synthesis: Speaking Style and Emotion|https://www.isca-speech.org/archive/interspeech_2021/lee21h_interspeech.html|
|Reinforcement Learning for Emotional Text-to-Speech Synthesis with Improved Emotion Discriminability|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/liu21p_interspeech.html|Speech Synthesis: Speaking Style and Emotion|https://www.isca-speech.org/archive/interspeech_2021/liu21p_interspeech.html|
|Emotional Prosody Control for Speech Generation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/sivaprasad21_interspeech.html|Speech Synthesis: Speaking Style and Emotion|https://www.isca-speech.org/archive/interspeech_2021/sivaprasad21_interspeech.html|
|Controllable Context-Aware Conversational Speech Synthesis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/cong21b_interspeech.html|Speech Synthesis: Speaking Style and Emotion|https://www.isca-speech.org/archive/interspeech_2021/cong21b_interspeech.html|
|Expressive Text-to-Speech Using Style Tag|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kim21n_interspeech.html|Speech Synthesis: Speaking Style and Emotion|https://www.isca-speech.org/archive/interspeech_2021/kim21n_interspeech.html|
|Adaptive Text to Speech for Spontaneous Style|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/yan21d_interspeech.html|Speech Synthesis: Speaking Style and Emotion|https://www.isca-speech.org/archive/interspeech_2021/yan21d_interspeech.html|
|Towards Multi-Scale Style Control for Expressive Speech Synthesis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/li21r_interspeech.html|Speech Synthesis: Speaking Style and Emotion|https://www.isca-speech.org/archive/interspeech_2021/li21r_interspeech.html|
|Cross-Speaker Style Transfer with Prosody Bottleneck in Neural Speech Synthesis|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/pan21d_interspeech.html|Speech Synthesis: Speaking Style and Emotion|https://www.isca-speech.org/archive/interspeech_2021/pan21d_interspeech.html|
|Fine-Grained Style Modeling, Transfer and Prediction in Text-to-Speech Synthesis via Phone-Level Content-Style Disentanglement|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/tan21_interspeech.html|Speech Synthesis: Speaking Style and Emotion|https://www.isca-speech.org/archive/interspeech_2021/tan21_interspeech.html|
|Improving Performance of Seen and Unseen Speech Style Transfer in End-to-End Neural TTS|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/an21b_interspeech.html|Speech Synthesis: Speaking Style and Emotion|https://www.isca-speech.org/archive/interspeech_2021/an21b_interspeech.html|
|Synthesis of Expressive Speaking Styles with Limited Training Data in a Multi-Speaker, Prosody-Controllable Sequence-to-Sequence Architecture|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/shechtman21_interspeech.html|Speech Synthesis: Speaking Style and Emotion|https://www.isca-speech.org/archive/interspeech_2021/shechtman21_interspeech.html|
|Intent Detection and Slot Filling for Vietnamese|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/dao21_interspeech.html|Spoken Language Understanding II|https://www.isca-speech.org/archive/interspeech_2021/dao21_interspeech.html|
|Augmenting Slot Values and Contexts for Spoken Language Understanding with Pretrained Models|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/lin21k_interspeech.html|Spoken Language Understanding II|https://www.isca-speech.org/archive/interspeech_2021/lin21k_interspeech.html|
|The Impact of Intent Distribution Mismatch on Semi-Supervised Spoken Language Understanding|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/gaspers21_interspeech.html|Spoken Language Understanding II|https://www.isca-speech.org/archive/interspeech_2021/gaspers21_interspeech.html|
|Knowledge Distillation from BERT Transformer to Speech Transformer for Intent Classification|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/jiang21c_interspeech.html|Spoken Language Understanding II|https://www.isca-speech.org/archive/interspeech_2021/jiang21c_interspeech.html|
|Three-Module Modeling For End-to-End Spoken Language Understanding Using Pre-Trained DNN-HMM-Based Acoustic-Phonetic Model|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21ia_interspeech.html|Spoken Language Understanding II|https://www.isca-speech.org/archive/interspeech_2021/wang21ia_interspeech.html|
|Speak or Chat with Me: End-to-End Spoken Language Understanding System with Flexible Inputs|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/cha21_interspeech.html|Spoken Language Understanding II|https://www.isca-speech.org/archive/interspeech_2021/cha21_interspeech.html|
|End-to-End Cross-Lingual Spoken Language Understanding Model with Multilingual Pretraining|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21ha_interspeech.html|Spoken Language Understanding II|https://www.isca-speech.org/archive/interspeech_2021/zhang21ha_interspeech.html|
|Factorization-Aware Training of Transformers for Natural Language Understanding on the Edge|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/saghir21_interspeech.html|Spoken Language Understanding II|https://www.isca-speech.org/archive/interspeech_2021/saghir21_interspeech.html|
|End-to-End Spoken Language Understanding for Generalized Voice Assistants|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/saxon21_interspeech.html|Spoken Language Understanding II|https://www.isca-speech.org/archive/interspeech_2021/saxon21_interspeech.html|
|Bi-Directional Joint Neural Networks for Intent Classification and Slot Filling|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/han21f_interspeech.html|Spoken Language Understanding II|https://www.isca-speech.org/archive/interspeech_2021/han21f_interspeech.html|
|INTERSPEECH 2021 Acoustic Echo Cancellation Challenge|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/cutler21_interspeech.html|INTERSPEECH 2021 Acoustic Echo Cancellation Challenge|https://www.isca-speech.org/archive/interspeech_2021/cutler21_interspeech.html|
|Acoustic Echo Cancellation with Cross-Domain Learning|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/pfeifenberger21_interspeech.html|INTERSPEECH 2021 Acoustic Echo Cancellation Challenge|https://www.isca-speech.org/archive/interspeech_2021/pfeifenberger21_interspeech.html|
|F-T-LSTM Based Complex Network for Joint Acoustic Echo Cancellation and Speech Enhancement|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21ia_interspeech.html|INTERSPEECH 2021 Acoustic Echo Cancellation Challenge|https://www.isca-speech.org/archive/interspeech_2021/zhang21ia_interspeech.html|
|Y2-Net FCRN for Acoustic Echo and Noise Suppression|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/seidel21_interspeech.html|INTERSPEECH 2021 Acoustic Echo Cancellation Challenge|https://www.isca-speech.org/archive/interspeech_2021/seidel21_interspeech.html|
|Acoustic Echo Cancellation Using Deep Complex Neural Network with Nonlinear Magnitude Compression and Phase Information|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/peng21f_interspeech.html|INTERSPEECH 2021 Acoustic Echo Cancellation Challenge|https://www.isca-speech.org/archive/interspeech_2021/peng21f_interspeech.html|
|Nonlinear Acoustic Echo Cancellation with Deep Learning|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/ivry21_interspeech.html|INTERSPEECH 2021 Acoustic Echo Cancellation Challenge|https://www.isca-speech.org/archive/interspeech_2021/ivry21_interspeech.html|
|Automatic Speech Recognition of Disordered Speech: Personalized Models Outperforming Human Listeners on Short Phrases|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/green21_interspeech.html|Speech Recognition of Atypical Speech|https://www.isca-speech.org/archive/interspeech_2021/green21_interspeech.html|
|Investigating the Utility of Multimodal Conversational Technology and Audiovisual Analytic Measures for the Assessment and Monitoring of Amyotrophic Lateral Sclerosis at Scale|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/neumann21b_interspeech.html|Speech Recognition of Atypical Speech|https://www.isca-speech.org/archive/interspeech_2021/neumann21b_interspeech.html|
|Handling Acoustic Variation in Dysarthric Speech Recognition Systems Through Model Combination|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/hermann21_interspeech.html|Speech Recognition of Atypical Speech|https://www.isca-speech.org/archive/interspeech_2021/hermann21_interspeech.html|
|Spectro-Temporal Deep Features for Disordered Speech Assessment and Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/geng21b_interspeech.html|Speech Recognition of Atypical Speech|https://www.isca-speech.org/archive/interspeech_2021/geng21b_interspeech.html|
|Speaking with a KN95 Face Mask: ASR Performance and Speaker Compensation|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/gutz21_interspeech.html|Speech Recognition of Atypical Speech|https://www.isca-speech.org/archive/interspeech_2021/gutz21_interspeech.html|
|Adversarial Data Augmentation for Disordered Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/jin21_interspeech.html|Speech Recognition of Atypical Speech|https://www.isca-speech.org/archive/interspeech_2021/jin21_interspeech.html|
|Variational Auto-Encoder Based Variability Encoding for Dysarthric Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/xie21b_interspeech.html|Speech Recognition of Atypical Speech|https://www.isca-speech.org/archive/interspeech_2021/xie21b_interspeech.html|
|Learning Explicit Prosody Models and Deep Speaker Embeddings for Atypical Voice Conversion|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/wang21ja_interspeech.html|Speech Recognition of Atypical Speech|https://www.isca-speech.org/archive/interspeech_2021/wang21ja_interspeech.html|
|Bayesian Parametric and Architectural Domain Adaptation of LF-MMI Trained TDNNs for Elderly and Dysarthric Speech Recognition|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/deng21d_interspeech.html|Speech Recognition of Atypical Speech|https://www.isca-speech.org/archive/interspeech_2021/deng21d_interspeech.html|
|A Voice-Activated Switch for Persons with Motor and Speech Impairments: Isolated-Vowel Spotting Using Neural Networks|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/cai21c_interspeech.html|Speech Recognition of Atypical Speech|https://www.isca-speech.org/archive/interspeech_2021/cai21c_interspeech.html|
|Conformer Parrotron: A Faster and Stronger End-to-End Speech Conversion and Recognition Model for Atypical Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/chen21w_interspeech.html|Speech Recognition of Atypical Speech|https://www.isca-speech.org/archive/interspeech_2021/chen21w_interspeech.html|
|Disordered Speech Data Collection: Lessons Learned at 1 Million Utterances from Project Euphonia|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/macdonald21_interspeech.html|Speech Recognition of Atypical Speech|https://www.isca-speech.org/archive/interspeech_2021/macdonald21_interspeech.html|
|Automatic Severity Classification of Korean Dysarthric Speech Using Phoneme-Level Pronunciation Features|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/yeo21_interspeech.html|Speech Recognition of Atypical Speech|https://www.isca-speech.org/archive/interspeech_2021/yeo21_interspeech.html|
|Comparing Supervised Models and Learned Speech Representations for Classifying Intelligibility of Disordered Speech on Selected Phrases|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/venugopalan21_interspeech.html|Speech Recognition of Atypical Speech|https://www.isca-speech.org/archive/interspeech_2021/venugopalan21_interspeech.html|
|Analysis and Tuning of a Voice Assistant System for Dysfluent Speech|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/mitra21_interspeech.html|Speech Recognition of Atypical Speech|https://www.isca-speech.org/archive/interspeech_2021/mitra21_interspeech.html|
|Interactive and Real-Time Acoustic Measurement Tools for Speech Data Acquisition and Presentation: Application of an Extended Member of Time Stretched Pulses|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/kawahara21b_interspeech.html|Show and Tell 4|https://www.isca-speech.org/archive/interspeech_2021/kawahara21b_interspeech.html|
|Save Your Voice: Voice Banking and TTS for Anyone|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/tihelka21_interspeech.html|Show and Tell 4|https://www.isca-speech.org/archive/interspeech_2021/tihelka21_interspeech.html|
|NeMo (Inverse) Text Normalization: From Development to Production|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/zhang21ja_interspeech.html|Show and Tell 4|https://www.isca-speech.org/archive/interspeech_2021/zhang21ja_interspeech.html|
|Lalilo: A Reading Assistant for Children Featuring Speech Recognition-Based Reading Mistake Detection|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/hembise21_interspeech.html|Show and Tell 4|https://www.isca-speech.org/archive/interspeech_2021/hembise21_interspeech.html|
|Automatic Radiology Report Editing Through Voice|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/nguyen21f_interspeech.html|Show and Tell 4|https://www.isca-speech.org/archive/interspeech_2021/nguyen21f_interspeech.html|
|WittyKiddy: Multilingual Spoken Language Learning for Kids|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/shi21e_interspeech.html|Show and Tell 4|https://www.isca-speech.org/archive/interspeech_2021/shi21e_interspeech.html|
|Duplex Conversation in Outbound Agent System|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/jin21b_interspeech.html|Show and Tell 4|https://www.isca-speech.org/archive/interspeech_2021/jin21b_interspeech.html|
|Web Interface for Estimating Articulatory Movements in Speech Production from Acoustics and Text|interspeech21|https://www.isca-speech.org/archive/interspeech_2021/udupa21b_interspeech.html|Show and Tell 4|https://www.isca-speech.org/archive/interspeech_2021/udupa21b_interspeech.html|
