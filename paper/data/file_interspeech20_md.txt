|The cognitive status of simple and complex models|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/pierrehumbert20_interspeech.html|Keynote 1|https://www.isca-speech.org/archive/interspeech_2020/pierrehumbert20_interspeech.html|
|On the Comparison of Popular End-to-End Models for Large Scale Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20_interspeech.html|ASR Neural Network Architectures I|https://www.isca-speech.org/archive/interspeech_2020/li20_interspeech.html|
|SAN-M: Memory Equipped Self-Attention for End-to-End Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/gao20_interspeech.html|ASR Neural Network Architectures I|https://www.isca-speech.org/archive/interspeech_2020/gao20_interspeech.html|
|Contextual RNN-T for Open Domain ASR|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/jain20_interspeech.html|ASR Neural Network Architectures I|https://www.isca-speech.org/archive/interspeech_2020/jain20_interspeech.html|
|ASAPP-ASR: Multistream CNN and Self-Attentive SRU for SOTA Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/pan20_interspeech.html|ASR Neural Network Architectures I|https://www.isca-speech.org/archive/interspeech_2020/pan20_interspeech.html|
|Compressing LSTM Networks with Hierarchical Coarse-Grain Sparsity|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kadetotad20_interspeech.html|ASR Neural Network Architectures I|https://www.isca-speech.org/archive/interspeech_2020/kadetotad20_interspeech.html|
|BLSTM-Driven Stream Fusion for Automatic Speech Recognition: Novel Methods and a Multi-Size Window Fusion Example|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lohrenz20_interspeech.html|ASR Neural Network Architectures I|https://www.isca-speech.org/archive/interspeech_2020/lohrenz20_interspeech.html|
|Relative Positional Encoding for Speech Recognition and Direct Translation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/pham20_interspeech.html|ASR Neural Network Architectures I|https://www.isca-speech.org/archive/interspeech_2020/pham20_interspeech.html|
|Joint Speaker Counting, Speech Recognition, and Speaker Identification for Overlapped Speech of any Number of Speakers|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kanda20_interspeech.html|ASR Neural Network Architectures I|https://www.isca-speech.org/archive/interspeech_2020/kanda20_interspeech.html|
|Implicit Transfer of Privileged Acoustic Information in a Generalized Knowledge Distillation Framework|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/fukuda20_interspeech.html|ASR Neural Network Architectures I|https://www.isca-speech.org/archive/interspeech_2020/fukuda20_interspeech.html|
|Effect of Adding Positional Information on Convolutional Neural Networks for End-to-End Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/park20_interspeech.html|ASR Neural Network Architectures I|https://www.isca-speech.org/archive/interspeech_2020/park20_interspeech.html|
|Deep Neural Network-Based Generalized Sidelobe Canceller for Robust Multi-Channel Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20b_interspeech.html|Multi-Channel Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2020/li20b_interspeech.html|
|Neural Spatio-Temporal Beamformer for Target Speech Separation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/xu20_interspeech.html|Multi-Channel Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2020/xu20_interspeech.html|
|Online Directional Speech Enhancement Using Geometrically Constrained Independent Vector Analysis|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20c_interspeech.html|Multi-Channel Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2020/li20c_interspeech.html|
|End-to-End Multi-Look Keyword Spotting|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yu20_interspeech.html|Multi-Channel Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2020/yu20_interspeech.html|
|Differential Beamforming for Uniform Circular Array with Directional Microphones|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/huang20_interspeech.html|Multi-Channel Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2020/huang20_interspeech.html|
|Exploring Deep Hybrid Tensor-to-Vector Network Architectures for Regression Based Speech Enhancement|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/qi20_interspeech.html|Multi-Channel Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2020/qi20_interspeech.html|
|An End-to-End Architecture of Online Multi-Channel Speech Separation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wu20_interspeech.html|Multi-Channel Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2020/wu20_interspeech.html|
|Mentoring-Reverse Mentoring for Unsupervised Multi-Channel Speech Source Separation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/nakagome20_interspeech.html|Multi-Channel Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2020/nakagome20_interspeech.html|
|Computationally Efficient and Versatile Framework for Joint Optimization of Blind Speech Separation and Dereverberation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/nakatani20_interspeech.html|Multi-Channel Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2020/nakatani20_interspeech.html|
|A Space-and-Speaker-Aware Iterative Mask Estimation Approach to Multi-Channel Speech Recognition in the CHiME-6 Challenge|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/tu20_interspeech.html|Multi-Channel Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2020/tu20_interspeech.html|
|Identifying Causal Relationships Between Behavior and Local Brain Activity During Natural Conversation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/youssef20_interspeech.html|Speech Processing in the Brain|https://www.isca-speech.org/archive/interspeech_2020/youssef20_interspeech.html|
|Neural Entrainment to Natural Speech Envelope Based on Subject Aligned EEG Signals|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhou20_interspeech.html|Speech Processing in the Brain|https://www.isca-speech.org/archive/interspeech_2020/zhou20_interspeech.html|
|Does Lexical Retrieval Deteriorate in Patients with Mild Cognitive Impairment? Analysis of Brain Functional Network Will Tell|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lian20_interspeech.html|Speech Processing in the Brain|https://www.isca-speech.org/archive/interspeech_2020/lian20_interspeech.html|
|Congruent Audiovisual Speech Enhances Cortical Envelope Tracking During Auditory Selective Attention|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/fu20_interspeech.html|Speech Processing in the Brain|https://www.isca-speech.org/archive/interspeech_2020/fu20_interspeech.html|
|Contribution of RMS-Level-Based Speech Segments to Target Speech Decoding Under Noisy Conditions|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20_interspeech.html|Speech Processing in the Brain|https://www.isca-speech.org/archive/interspeech_2020/wang20_interspeech.html|
|Cortical Oscillatory Hierarchy for Natural Sentence Processing|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhao20_interspeech.html|Speech Processing in the Brain|https://www.isca-speech.org/archive/interspeech_2020/zhao20_interspeech.html|
|Comparing EEG Analyses with Different Epoch Alignments in an Auditory Lexical Decision Experiment|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/bosch20_interspeech.html|Speech Processing in the Brain|https://www.isca-speech.org/archive/interspeech_2020/bosch20_interspeech.html|
|Detection of Subclinical Mild Traumatic Brain Injury (mTBI) Through Speech and Gait|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/talkar20_interspeech.html|Speech Processing in the Brain|https://www.isca-speech.org/archive/interspeech_2020/talkar20_interspeech.html|
|Towards Learning a Universal Non-Semantic Representation of Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/shor20_interspeech.html|Speech Signal Representation|https://www.isca-speech.org/archive/interspeech_2020/shor20_interspeech.html|
|Poetic Meter Classification Using i-Vector-MTF Fusion|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/rajan20_interspeech.html|Speech Signal Representation|https://www.isca-speech.org/archive/interspeech_2020/rajan20_interspeech.html|
|Formant Tracking Using Dilated Convolutional Networks Through Dense Connection with Gating Mechanism|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/dai20_interspeech.html|Speech Signal Representation|https://www.isca-speech.org/archive/interspeech_2020/dai20_interspeech.html|
|Automatic Analysis of Speech Prosody in Dutch|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hu20_interspeech.html|Speech Signal Representation|https://www.isca-speech.org/archive/interspeech_2020/hu20_interspeech.html|
|Learning Voice Representation Using Knowledge Distillation for Automatic Voice Casting|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/gresse20_interspeech.html|Speech Signal Representation|https://www.isca-speech.org/archive/interspeech_2020/gresse20_interspeech.html|
|Enhancing Formant Information in Spectrographic Display of Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yegnanarayana20_interspeech.html|Speech Signal Representation|https://www.isca-speech.org/archive/interspeech_2020/yegnanarayana20_interspeech.html|
|Unsupervised Methods for Evaluating Speech Representations|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/gump20_interspeech.html|Speech Signal Representation|https://www.isca-speech.org/archive/interspeech_2020/gump20_interspeech.html|
|Robust Pitch Regression with Voiced/Unvoiced Classification in Nonstationary Noise Environments|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/tran20_interspeech.html|Speech Signal Representation|https://www.isca-speech.org/archive/interspeech_2020/tran20_interspeech.html|
|Nonlinear ISA with Auxiliary Variables for Learning Speech Representations|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/setlur20_interspeech.html|Speech Signal Representation|https://www.isca-speech.org/archive/interspeech_2020/setlur20_interspeech.html|
|Harmonic Lowering for Accelerating Harmonic Convolution for Audio Signals|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/takeuchi20_interspeech.html|Speech Signal Representation|https://www.isca-speech.org/archive/interspeech_2020/takeuchi20_interspeech.html|
|Knowledge-and-Data-Driven Amplitude Spectrum Prediction for Hierarchical Neural Vocoders|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ai20_interspeech.html|Speech Synthesis: Neural Waveform Generation I|https://www.isca-speech.org/archive/interspeech_2020/ai20_interspeech.html|
|FeatherWave: An Efficient High-Fidelity Neural Vocoder with Multi-Band Linear Prediction|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/tian20_interspeech.html|Speech Synthesis: Neural Waveform Generation I|https://www.isca-speech.org/archive/interspeech_2020/tian20_interspeech.html|
|VocGAN: A High-Fidelity Real-Time Vocoder with a Hierarchically-Nested Adversarial Network|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yang20_interspeech.html|Speech Synthesis: Neural Waveform Generation I|https://www.isca-speech.org/archive/interspeech_2020/yang20_interspeech.html|
|Lightweight LPCNet-Based Neural Vocoder with Tensor Decomposition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kanagawa20_interspeech.html|Speech Synthesis: Neural Waveform Generation I|https://www.isca-speech.org/archive/interspeech_2020/kanagawa20_interspeech.html|
|WG-WaveNet: Real-Time High-Fidelity Speech Synthesis Without GPU|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hsu20_interspeech.html|Speech Synthesis: Neural Waveform Generation I|https://www.isca-speech.org/archive/interspeech_2020/hsu20_interspeech.html|
|What the Future Brings: Investigating the Impact of Lookahead for Incremental Neural TTS|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/stephenson20_interspeech.html|Speech Synthesis: Neural Waveform Generation I|https://www.isca-speech.org/archive/interspeech_2020/stephenson20_interspeech.html|
|Fast and Lightweight On-Device TTS with Tacotron2 and LPCNet|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/popov20_interspeech.html|Speech Synthesis: Neural Waveform Generation I|https://www.isca-speech.org/archive/interspeech_2020/popov20_interspeech.html|
|Efficient WaveGlow: An Improved WaveGlow Vocoder with Enhanced Speed|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/song20_interspeech.html|Speech Synthesis: Neural Waveform Generation I|https://www.isca-speech.org/archive/interspeech_2020/song20_interspeech.html|
|Can Auditory Nerve Models Tell us What’s Different About WaveNet Vocoded Speech?|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/maguer20_interspeech.html|Speech Synthesis: Neural Waveform Generation I|https://www.isca-speech.org/archive/interspeech_2020/maguer20_interspeech.html|
|Speaker Conditional WaveRNN: Towards Universal Neural Vocoder for Unseen Speaker and Recording Conditions|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/paul20_interspeech.html|Speech Synthesis: Neural Waveform Generation I|https://www.isca-speech.org/archive/interspeech_2020/paul20_interspeech.html|
|Neural Homomorphic Vocoder|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/liu20_interspeech.html|Speech Synthesis: Neural Waveform Generation I|https://www.isca-speech.org/archive/interspeech_2020/liu20_interspeech.html|
|Overview of the Interspeech TLT2020 Shared Task on ASR for Non-Native Children’s Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/gretter20_interspeech.html|Automatic Speech Recognition for Non-Native Children’s Speech|https://www.isca-speech.org/archive/interspeech_2020/gretter20_interspeech.html|
|The NTNU System at the Interspeech 2020 Non-Native Children’s Speech ASR Challenge|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lo20_interspeech.html|Automatic Speech Recognition for Non-Native Children’s Speech|https://www.isca-speech.org/archive/interspeech_2020/lo20_interspeech.html|
|Non-Native Children’s Automatic Speech Recognition: The INTERSPEECH 2020 Shared Task ALTA Systems|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/knill20_interspeech.html|Automatic Speech Recognition for Non-Native Children’s Speech|https://www.isca-speech.org/archive/interspeech_2020/knill20_interspeech.html|
|Data Augmentation Using Prosody and False Starts to Recognize Non-Native Children’s Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kathania20_interspeech.html|Automatic Speech Recognition for Non-Native Children’s Speech|https://www.isca-speech.org/archive/interspeech_2020/kathania20_interspeech.html|
|UNSW System Description for the Shared Task on Automatic Speech Recognition for Non-Native Children’s Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/shahin20_interspeech.html|Automatic Speech Recognition for Non-Native Children’s Speech|https://www.isca-speech.org/archive/interspeech_2020/shahin20_interspeech.html|
|End-to-End Speaker Diarization for an Unknown Number of Speakers with Encoder-Decoder Based Attractors|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/horiguchi20_interspeech.html|Speaker Diarization|https://www.isca-speech.org/archive/interspeech_2020/horiguchi20_interspeech.html|
|Target-Speaker Voice Activity Detection: A Novel Approach for Multi-Speaker Diarization in a Dinner Party Scenario|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/medennikov20_interspeech.html|Speaker Diarization|https://www.isca-speech.org/archive/interspeech_2020/medennikov20_interspeech.html|
|New Advances in Speaker Diarization|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/aronowitz20_interspeech.html|Speaker Diarization|https://www.isca-speech.org/archive/interspeech_2020/aronowitz20_interspeech.html|
|Self-Attentive Similarity Measurement Strategies in Speaker Diarization|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lin20_interspeech.html|Speaker Diarization|https://www.isca-speech.org/archive/interspeech_2020/lin20_interspeech.html|
|Speaker Attribution with Voice Profiles by Graph-Based Semi-Supervised Learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20b_interspeech.html|Speaker Diarization|https://www.isca-speech.org/archive/interspeech_2020/wang20b_interspeech.html|
|Deep Self-Supervised Hierarchical Clustering for Speaker Diarization|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/singh20_interspeech.html|Speaker Diarization|https://www.isca-speech.org/archive/interspeech_2020/singh20_interspeech.html|
|Spot the Conversation: Speaker Diarisation in the Wild|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chung20_interspeech.html|Speaker Diarization|https://www.isca-speech.org/archive/interspeech_2020/chung20_interspeech.html|
|Learning Contextual Language Embeddings for Monaural Multi-Talker Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20_interspeech.html|Noise Robust and Distant Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/zhang20_interspeech.html|
|Double Adversarial Network Based Monaural Speech Enhancement for Robust Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/du20_interspeech.html|Noise Robust and Distant Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/du20_interspeech.html|
|Anti-Aliasing Regularization in Stacking Layers|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/bruguier20_interspeech.html|Noise Robust and Distant Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/bruguier20_interspeech.html|
|Towards a Competitive End-to-End Speech Recognition for CHiME-6 Dinner Party Transcription|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/andrusenko20_interspeech.html|Noise Robust and Distant Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/andrusenko20_interspeech.html|
|End-to-End Far-Field Speech Recognition with Unified Dereverberation and Beamforming|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20b_interspeech.html|Noise Robust and Distant Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/zhang20b_interspeech.html|
|Quaternion Neural Networks for Multi-Channel Distant Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/qiu20_interspeech.html|Noise Robust and Distant Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/qiu20_interspeech.html|
|Improved Guided Source Separation Integrated with a Strong Back-End for the CHiME-6 Dinner Party Scenario|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chen20_interspeech.html|Noise Robust and Distant Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/chen20_interspeech.html|
|Neural Speech Separation Using Spatially Distributed Microphones|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20c_interspeech.html|Noise Robust and Distant Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/wang20c_interspeech.html|
|Utterance-Wise Meeting Transcription System Using Asynchronous Distributed Microphones|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/horiguchi20b_interspeech.html|Noise Robust and Distant Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/horiguchi20b_interspeech.html|
|Simulating Realistically-Spatialised Simultaneous Speech Using Video-Driven Speaker Detection and the CHiME-5 Dataset|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/deadman20_interspeech.html|Noise Robust and Distant Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/deadman20_interspeech.html|
|Toward Silent Paralinguistics: Speech-to-EMG — Retrieving Articulatory Muscle Activity from Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/botelho20_interspeech.html|Speech in Multimodality|https://www.isca-speech.org/archive/interspeech_2020/botelho20_interspeech.html|
|Multimodal Deception Detection Using Automatically Extracted Acoustic, Visual, and Lexical Features|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20c_interspeech.html|Speech in Multimodality|https://www.isca-speech.org/archive/interspeech_2020/zhang20c_interspeech.html|
|Multi-Modal Attention for Speech Emotion Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/pan20b_interspeech.html|Speech in Multimodality|https://www.isca-speech.org/archive/interspeech_2020/pan20b_interspeech.html|
|WISE: Word-Level Interaction-Based Multimodal Fusion for Speech Emotion Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/shen20_interspeech.html|Speech in Multimodality|https://www.isca-speech.org/archive/interspeech_2020/shen20_interspeech.html|
|A Multi-Scale Fusion Framework for Bimodal Speech Emotion Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chen20b_interspeech.html|Speech in Multimodality|https://www.isca-speech.org/archive/interspeech_2020/chen20b_interspeech.html|
|Group Gated Fusion on Attention-Based Bidirectional Alignment for Multimodal Emotion Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/liu20b_interspeech.html|Speech in Multimodality|https://www.isca-speech.org/archive/interspeech_2020/liu20b_interspeech.html|
|Multi-Modal Embeddings Using Multi-Task Learning for Emotion Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/khare20_interspeech.html|Speech in Multimodality|https://www.isca-speech.org/archive/interspeech_2020/khare20_interspeech.html|
|Using Speaker-Aligned Graph Memory Block in Multimodally Attentive Emotion Recognition Network|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20d_interspeech.html|Speech in Multimodality|https://www.isca-speech.org/archive/interspeech_2020/li20d_interspeech.html|
|Context-Dependent Domain Adversarial Neural Network for Multimodal Emotion Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lian20b_interspeech.html|Speech in Multimodality|https://www.isca-speech.org/archive/interspeech_2020/lian20b_interspeech.html|
|ATCSpeech: A Multilingual Pilot-Controller Speech Corpus from Real Air Traffic Control Environment|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yang20b_interspeech.html|Speech, Language, and Multimodal Resources|https://www.isca-speech.org/archive/interspeech_2020/yang20b_interspeech.html|
|Developing an Open-Source Corpus of Yoruba Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/gutkin20_interspeech.html|Speech, Language, and Multimodal Resources|https://www.isca-speech.org/archive/interspeech_2020/gutkin20_interspeech.html|
|ClovaCall: Korean Goal-Oriented Dialog Speech Corpus for Automatic Speech Recognition of Contact Centers|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ha20_interspeech.html|Speech, Language, and Multimodal Resources|https://www.isca-speech.org/archive/interspeech_2020/ha20_interspeech.html|
|LAIX Corpus of Chinese Learner English: Towards a Benchmark for L2 English ASR|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20d_interspeech.html|Speech, Language, and Multimodal Resources|https://www.isca-speech.org/archive/interspeech_2020/wang20d_interspeech.html|
|Design and Development of a Human-Machine Dialog Corpus for the Automated Assessment of Conversational English Proficiency|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ramanarayanan20_interspeech.html|Speech, Language, and Multimodal Resources|https://www.isca-speech.org/archive/interspeech_2020/ramanarayanan20_interspeech.html|
|CUCHILD: A Large-Scale Cantonese Corpus of Child Speech for Phonology and Articulation Assessment|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ng20_interspeech.html|Speech, Language, and Multimodal Resources|https://www.isca-speech.org/archive/interspeech_2020/ng20_interspeech.html|
|FinChat: Corpus and Evaluation Setup for Finnish Chat Conversations on Everyday Topics|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/leino20_interspeech.html|Speech, Language, and Multimodal Resources|https://www.isca-speech.org/archive/interspeech_2020/leino20_interspeech.html|
|DiPCo — Dinner Party Corpus|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/segbroeck20_interspeech.html|Speech, Language, and Multimodal Resources|https://www.isca-speech.org/archive/interspeech_2020/segbroeck20_interspeech.html|
|Learning to Detect Bipolar Disorder and Borderline Personality Disorder with Language and Speech in Non-Clinical Interviews|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20e_interspeech.html|Speech, Language, and Multimodal Resources|https://www.isca-speech.org/archive/interspeech_2020/wang20e_interspeech.html|
|FT Speech: Danish Parliament Speech Corpus|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kirkedal20_interspeech.html|Speech, Language, and Multimodal Resources|https://www.isca-speech.org/archive/interspeech_2020/kirkedal20_interspeech.html|
|Metric Learning Loss Functions to Reduce Domain Mismatch in the x-Vector Space for Language Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/duroselle20_interspeech.html|Language Recognition|https://www.isca-speech.org/archive/interspeech_2020/duroselle20_interspeech.html|
|The XMUSPEECH System for the AP19-OLR Challenge|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20e_interspeech.html|Language Recognition|https://www.isca-speech.org/archive/interspeech_2020/li20e_interspeech.html|
|On the Usage of Multi-Feature Integration for Speaker Verification and Language Identification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20f_interspeech.html|Language Recognition|https://www.isca-speech.org/archive/interspeech_2020/li20f_interspeech.html|
|What Does an End-to-End Dialect Identification Model Learn About Non-Dialectal Information?|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chowdhury20_interspeech.html|Language Recognition|https://www.isca-speech.org/archive/interspeech_2020/chowdhury20_interspeech.html|
|Releasing a Toolkit and Comparing the Performance of Language Embeddings Across Various Spoken Language Identification Datasets|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lindgren20_interspeech.html|Language Recognition|https://www.isca-speech.org/archive/interspeech_2020/lindgren20_interspeech.html|
|Learning Intonation Pattern Embeddings for Arabic Dialect Identification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/alvarez20_interspeech.html|Language Recognition|https://www.isca-speech.org/archive/interspeech_2020/alvarez20_interspeech.html|
|Cross-Domain Adaptation of Spoken Language Identification for Related Languages: The Curious Case of Slavic Languages|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/abdullah20_interspeech.html|Language Recognition|https://www.isca-speech.org/archive/interspeech_2020/abdullah20_interspeech.html|
|ICE-Talk: An Interface for a Controllable Expressive Talking Machine|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/tits20_interspeech.html|Speech Processing and Analysis|https://www.isca-speech.org/archive/interspeech_2020/tits20_interspeech.html|
|Kaldi-Web: An Installation-Free, On-Device Speech Recognition System|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hu20b_interspeech.html|Speech Processing and Analysis|https://www.isca-speech.org/archive/interspeech_2020/hu20b_interspeech.html|
|Soapbox Labs Verification Platform for Child Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kelly20_interspeech.html|Speech Processing and Analysis|https://www.isca-speech.org/archive/interspeech_2020/kelly20_interspeech.html|
|SoapBox Labs Fluency Assessment Platform for Child Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kelly20b_interspeech.html|Speech Processing and Analysis|https://www.isca-speech.org/archive/interspeech_2020/kelly20b_interspeech.html|
|CATOTRON — A Neural Text-to-Speech System in Catalan|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kulebi20_interspeech.html|Speech Processing and Analysis|https://www.isca-speech.org/archive/interspeech_2020/kulebi20_interspeech.html|
|Toward Remote Patient Monitoring of Speech, Video, Cognitive and Respiratory Biomarkers Using Multimodal Dialog Technology|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ramanarayanan20b_interspeech.html|Speech Processing and Analysis|https://www.isca-speech.org/archive/interspeech_2020/ramanarayanan20b_interspeech.html|
|VoiceID on the Fly: A Speaker Recognition System that Learns from Scratch|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lin20b_interspeech.html|Speech Processing and Analysis|https://www.isca-speech.org/archive/interspeech_2020/lin20b_interspeech.html|
|Enhancing Transferability of Black-Box Adversarial Attacks via Lifelong Learning for Speech Emotion Recognition Models|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ren20_interspeech.html|Speech Emotion Recognition I|https://www.isca-speech.org/archive/interspeech_2020/ren20_interspeech.html|
|End-to-End Speech Emotion Recognition Combined with Acoustic-to-Word ASR Model|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/feng20_interspeech.html|Speech Emotion Recognition I|https://www.isca-speech.org/archive/interspeech_2020/feng20_interspeech.html|
|Improving Speech Emotion Recognition Using Graph Attentive Bi-Directional Gated Recurrent Unit Network|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/su20_interspeech.html|Speech Emotion Recognition I|https://www.isca-speech.org/archive/interspeech_2020/su20_interspeech.html|
|An Investigation of Cross-Cultural Semi-Supervised Learning for Continuous Affect Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mallolragolta20_interspeech.html|Speech Emotion Recognition I|https://www.isca-speech.org/archive/interspeech_2020/mallolragolta20_interspeech.html|
|Ensemble of Students Taught by Probabilistic Teachers to Improve Speech Emotion Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/sridhar20_interspeech.html|Speech Emotion Recognition I|https://www.isca-speech.org/archive/interspeech_2020/sridhar20_interspeech.html|
|Augmenting Generative Adversarial Networks for Speech Emotion Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/latif20_interspeech.html|Speech Emotion Recognition I|https://www.isca-speech.org/archive/interspeech_2020/latif20_interspeech.html|
|Speech Emotion Recognition ‘in the Wild’ Using an Autoencoder|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/dissanayake20_interspeech.html|Speech Emotion Recognition I|https://www.isca-speech.org/archive/interspeech_2020/dissanayake20_interspeech.html|
|Emotion Profile Refinery for Speech Emotion Classification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mao20_interspeech.html|Speech Emotion Recognition I|https://www.isca-speech.org/archive/interspeech_2020/mao20_interspeech.html|
|Speech Representation Learning for Emotion Recognition Using End-to-End ASR with Factorized Adaptation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yeh20_interspeech.html|Speech Emotion Recognition I|https://www.isca-speech.org/archive/interspeech_2020/yeh20_interspeech.html|
|Fast and Slow Acoustic Model|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kumar20_interspeech.html|ASR Neural Network Architectures and Training I|https://www.isca-speech.org/archive/interspeech_2020/kumar20_interspeech.html|
|Self-Distillation for Improving CTC-Transformer-Based ASR Systems|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/moriya20_interspeech.html|ASR Neural Network Architectures and Training I|https://www.isca-speech.org/archive/interspeech_2020/moriya20_interspeech.html|
|Single Headed Attention Based Sequence-to-Sequence Model for State-of-the-Art Results on Switchboard|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/tuske20_interspeech.html|ASR Neural Network Architectures and Training I|https://www.isca-speech.org/archive/interspeech_2020/tuske20_interspeech.html|
|Improving Speech Recognition Using GAN-Based Speech Synthesis and Contrastive Unspoken Text Selection|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chen20c_interspeech.html|ASR Neural Network Architectures and Training I|https://www.isca-speech.org/archive/interspeech_2020/chen20c_interspeech.html|
|PyChain: A Fully Parallelized PyTorch Implementation of LF-MMI for End-to-End ASR|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/shao20_interspeech.html|ASR Neural Network Architectures and Training I|https://www.isca-speech.org/archive/interspeech_2020/shao20_interspeech.html|
|CAT: A CTC-CRF Based ASR Toolkit Bridging the Hybrid and the End-to-End Approaches Towards Data Efficiency and Low Latency|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/an20_interspeech.html|ASR Neural Network Architectures and Training I|https://www.isca-speech.org/archive/interspeech_2020/an20_interspeech.html|
|CTC-Synchronous Training for Monotonic Attention Model|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/inaguma20_interspeech.html|ASR Neural Network Architectures and Training I|https://www.isca-speech.org/archive/interspeech_2020/inaguma20_interspeech.html|
|Continual Learning for Multi-Dialect Acoustic Models|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/houston20_interspeech.html|ASR Neural Network Architectures and Training I|https://www.isca-speech.org/archive/interspeech_2020/houston20_interspeech.html|
|SpecSwap: A Simple Data Augmentation Method for End-to-End Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/song20b_interspeech.html|ASR Neural Network Architectures and Training I|https://www.isca-speech.org/archive/interspeech_2020/song20b_interspeech.html|
|RECOApy: Data Recording, Pre-Processing and Phonetic Transcription for End-to-End Speech-Based Applications|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/stan20_interspeech.html|Evaluation of Speech Technology Systems and Methods for Resource Construction and Annotation|https://www.isca-speech.org/archive/interspeech_2020/stan20_interspeech.html|
|Analyzing the Quality and Stability of a Streaming End-to-End On-Device Speech Recognizer|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/shangguan20_interspeech.html|Evaluation of Speech Technology Systems and Methods for Resource Construction and Annotation|https://www.isca-speech.org/archive/interspeech_2020/shangguan20_interspeech.html|
|Statistical Testing on ASR Performance via Blockwise Bootstrap|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/liu20c_interspeech.html|Evaluation of Speech Technology Systems and Methods for Resource Construction and Annotation|https://www.isca-speech.org/archive/interspeech_2020/liu20c_interspeech.html|
|Sentence Level Estimation of Psycholinguistic Norms Using Joint Multidimensional Annotations|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ramakrishna20_interspeech.html|Evaluation of Speech Technology Systems and Methods for Resource Construction and Annotation|https://www.isca-speech.org/archive/interspeech_2020/ramakrishna20_interspeech.html|
|Neural Zero-Inflated Quality Estimation Model for Automatic Speech Recognition System|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/fan20_interspeech.html|Evaluation of Speech Technology Systems and Methods for Resource Construction and Annotation|https://www.isca-speech.org/archive/interspeech_2020/fan20_interspeech.html|
|Confidence Measures in Encoder-Decoder Models for Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/woodward20_interspeech.html|Evaluation of Speech Technology Systems and Methods for Resource Construction and Annotation|https://www.isca-speech.org/archive/interspeech_2020/woodward20_interspeech.html|
|Word Error Rate Estimation Without ASR Output: e-WER2|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ali20_interspeech.html|Evaluation of Speech Technology Systems and Methods for Resource Construction and Annotation|https://www.isca-speech.org/archive/interspeech_2020/ali20_interspeech.html|
|An Evaluation of Manual and Semi-Automatic Laughter Annotation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ludusan20_interspeech.html|Evaluation of Speech Technology Systems and Methods for Resource Construction and Annotation|https://www.isca-speech.org/archive/interspeech_2020/ludusan20_interspeech.html|
|Understanding Racial Disparities in Automatic Speech Recognition: The Case of Habitual “be”|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/martin20_interspeech.html|Evaluation of Speech Technology Systems and Methods for Resource Construction and Annotation|https://www.isca-speech.org/archive/interspeech_2020/martin20_interspeech.html|
|Secondary Phonetic Cues in the Production of the Nasal Short-a System in California English|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zellou20_interspeech.html|Phonetics and Phonology|https://www.isca-speech.org/archive/interspeech_2020/zellou20_interspeech.html|
|Acoustic Properties of Strident Fricatives at the Edges: Implications for Consonant Discrimination|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lorin20_interspeech.html|Phonetics and Phonology|https://www.isca-speech.org/archive/interspeech_2020/lorin20_interspeech.html|
|Processes and Consequences of Co-Articulation  in Mandarin V1N.(C2)V2 Context: Phonology and Phonetics|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/luo20_interspeech.html|Phonetics and Phonology|https://www.isca-speech.org/archive/interspeech_2020/luo20_interspeech.html|
|Voicing Distinction of Obstruents in the Hangzhou Wu Chinese Dialect|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yue20_interspeech.html|Phonetics and Phonology|https://www.isca-speech.org/archive/interspeech_2020/yue20_interspeech.html|
|The Phonology and Phonetics of Kaifeng Mandarin Vowels|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20f_interspeech.html|Phonetics and Phonology|https://www.isca-speech.org/archive/interspeech_2020/wang20f_interspeech.html|
|Microprosodic Variability in Plosives in German and Austrian German|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zellers20_interspeech.html|Phonetics and Phonology|https://www.isca-speech.org/archive/interspeech_2020/zellers20_interspeech.html|
|Er-Suffixation in Southwestern Mandarin: An EMA and Ultrasound Study|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/huang20b_interspeech.html|Phonetics and Phonology|https://www.isca-speech.org/archive/interspeech_2020/huang20b_interspeech.html|
|Electroglottographic-Phonetic Study on Korean Phonation Induced by Tripartite Plosives in Yanbian Korean|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20g_interspeech.html|Phonetics and Phonology|https://www.isca-speech.org/archive/interspeech_2020/li20g_interspeech.html|
|Modeling Global Body Configurations in American Sign Language|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wilkins20_interspeech.html|Phonetics and Phonology|https://www.isca-speech.org/archive/interspeech_2020/wilkins20_interspeech.html|
|Augmenting Turn-Taking Prediction with Wearable Eye Activity During Conversation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20h_interspeech.html|Topics in ASR I|https://www.isca-speech.org/archive/interspeech_2020/li20h_interspeech.html|
|CAM: Uninteresting Speech Detector|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lu20_interspeech.html|Topics in ASR I|https://www.isca-speech.org/archive/interspeech_2020/lu20_interspeech.html|
|Mixed Case Contextual ASR Using Capitalization Masks|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/caseiro20_interspeech.html|Topics in ASR I|https://www.isca-speech.org/archive/interspeech_2020/caseiro20_interspeech.html|
|Speech Recognition and Multi-Speaker Diarization of Long Conversations|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mao20b_interspeech.html|Topics in ASR I|https://www.isca-speech.org/archive/interspeech_2020/mao20b_interspeech.html|
|Investigation of Data Augmentation Techniques for Disordered Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/geng20_interspeech.html|Topics in ASR I|https://www.isca-speech.org/archive/interspeech_2020/geng20_interspeech.html|
|A Real-Time Robot-Based Auxiliary System for Risk Evaluation of COVID-19 Infection|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wei20_interspeech.html|Topics in ASR I|https://www.isca-speech.org/archive/interspeech_2020/wei20_interspeech.html|
|An Utterance Verification System for Word Naming Therapy in Aphasia|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/barbera20_interspeech.html|Topics in ASR I|https://www.isca-speech.org/archive/interspeech_2020/barbera20_interspeech.html|
|Exploiting Cross-Domain Visual Feature Generation for Disordered Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/liu20d_interspeech.html|Topics in ASR I|https://www.isca-speech.org/archive/interspeech_2020/liu20d_interspeech.html|
|Joint Prediction of Punctuation and Disfluency in Speech Transcripts|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lin20c_interspeech.html|Topics in ASR I|https://www.isca-speech.org/archive/interspeech_2020/lin20c_interspeech.html|
|Focal Loss for Punctuation Prediction|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yi20_interspeech.html|Topics in ASR I|https://www.isca-speech.org/archive/interspeech_2020/yi20_interspeech.html|
|Improving X-Vector and PLDA for Text-Dependent Speaker Verification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chen20d_interspeech.html|Large-Scale Evaluation of Short-Duration Speaker Verification|https://www.isca-speech.org/archive/interspeech_2020/chen20d_interspeech.html|
|SdSV Challenge 2020: Large-Scale Evaluation of Short-Duration Speaker Verification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zeinali20_interspeech.html|Large-Scale Evaluation of Short-Duration Speaker Verification|https://www.isca-speech.org/archive/interspeech_2020/zeinali20_interspeech.html|
|The XMUSPEECH System for Short-Duration Speaker Verification Challenge 2020|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/jiang20_interspeech.html|Large-Scale Evaluation of Short-Duration Speaker Verification|https://www.isca-speech.org/archive/interspeech_2020/jiang20_interspeech.html|
|Robust Text-Dependent Speaker Verification via Character-Level Information Preservation for the SdSV Challenge 2020|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mun20_interspeech.html|Large-Scale Evaluation of Short-Duration Speaker Verification|https://www.isca-speech.org/archive/interspeech_2020/mun20_interspeech.html|
|The TalTech Systems for the Short-Duration Speaker Verification Challenge 2020|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/alumae20_interspeech.html|Large-Scale Evaluation of Short-Duration Speaker Verification|https://www.isca-speech.org/archive/interspeech_2020/alumae20_interspeech.html|
|Investigation of NICT Submission for Short-Duration Speaker Verification Challenge 2020|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/shen20b_interspeech.html|Large-Scale Evaluation of Short-Duration Speaker Verification|https://www.isca-speech.org/archive/interspeech_2020/shen20b_interspeech.html|
|Cross-Lingual Speaker Verification with Domain-Balanced Hard Prototype Mining and Language-Dependent Score Normalization|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/thienpondt20_interspeech.html|Large-Scale Evaluation of Short-Duration Speaker Verification|https://www.isca-speech.org/archive/interspeech_2020/thienpondt20_interspeech.html|
|BUT Text-Dependent Speaker Verification System for SdSV Challenge 2020|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lozanodiez20_interspeech.html|Large-Scale Evaluation of Short-Duration Speaker Verification|https://www.isca-speech.org/archive/interspeech_2020/lozanodiez20_interspeech.html|
|Exploring the Use of an Unsupervised Autoregressive Model as a Shared Encoder for Text-Dependent Speaker Verification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ravi20_interspeech.html|Large-Scale Evaluation of Short-Duration Speaker Verification|https://www.isca-speech.org/archive/interspeech_2020/ravi20_interspeech.html|
|Recognition-Synthesis Based Non-Parallel Voice Conversion with Adversarial Learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20d_interspeech.html|Voice Conversion and Adaptation I|https://www.isca-speech.org/archive/interspeech_2020/zhang20d_interspeech.html|
|Improving the Speaker Identity of Non-Parallel Many-to-Many Voice Conversion with Adversarial Speaker Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ding20_interspeech.html|Voice Conversion and Adaptation I|https://www.isca-speech.org/archive/interspeech_2020/ding20_interspeech.html|
|Non-Parallel Many-to-Many Voice Conversion with PSR-StarGAN|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20i_interspeech.html|Voice Conversion and Adaptation I|https://www.isca-speech.org/archive/interspeech_2020/li20i_interspeech.html|
|TTS Skins: Speaker Conversion via ASR|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/polyak20_interspeech.html|Voice Conversion and Adaptation I|https://www.isca-speech.org/archive/interspeech_2020/polyak20_interspeech.html|
|GAZEV: GAN-Based Zero-Shot Voice Conversion Over Non-Parallel Speech Corpus|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20e_interspeech.html|Voice Conversion and Adaptation I|https://www.isca-speech.org/archive/interspeech_2020/zhang20e_interspeech.html|
|Spoken Content and Voice Factorization for Few-Shot Speaker Adaptation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20g_interspeech.html|Voice Conversion and Adaptation I|https://www.isca-speech.org/archive/interspeech_2020/wang20g_interspeech.html|
|Unsupervised Cross-Domain Singing Voice Conversion|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/polyak20b_interspeech.html|Voice Conversion and Adaptation I|https://www.isca-speech.org/archive/interspeech_2020/polyak20b_interspeech.html|
|Attention-Based Speaker Embeddings for One-Shot Voice Conversion|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ishihara20_interspeech.html|Voice Conversion and Adaptation I|https://www.isca-speech.org/archive/interspeech_2020/ishihara20_interspeech.html|
|Data Efficient Voice Cloning from Noisy Samples with Domain Adversarial Training|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/cong20_interspeech.html|Voice Conversion and Adaptation I|https://www.isca-speech.org/archive/interspeech_2020/cong20_interspeech.html|
|Gated Multi-Head Attention Pooling for Weakly Labelled Audio Tagging|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hong20_interspeech.html|Acoustic Event Detection|https://www.isca-speech.org/archive/interspeech_2020/hong20_interspeech.html|
|Environmental Sound Classification with Parallel Temporal-Spectral Attention|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20h_interspeech.html|Acoustic Event Detection|https://www.isca-speech.org/archive/interspeech_2020/wang20h_interspeech.html|
|Contrastive Predictive Coding of Audio with an Adversary|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20i_interspeech.html|Acoustic Event Detection|https://www.isca-speech.org/archive/interspeech_2020/wang20i_interspeech.html|
|Memory Controlled Sequential Self Attention for Sound Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/pankajakshan20_interspeech.html|Acoustic Event Detection|https://www.isca-speech.org/archive/interspeech_2020/pankajakshan20_interspeech.html|
|Dual Stage Learning Based Dynamic Time-Frequency Mask Generation for Audio Event Classification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kim20_interspeech.html|Acoustic Event Detection|https://www.isca-speech.org/archive/interspeech_2020/kim20_interspeech.html|
|An Effective Perturbation Based Semi-Supervised Learning Method for Sound Event Detection|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zheng20_interspeech.html|Acoustic Event Detection|https://www.isca-speech.org/archive/interspeech_2020/zheng20_interspeech.html|
|A Joint Framework for Audio Tagging and Weakly Supervised Acoustic Event Detection Using DenseNet with Global Average Pooling|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kao20_interspeech.html|Acoustic Event Detection|https://www.isca-speech.org/archive/interspeech_2020/kao20_interspeech.html|
|Intra-Utterance Similarity Preserving Knowledge Distillation for Audio Tagging|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chang20_interspeech.html|Acoustic Event Detection|https://www.isca-speech.org/archive/interspeech_2020/chang20_interspeech.html|
|Two-Stage Polyphonic Sound Event Detection Based on Faster R-CNN-LSTM with Multi-Token Connectionist Temporal Classification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/park20b_interspeech.html|Acoustic Event Detection|https://www.isca-speech.org/archive/interspeech_2020/park20b_interspeech.html|
|SpeechMix — Augmenting Deep Sound Recognition Using Hidden Space Interpolations|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/jindal20_interspeech.html|Acoustic Event Detection|https://www.isca-speech.org/archive/interspeech_2020/jindal20_interspeech.html|
|End-to-End Neural Transformer Based Spoken Language Understanding|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/radfar20_interspeech.html|Spoken Language Understanding I|https://www.isca-speech.org/archive/interspeech_2020/radfar20_interspeech.html|
|Jointly Encoding Word Confusion Network and Dialogue Context with BERT for Spoken Language Understanding|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/liu20e_interspeech.html|Spoken Language Understanding I|https://www.isca-speech.org/archive/interspeech_2020/liu20e_interspeech.html|
|Speech to Semantics: Improve ASR and NLU Jointly via All-Neural Interfaces|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/rao20_interspeech.html|Spoken Language Understanding I|https://www.isca-speech.org/archive/interspeech_2020/rao20_interspeech.html|
|Pretrained Semantic Speech Embeddings for End-to-End Spoken Language Understanding via Cross-Modal Teacher-Student Learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/denisov20_interspeech.html|Spoken Language Understanding I|https://www.isca-speech.org/archive/interspeech_2020/denisov20_interspeech.html|
|Context Dependent RNNLM for Automatic Transcription of Conversations|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chetupalli20_interspeech.html|Spoken Language Understanding I|https://www.isca-speech.org/archive/interspeech_2020/chetupalli20_interspeech.html|
|Improving End-to-End Speech-to-Intent Classification with Reptile|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/tian20b_interspeech.html|Spoken Language Understanding I|https://www.isca-speech.org/archive/interspeech_2020/tian20b_interspeech.html|
|Speech to Text Adaptation: Towards an Efficient Cross-Modal Distillation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/cho20_interspeech.html|Spoken Language Understanding I|https://www.isca-speech.org/archive/interspeech_2020/cho20_interspeech.html|
|Towards an ASR Error Robust Spoken Language Understanding System|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ruan20_interspeech.html|Spoken Language Understanding I|https://www.isca-speech.org/archive/interspeech_2020/ruan20_interspeech.html|
|End-to-End Spoken Language Understanding Without Full Transcripts|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kuo20_interspeech.html|Spoken Language Understanding I|https://www.isca-speech.org/archive/interspeech_2020/kuo20_interspeech.html|
|Are Neural Open-Domain Dialog Systems Robust to Speech Recognition Errors in the Dialog History? An Empirical Study|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/gopalakrishnan20_interspeech.html|Spoken Language Understanding I|https://www.isca-speech.org/archive/interspeech_2020/gopalakrishnan20_interspeech.html|
|AutoSpeech: Neural Architecture Search for Speaker Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ding20b_interspeech.html|DNN Architectures for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2020/ding20b_interspeech.html|
|Densely Connected Time Delay Neural Network for Speaker Verification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yu20b_interspeech.html|DNN Architectures for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2020/yu20b_interspeech.html|
|Phonetically-Aware Coupled Network For Short Duration Text-Independent Speaker Verification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zheng20b_interspeech.html|DNN Architectures for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2020/zheng20b_interspeech.html|
|Multi-Task Network for Noise-Robust Keyword Spotting and Speaker Verification Using CTC-Based Soft VAD and Global Query Attention|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/jung20_interspeech.html|DNN Architectures for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2020/jung20_interspeech.html|
|Vector-Based Attentive Pooling for Text-Independent Speaker Verification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wu20b_interspeech.html|DNN Architectures for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2020/wu20b_interspeech.html|
|Self-Attention Encoding and Pooling for Speaker Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/safari20_interspeech.html|DNN Architectures for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2020/safari20_interspeech.html|
|ARET: Aggregated Residual Extended Time-Delay Neural Networks for Speaker Verification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20f_interspeech.html|DNN Architectures for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2020/zhang20f_interspeech.html|
|Adversarial Separation Network for Speaker Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20g_interspeech.html|DNN Architectures for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2020/zhang20g_interspeech.html|
|Text-Independent Speaker Verification with Dual Attention Network|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20j_interspeech.html|DNN Architectures for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2020/li20j_interspeech.html|
|Evolutionary Algorithm Enhanced Neural Architecture Search for Text-Independent Speaker Verification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/qu20_interspeech.html|DNN Architectures for Speaker Recognition|https://www.isca-speech.org/archive/interspeech_2020/qu20_interspeech.html|
|Minimum Bayes Risk Training of RNN-Transducer for End-to-End Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/weng20_interspeech.html|ASR Model Training and Strategies|https://www.isca-speech.org/archive/interspeech_2020/weng20_interspeech.html|
|Semantic Mask for Transformer Based End-to-End Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20j_interspeech.html|ASR Model Training and Strategies|https://www.isca-speech.org/archive/interspeech_2020/wang20j_interspeech.html|
|Faster, Simpler and More Accurate Hybrid ASR Systems Using Wordpieces|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20h_interspeech.html|ASR Model Training and Strategies|https://www.isca-speech.org/archive/interspeech_2020/zhang20h_interspeech.html|
|A Federated Approach in Training Acoustic Models|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/dimitriadis20_interspeech.html|ASR Model Training and Strategies|https://www.isca-speech.org/archive/interspeech_2020/dimitriadis20_interspeech.html|
|On Semi-Supervised LF-MMI Training of Acoustic Models with Limited Data|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/sheikh20_interspeech.html|ASR Model Training and Strategies|https://www.isca-speech.org/archive/interspeech_2020/sheikh20_interspeech.html|
|On Front-End Gain Invariant Modeling for Wake Word Spotting|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/gao20b_interspeech.html|ASR Model Training and Strategies|https://www.isca-speech.org/archive/interspeech_2020/gao20b_interspeech.html|
|Unsupervised Regularization-Based Adaptive Training for Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ding20c_interspeech.html|ASR Model Training and Strategies|https://www.isca-speech.org/archive/interspeech_2020/ding20c_interspeech.html|
|On the Robustness and Training Dynamics of Raw Waveform Models|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/loweimi20_interspeech.html|ASR Model Training and Strategies|https://www.isca-speech.org/archive/interspeech_2020/loweimi20_interspeech.html|
|Iterative Pseudo-Labeling for Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/xu20b_interspeech.html|ASR Model Training and Strategies|https://www.isca-speech.org/archive/interspeech_2020/xu20b_interspeech.html|
|Smart Tube: A Biofeedback System for Vocal Training and Therapy Through Tube Phonation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kawamura20_interspeech.html|Speech Annotation and Speech Assessment|https://www.isca-speech.org/archive/interspeech_2020/kawamura20_interspeech.html|
|VCTUBE : A Library for Automatic Speech Data Annotation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/choi20_interspeech.html|Speech Annotation and Speech Assessment|https://www.isca-speech.org/archive/interspeech_2020/choi20_interspeech.html|
|A Mandarin L2 Learning APP with Mispronunciation Detection and Feedback|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/xie20_interspeech.html|Speech Annotation and Speech Assessment|https://www.isca-speech.org/archive/interspeech_2020/xie20_interspeech.html|
|Rapid Enhancement of NLP Systems by Acquisition of Data in Correlated Domains|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/udayakumar20_interspeech.html|Speech Annotation and Speech Assessment|https://www.isca-speech.org/archive/interspeech_2020/udayakumar20_interspeech.html|
|Computer-Assisted Language Learning System: Automatic Speech Evaluation for Children Learning Malay and Tamil|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/shi20_interspeech.html|Speech Annotation and Speech Assessment|https://www.isca-speech.org/archive/interspeech_2020/shi20_interspeech.html|
|Real-Time, Full-Band, Online DNN-Based Voice Conversion System Using a Single CPU|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/saeki20_interspeech.html|Speech Annotation and Speech Assessment|https://www.isca-speech.org/archive/interspeech_2020/saeki20_interspeech.html|
|A Dynamic 3D Pronunciation Teaching Model Based on Pronunciation Attributes and Anatomy|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/feng20b_interspeech.html|Speech Annotation and Speech Assessment|https://www.isca-speech.org/archive/interspeech_2020/feng20b_interspeech.html|
|End-to-End Deep Learning Speech Recognition Model for Silent Speech Challenge|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kimura20_interspeech.html|Speech Annotation and Speech Assessment|https://www.isca-speech.org/archive/interspeech_2020/kimura20_interspeech.html|
|Autosegmental Neural Nets: Should Phones and Tones be Synchronous or Asynchronous?|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20k_interspeech.html|Cross/Multi-Lingual and Code-Switched Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/li20k_interspeech.html|
|Development of Multilingual ASR Using GlobalPhone for Less-Resourced Languages: The Case of Ethiopian Languages|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/tachbelie20_interspeech.html|Cross/Multi-Lingual and Code-Switched Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/tachbelie20_interspeech.html|
|Large-Scale End-to-End Multilingual Speech Recognition and Language Identification with Multi-Task Learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hou20_interspeech.html|Cross/Multi-Lingual and Code-Switched Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/hou20_interspeech.html|
|Multi-Encoder-Decoder Transformer for Code-Switching Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhou20b_interspeech.html|Cross/Multi-Lingual and Code-Switched Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/zhou20b_interspeech.html|
|Multilingual Acoustic and Language Modeling for Ethio-Semitic Languages|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/abate20_interspeech.html|Cross/Multi-Lingual and Code-Switched Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/abate20_interspeech.html|
|Multilingual Jointly Trained Acoustic and Written Word Embeddings|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hu20c_interspeech.html|Cross/Multi-Lingual and Code-Switched Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/hu20c_interspeech.html|
|Improving Code-Switching Language Modeling with Artificially Generated Texts Using Cycle-Consistent Adversarial Networks|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20l_interspeech.html|Cross/Multi-Lingual and Code-Switched Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/li20l_interspeech.html|
|Data Augmentation for Code-Switch Language Modeling by Fusing Multiple Text Generation Methods|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hu20d_interspeech.html|Cross/Multi-Lingual and Code-Switched Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/hu20d_interspeech.html|
|A 43 Language Multilingual Punctuation Prediction Neural Network Model|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20m_interspeech.html|Cross/Multi-Lingual and Code-Switched Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/li20m_interspeech.html|
|Exploring Lexicon-Free Modeling Units for End-to-End Korean and Korean-English Code-Switching Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20k_interspeech.html|Cross/Multi-Lingual and Code-Switched Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/wang20k_interspeech.html|
|Multi-Task Siamese Neural Network for Improving Replay Attack Detection|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/platen20_interspeech.html|Anti-Spoofing and Liveness Detection|https://www.isca-speech.org/archive/interspeech_2020/platen20_interspeech.html|
|POCO: A Voice Spoofing and Liveness Detection Corpus Based on Pop Noise|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/akimoto20_interspeech.html|Anti-Spoofing and Liveness Detection|https://www.isca-speech.org/archive/interspeech_2020/akimoto20_interspeech.html|
|Dual-Adversarial Domain Adaptation for Generalized Replay Attack Detection|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20l_interspeech.html|Anti-Spoofing and Liveness Detection|https://www.isca-speech.org/archive/interspeech_2020/wang20l_interspeech.html|
|Self-Supervised Pre-Training with Acoustic Configurations for Replay Spoofing Detection|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/shim20_interspeech.html|Anti-Spoofing and Liveness Detection|https://www.isca-speech.org/archive/interspeech_2020/shim20_interspeech.html|
|Competency Evaluation in Voice Mimicking Using Acoustic Cues|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/g20_interspeech.html|Anti-Spoofing and Liveness Detection|https://www.isca-speech.org/archive/interspeech_2020/g20_interspeech.html|
|Light Convolutional Neural Network with Feature Genuinization for Detection of Synthetic Speech Attacks|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wu20c_interspeech.html|Anti-Spoofing and Liveness Detection|https://www.isca-speech.org/archive/interspeech_2020/wu20c_interspeech.html|
|Spoofing Attack Detection Using the Non-Linear Fusion of Sub-Band Classifiers|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/tak20_interspeech.html|Anti-Spoofing and Liveness Detection|https://www.isca-speech.org/archive/interspeech_2020/tak20_interspeech.html|
|Investigating Light-ResNet Architecture for Spoofing Detection Under Mismatched Conditions|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/parasu20_interspeech.html|Anti-Spoofing and Liveness Detection|https://www.isca-speech.org/archive/interspeech_2020/parasu20_interspeech.html|
|Siamese Convolutional Neural Network Using Gaussian Probability Feature for Spoofing Speech Detection|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lei20_interspeech.html|Anti-Spoofing and Liveness Detection|https://www.isca-speech.org/archive/interspeech_2020/lei20_interspeech.html|
|Lightweight Online Noise Reduction on Embedded Devices Using Hierarchical Recurrent Neural Networks|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/schroter20_interspeech.html|Noise Reduction and Intelligibility|https://www.isca-speech.org/archive/interspeech_2020/schroter20_interspeech.html|
|SEANet: A Multi-Modal Speech Enhancement Network|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/tagliasacchi20_interspeech.html|Noise Reduction and Intelligibility|https://www.isca-speech.org/archive/interspeech_2020/tagliasacchi20_interspeech.html|
|Lite Audio-Visual Speech Enhancement|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chuang20_interspeech.html|Noise Reduction and Intelligibility|https://www.isca-speech.org/archive/interspeech_2020/chuang20_interspeech.html|
|ORCA-CLEAN: A Deep Denoising Toolkit for Killer Whale Communication|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/bergler20_interspeech.html|Noise Reduction and Intelligibility|https://www.isca-speech.org/archive/interspeech_2020/bergler20_interspeech.html|
|A Deep Learning Approach to Active Noise Control|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20i_interspeech.html|Noise Reduction and Intelligibility|https://www.isca-speech.org/archive/interspeech_2020/zhang20i_interspeech.html|
|Improving Speech Intelligibility Through Speaker Dependent and Independent Spectral Style Conversion|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/dinh20_interspeech.html|Noise Reduction and Intelligibility|https://www.isca-speech.org/archive/interspeech_2020/dinh20_interspeech.html|
|End-to-End Speech Intelligibility Prediction Using Time-Domain Fully Convolutional Neural Networks|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/pedersen20_interspeech.html|Noise Reduction and Intelligibility|https://www.isca-speech.org/archive/interspeech_2020/pedersen20_interspeech.html|
|Predicting Intelligibility of Enhanced Speech Using Posteriors Derived from DNN-Based ASR System|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/arai20_interspeech.html|Noise Reduction and Intelligibility|https://www.isca-speech.org/archive/interspeech_2020/arai20_interspeech.html|
|Automatic Estimation of Intelligibility Measure for Consonants in Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/abavisani20_interspeech.html|Noise Reduction and Intelligibility|https://www.isca-speech.org/archive/interspeech_2020/abavisani20_interspeech.html|
|Large Scale Evaluation of Importance Maps in Automatic Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/trinh20_interspeech.html|Noise Reduction and Intelligibility|https://www.isca-speech.org/archive/interspeech_2020/trinh20_interspeech.html|
|Neural Architecture Search on Acoustic Scene Classification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20n_interspeech.html|Acoustic Scene Classification|https://www.isca-speech.org/archive/interspeech_2020/li20n_interspeech.html|
|Acoustic Scene Classification Using Audio Tagging|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/jung20b_interspeech.html|Acoustic Scene Classification|https://www.isca-speech.org/archive/interspeech_2020/jung20b_interspeech.html|
|ATReSN-Net: Capturing Attentive Temporal Relations in Semantic Neighborhood for Acoustic Scene Classification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20j_interspeech.html|Acoustic Scene Classification|https://www.isca-speech.org/archive/interspeech_2020/zhang20j_interspeech.html|
|Environment Sound Classification Using Multiple Feature Channels and Attention Based Deep Convolutional Neural Network|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/sharma20_interspeech.html|Acoustic Scene Classification|https://www.isca-speech.org/archive/interspeech_2020/sharma20_interspeech.html|
|Acoustic Scene Analysis with Multi-Head Attention Networks|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20m_interspeech.html|Acoustic Scene Classification|https://www.isca-speech.org/archive/interspeech_2020/wang20m_interspeech.html|
|Relational Teacher Student Learning with Neural Label Embedding for Device Adaptation in Acoustic Scene Classification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hu20e_interspeech.html|Acoustic Scene Classification|https://www.isca-speech.org/archive/interspeech_2020/hu20e_interspeech.html|
|An Acoustic Segment Model Based Segment Unit Selection Approach to Acoustic Scene Classification with Partial Utterances|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hu20f_interspeech.html|Acoustic Scene Classification|https://www.isca-speech.org/archive/interspeech_2020/hu20f_interspeech.html|
|Attention-Driven Projections for Soundscape Classification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/devalraju20_interspeech.html|Acoustic Scene Classification|https://www.isca-speech.org/archive/interspeech_2020/devalraju20_interspeech.html|
|Computer Audition for Continuous Rainforest Occupancy Monitoring: The Case of Bornean Gibbons’ Call Detection|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/tzirakis20_interspeech.html|Acoustic Scene Classification|https://www.isca-speech.org/archive/interspeech_2020/tzirakis20_interspeech.html|
|Deep Learning Based Open Set Acoustic Scene Classification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kwiatkowska20_interspeech.html|Acoustic Scene Classification|https://www.isca-speech.org/archive/interspeech_2020/kwiatkowska20_interspeech.html|
|Singing Synthesis: With a Little Help from my Attention|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/angelini20_interspeech.html|Singing Voice Computing and Processing in Music|https://www.isca-speech.org/archive/interspeech_2020/angelini20_interspeech.html|
|Peking Opera Synthesis via Duration Informed Attention Network|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wu20d_interspeech.html|Singing Voice Computing and Processing in Music|https://www.isca-speech.org/archive/interspeech_2020/wu20d_interspeech.html|
|DurIAN-SC: Duration Informed Attention Network Based Singing Voice Conversion System|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20k_interspeech.html|Singing Voice Computing and Processing in Music|https://www.isca-speech.org/archive/interspeech_2020/zhang20k_interspeech.html|
|Transfer Learning for Improving Singing-Voice Detection in Polyphonic Instrumental Music|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hou20b_interspeech.html|Singing Voice Computing and Processing in Music|https://www.isca-speech.org/archive/interspeech_2020/hou20b_interspeech.html|
|Channel-Wise Subband Input for Better Voice and Accompaniment Separation on High Resolution Music|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/liu20f_interspeech.html|Singing Voice Computing and Processing in Music|https://www.isca-speech.org/archive/interspeech_2020/liu20f_interspeech.html|
|Continual Learning in Automatic Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/sadhu20_interspeech.html|Acoustic Model Adaptation for ASR|https://www.isca-speech.org/archive/interspeech_2020/sadhu20_interspeech.html|
|Speaker Adaptive Training for Speech Recognition Based on Attention-Over-Attention Mechanism|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wan20_interspeech.html|Acoustic Model Adaptation for ASR|https://www.isca-speech.org/archive/interspeech_2020/wan20_interspeech.html|
|Rapid RNN-T Adaptation Using Personalized Speech Synthesis and Neural Language Generator|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/huang20c_interspeech.html|Acoustic Model Adaptation for ASR|https://www.isca-speech.org/archive/interspeech_2020/huang20c_interspeech.html|
|Speech Transformer with Speaker Aware Persistent Memory|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhao20b_interspeech.html|Acoustic Model Adaptation for ASR|https://www.isca-speech.org/archive/interspeech_2020/zhao20b_interspeech.html|
|Adaptive Speaker Normalization for CTC-Based Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ding20d_interspeech.html|Acoustic Model Adaptation for ASR|https://www.isca-speech.org/archive/interspeech_2020/ding20d_interspeech.html|
|Unsupervised Domain Adaptation Under Label Space Mismatch for Speech Classification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mathur20_interspeech.html|Acoustic Model Adaptation for ASR|https://www.isca-speech.org/archive/interspeech_2020/mathur20_interspeech.html|
|Learning Fast Adaptation on Cross-Accented Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/winata20_interspeech.html|Acoustic Model Adaptation for ASR|https://www.isca-speech.org/archive/interspeech_2020/winata20_interspeech.html|
|Black-Box Adaptation of ASR for Accented Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/khandelwal20_interspeech.html|Acoustic Model Adaptation for ASR|https://www.isca-speech.org/archive/interspeech_2020/khandelwal20_interspeech.html|
|Achieving Multi-Accent ASR via Unsupervised Acoustic Model Adaptation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/turan20_interspeech.html|Acoustic Model Adaptation for ASR|https://www.isca-speech.org/archive/interspeech_2020/turan20_interspeech.html|
|Frame-Wise Online Unsupervised Adaptation of DNN-HMM Acoustic Model from Perspective of Robust Adaptive Filtering|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/takeda20_interspeech.html|Acoustic Model Adaptation for ASR|https://www.isca-speech.org/archive/interspeech_2020/takeda20_interspeech.html|
|Adversarially Trained Multi-Singer Sequence-to-Sequence Singing Synthesizer|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wu20e_interspeech.html|Singing and Multimodal Synthesis|https://www.isca-speech.org/archive/interspeech_2020/wu20e_interspeech.html|
|Prediction of Head Motion from Speech Waveforms with a Canonical-Correlation-Constrained Autoencoder|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lu20b_interspeech.html|Singing and Multimodal Synthesis|https://www.isca-speech.org/archive/interspeech_2020/lu20b_interspeech.html|
|XiaoiceSing: A High-Quality and Integrated Singing Voice Synthesis System|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lu20c_interspeech.html|Singing and Multimodal Synthesis|https://www.isca-speech.org/archive/interspeech_2020/lu20c_interspeech.html|
|Stochastic Talking Face Generation Using Latent Distribution Matching|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yadav20_interspeech.html|Singing and Multimodal Synthesis|https://www.isca-speech.org/archive/interspeech_2020/yadav20_interspeech.html|
|Speech-to-Singing Conversion Based on Boundary Equilibrium GAN|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wu20f_interspeech.html|Singing and Multimodal Synthesis|https://www.isca-speech.org/archive/interspeech_2020/wu20f_interspeech.html|
|Face2Speech: Towards Multi-Speaker Text-to-Speech Synthesis Using an Embedding Vector Predicted from a Face Image|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/goto20_interspeech.html|Singing and Multimodal Synthesis|https://www.isca-speech.org/archive/interspeech_2020/goto20_interspeech.html|
|Speech Driven Talking Head Generation via Attentional Landmarks Based Representation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20n_interspeech.html|Singing and Multimodal Synthesis|https://www.isca-speech.org/archive/interspeech_2020/wang20n_interspeech.html|
|Optimization and Evaluation of an Intelligibility-Improving Signal Processing Approach (IISPA) for the Hurricane Challenge 2.0 with FADE|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/schadler20_interspeech.html|Intelligibility-Enhancing Speech Modification|https://www.isca-speech.org/archive/interspeech_2020/schadler20_interspeech.html|
|iMetricGAN: Intelligibility Enhancement for Speech-in-Noise Using Generative Adversarial Network-Based Metric Learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20o_interspeech.html|Intelligibility-Enhancing Speech Modification|https://www.isca-speech.org/archive/interspeech_2020/li20o_interspeech.html|
|Intelligibility-Enhancing Speech Modifications — The Hurricane Challenge 2.0|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/rennies20_interspeech.html|Intelligibility-Enhancing Speech Modification|https://www.isca-speech.org/archive/interspeech_2020/rennies20_interspeech.html|
|Exploring Listeners’ Speech Rate Preferences|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/simantiraki20_interspeech.html|Intelligibility-Enhancing Speech Modification|https://www.isca-speech.org/archive/interspeech_2020/simantiraki20_interspeech.html|
|Adaptive Compressive Onset-Enhancement for Improved Speech Intelligibility in Noise and Reverberation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/bederna20_interspeech.html|Intelligibility-Enhancing Speech Modification|https://www.isca-speech.org/archive/interspeech_2020/bederna20_interspeech.html|
|A Sound Engineering Approach to Near End Listening Enhancement|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chermaz20_interspeech.html|Intelligibility-Enhancing Speech Modification|https://www.isca-speech.org/archive/interspeech_2020/chermaz20_interspeech.html|
|Enhancing Speech Intelligibility in Text-To-Speech Synthesis Using Speaking Style Conversion|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/paul20b_interspeech.html|Intelligibility-Enhancing Speech Modification|https://www.isca-speech.org/archive/interspeech_2020/paul20b_interspeech.html|
|Two Different Mechanisms of Movable Mandible for Vocal-Tract Model with Flexible Tongue|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/arai20b_interspeech.html|Human Speech Production I|https://www.isca-speech.org/archive/interspeech_2020/arai20b_interspeech.html|
|Improving the Performance of Acoustic-to-Articulatory Inversion by Removing the Training Loss of Noncritical Portions of Articulatory Channels Dynamically|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/fang20_interspeech.html|Human Speech Production I|https://www.isca-speech.org/archive/interspeech_2020/fang20_interspeech.html|
|Speaker Conditioned Acoustic-to-Articulatory Inversion Using x-Vectors|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/illa20_interspeech.html|Human Speech Production I|https://www.isca-speech.org/archive/interspeech_2020/illa20_interspeech.html|
|Coarticulation as Synchronised Sequential Target Approximation: An EMA Study|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/liu20g_interspeech.html|Human Speech Production I|https://www.isca-speech.org/archive/interspeech_2020/liu20g_interspeech.html|
|Improved Model for Vocal Folds with a Polyp with Potential Application|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/santos20_interspeech.html|Human Speech Production I|https://www.isca-speech.org/archive/interspeech_2020/santos20_interspeech.html|
|Regional Resonance of the Lower Vocal Tract and its Contribution to Speaker Characteristics|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20l_interspeech.html|Human Speech Production I|https://www.isca-speech.org/archive/interspeech_2020/zhang20l_interspeech.html|
|Air-Tissue Boundary Segmentation in Real Time Magnetic Resonance Imaging Video Using 3-D Convolutional Neural Network|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mannem20_interspeech.html|Human Speech Production I|https://www.isca-speech.org/archive/interspeech_2020/mannem20_interspeech.html|
|An Investigation of the Virtual Lip Trajectories During the Production of Bilabial Stops and Nasal at Different Speaking Rates|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/purohit20_interspeech.html|Human Speech Production I|https://www.isca-speech.org/archive/interspeech_2020/purohit20_interspeech.html|
|SpEx+: A Complete Time Domain Speaker Extraction Network|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ge20_interspeech.html|Targeted Source Separation|https://www.isca-speech.org/archive/interspeech_2020/ge20_interspeech.html|
|Atss-Net: Target Speaker Separation via Attention-Based Neural Network|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20p_interspeech.html|Targeted Source Separation|https://www.isca-speech.org/archive/interspeech_2020/li20p_interspeech.html|
|Multimodal Target Speech Separation with Voice and Face References|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/qu20b_interspeech.html|Targeted Source Separation|https://www.isca-speech.org/archive/interspeech_2020/qu20b_interspeech.html|
|X-TaSNet: Robust and Accurate Time-Domain Speaker Extraction Network|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20m_interspeech.html|Targeted Source Separation|https://www.isca-speech.org/archive/interspeech_2020/zhang20m_interspeech.html|
|Listen, Watch and Understand at the Cocktail Party: Audio-Visual-Contextual Speech Separation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20q_interspeech.html|Targeted Source Separation|https://www.isca-speech.org/archive/interspeech_2020/li20q_interspeech.html|
|A Unified Framework for Low-Latency Speaker Extraction in Cocktail Party Environments|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hao20_interspeech.html|Targeted Source Separation|https://www.isca-speech.org/archive/interspeech_2020/hao20_interspeech.html|
|Time-Domain Target-Speaker Speech Separation with Waveform-Based Speaker Embedding|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhao20c_interspeech.html|Targeted Source Separation|https://www.isca-speech.org/archive/interspeech_2020/zhao20c_interspeech.html|
|Listen to What You Want: Neural Network-Based Universal Sound Selector|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ochiai20_interspeech.html|Targeted Source Separation|https://www.isca-speech.org/archive/interspeech_2020/ochiai20_interspeech.html|
|Crossmodal Sound Retrieval Based on Specific Target Co-Occurrence Denoted with Weak Labels|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yasuda20_interspeech.html|Targeted Source Separation|https://www.isca-speech.org/archive/interspeech_2020/yasuda20_interspeech.html|
|Speaker-Aware Monaural Speech Separation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/xu20c_interspeech.html|Targeted Source Separation|https://www.isca-speech.org/archive/interspeech_2020/xu20c_interspeech.html|
|Brain networks enabling speech perception in everyday settings|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/shinncunningham20_interspeech.html|Keynote 2|https://www.isca-speech.org/archive/interspeech_2020/shinncunningham20_interspeech.html|
|A DNN-HMM-DNN Hybrid Model for Discovering Word-Like Units from Spoken Captions and Image Regions|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20o_interspeech.html|Speech Translation and Multilingual/Multimodal Learning|https://www.isca-speech.org/archive/interspeech_2020/wang20o_interspeech.html|
|Efficient Wait-k Models for Simultaneous Machine Translation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/elbayad20_interspeech.html|Speech Translation and Multilingual/Multimodal Learning|https://www.isca-speech.org/archive/interspeech_2020/elbayad20_interspeech.html|
|Investigating Self-Supervised Pre-Training for End-to-End Speech Translation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/nguyen20_interspeech.html|Speech Translation and Multilingual/Multimodal Learning|https://www.isca-speech.org/archive/interspeech_2020/nguyen20_interspeech.html|
|Contextualized Translation of Automatically Segmented Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/gaido20_interspeech.html|Speech Translation and Multilingual/Multimodal Learning|https://www.isca-speech.org/archive/interspeech_2020/gaido20_interspeech.html|
|Self-Training for End-to-End Speech Translation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/pino20_interspeech.html|Speech Translation and Multilingual/Multimodal Learning|https://www.isca-speech.org/archive/interspeech_2020/pino20_interspeech.html|
|Evaluating and Optimizing Prosodic Alignment for Automatic Dubbing|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/federico20_interspeech.html|Speech Translation and Multilingual/Multimodal Learning|https://www.isca-speech.org/archive/interspeech_2020/federico20_interspeech.html|
|Pair Expansion for Learning Multilingual Semantic Embeddings Using Disjoint Visually-Grounded Speech Audio Datasets|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ohishi20_interspeech.html|Speech Translation and Multilingual/Multimodal Learning|https://www.isca-speech.org/archive/interspeech_2020/ohishi20_interspeech.html|
|Self-Supervised Representations Improve End-to-End Speech Translation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wu20g_interspeech.html|Speech Translation and Multilingual/Multimodal Learning|https://www.isca-speech.org/archive/interspeech_2020/wu20g_interspeech.html|
|Improved RawNet with Feature Map Scaling for Text-Independent Speaker Verification Using Raw Waveforms|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/jung20c_interspeech.html|Speaker Recognition I|https://www.isca-speech.org/archive/interspeech_2020/jung20c_interspeech.html|
|Improving Multi-Scale Aggregation Using Feature Pyramid Module for Robust Speaker Verification of Variable-Duration Utterances|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/jung20d_interspeech.html|Speaker Recognition I|https://www.isca-speech.org/archive/interspeech_2020/jung20d_interspeech.html|
|An Adaptive X-Vector Model for Text-Independent Speaker Verification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/gu20_interspeech.html|Speaker Recognition I|https://www.isca-speech.org/archive/interspeech_2020/gu20_interspeech.html|
|Shouted Speech Compensation for Speaker Verification Robust to Vocal Effort Conditions|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/prieto20_interspeech.html|Speaker Recognition I|https://www.isca-speech.org/archive/interspeech_2020/prieto20_interspeech.html|
|Sum-Product Networks for Robust Automatic Speaker Identification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/nicolson20_interspeech.html|Speaker Recognition I|https://www.isca-speech.org/archive/interspeech_2020/nicolson20_interspeech.html|
|Segment Aggregation for Short Utterances Speaker Verification Using Raw Waveforms|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kim20b_interspeech.html|Speaker Recognition I|https://www.isca-speech.org/archive/interspeech_2020/kim20b_interspeech.html|
|Siamese X-Vector Reconstruction for Domain Adapted Speaker Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/rozenberg20_interspeech.html|Speaker Recognition I|https://www.isca-speech.org/archive/interspeech_2020/rozenberg20_interspeech.html|
|Speaker Re-Identification with Speaker Dependent Speech Enhancement|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/shi20b_interspeech.html|Speaker Recognition I|https://www.isca-speech.org/archive/interspeech_2020/shi20b_interspeech.html|
|Blind Speech Signal Quality Estimation for Speaker Verification Systems|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lavrentyeva20_interspeech.html|Speaker Recognition I|https://www.isca-speech.org/archive/interspeech_2020/lavrentyeva20_interspeech.html|
|Investigating Robustness of Adversarial Samples Detection for Automatic Speaker Verification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20r_interspeech.html|Speaker Recognition I|https://www.isca-speech.org/archive/interspeech_2020/li20r_interspeech.html|
|Modeling ASR Ambiguity for Neural Dialogue State Tracking|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/pal20_interspeech.html|Spoken Language Understanding II|https://www.isca-speech.org/archive/interspeech_2020/pal20_interspeech.html|
|ASR Error Correction with Augmented Transformer for Entity Retrieval|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20p_interspeech.html|Spoken Language Understanding II|https://www.isca-speech.org/archive/interspeech_2020/wang20p_interspeech.html|
|Large-Scale Transfer Learning for Low-Resource Spoken Language Understanding|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/jia20_interspeech.html|Spoken Language Understanding II|https://www.isca-speech.org/archive/interspeech_2020/jia20_interspeech.html|
|Data Balancing for Boosting Performance of Low-Frequency Classes in Spoken Language Understanding|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/gaspers20_interspeech.html|Spoken Language Understanding II|https://www.isca-speech.org/archive/interspeech_2020/gaspers20_interspeech.html|
|An Interactive Adversarial Reward Learning-Based Spoken Language Understanding System|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20q_interspeech.html|Spoken Language Understanding II|https://www.isca-speech.org/archive/interspeech_2020/wang20q_interspeech.html|
|Style Attuned Pre-Training and Parameter Efficient Fine-Tuning for Spoken Language Understanding|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/cao20_interspeech.html|Spoken Language Understanding II|https://www.isca-speech.org/archive/interspeech_2020/cao20_interspeech.html|
|Unsupervised Domain Adaptation for Dialogue Sequence Labeling Based on Hierarchical Adversarial Training|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/orihashi20_interspeech.html|Spoken Language Understanding II|https://www.isca-speech.org/archive/interspeech_2020/orihashi20_interspeech.html|
|Deep F-Measure Maximization for End-to-End Speech Understanding|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/sar20_interspeech.html|Spoken Language Understanding II|https://www.isca-speech.org/archive/interspeech_2020/sar20_interspeech.html|
|An Effective Domain Adaptive Post-Training Method for BERT in Response Selection|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/whang20_interspeech.html|Spoken Language Understanding II|https://www.isca-speech.org/archive/interspeech_2020/whang20_interspeech.html|
|Confidence Measure for Speech-to-Concept End-to-End Spoken Language Understanding|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/caubriere20_interspeech.html|Spoken Language Understanding II|https://www.isca-speech.org/archive/interspeech_2020/caubriere20_interspeech.html|
|Attention to Indexical Information Improves Voice Recall|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mcguire20_interspeech.html|Human Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/mcguire20_interspeech.html|
|Categorization of Whistled Consonants by French Speakers|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ngoc20_interspeech.html|Human Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/ngoc20_interspeech.html|
|Whistled Vowel Identification by French Listeners|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ngoc20b_interspeech.html|Human Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/ngoc20b_interspeech.html|
|F0 Slope and Mean: Cues to Speech Segmentation in French|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/cordero20_interspeech.html|Human Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/cordero20_interspeech.html|
|Does French Listeners’ Ability to Use Accentual Information at the Word Level Depend on the Ear of Presentation?|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/michelas20_interspeech.html|Human Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/michelas20_interspeech.html|
|A Perceptual Study of the Five Level Tones in Hmu (Xinzhai Variety)|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/liu20h_interspeech.html|Human Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/liu20h_interspeech.html|
|Mandarin and English Adults’ Cue-Weighting of Lexical Stress|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zeng20_interspeech.html|Human Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/zeng20_interspeech.html|
|Age-Related Differences of Tone Perception in Mandarin-Speaking Seniors|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/feng20c_interspeech.html|Human Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/feng20c_interspeech.html|
|Social and Functional Pressures in Vocal Alignment: Differences for Human and Voice-AI Interlocutors|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zellou20b_interspeech.html|Human Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/zellou20b_interspeech.html|
|Identifying Important Time-Frequency Locations in Continuous Speech Utterances|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kavaki20_interspeech.html|Human Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/kavaki20_interspeech.html|
|Raw Sign and Magnitude Spectra for Multi-Head Acoustic Modelling|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/loweimi20b_interspeech.html|Feature Extraction and Distant ASR|https://www.isca-speech.org/archive/interspeech_2020/loweimi20b_interspeech.html|
|Robust Raw Waveform Speech Recognition Using Relevance Weighted Representations|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/agrawal20_interspeech.html|Feature Extraction and Distant ASR|https://www.isca-speech.org/archive/interspeech_2020/agrawal20_interspeech.html|
|A Deep 2D Convolutional Network for Waveform-Based Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/oglic20_interspeech.html|Feature Extraction and Distant ASR|https://www.isca-speech.org/archive/interspeech_2020/oglic20_interspeech.html|
|Lightweight End-to-End Speech Recognition from Raw Audio Data Using Sinc-Convolutions|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kurzinger20_interspeech.html|Feature Extraction and Distant ASR|https://www.isca-speech.org/archive/interspeech_2020/kurzinger20_interspeech.html|
|An Alternative to MFCCs for ASR|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ghahramani20_interspeech.html|Feature Extraction and Distant ASR|https://www.isca-speech.org/archive/interspeech_2020/ghahramani20_interspeech.html|
|Phase Based Spectro-Temporal Features for Building a Robust ASR System|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/dutta20_interspeech.html|Feature Extraction and Distant ASR|https://www.isca-speech.org/archive/interspeech_2020/dutta20_interspeech.html|
|Deep Scattering Power Spectrum Features for Robust Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/joy20_interspeech.html|Feature Extraction and Distant ASR|https://www.isca-speech.org/archive/interspeech_2020/joy20_interspeech.html|
|FusionRNN: Shared Neural Parameters for Multi-Channel Distant Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/parcollet20_interspeech.html|Feature Extraction and Distant ASR|https://www.isca-speech.org/archive/interspeech_2020/parcollet20_interspeech.html|
|Bandpass Noise Generation and Augmentation for Unified ASR|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kumar20b_interspeech.html|Feature Extraction and Distant ASR|https://www.isca-speech.org/archive/interspeech_2020/kumar20b_interspeech.html|
|Deep Learning Based Dereverberation of Temporal Envelopes for Robust Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/purushothaman20_interspeech.html|Feature Extraction and Distant ASR|https://www.isca-speech.org/archive/interspeech_2020/purushothaman20_interspeech.html|
|Introducing the VoicePrivacy Initiative|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/tomashenko20_interspeech.html|Voice Privacy Challenge|https://www.isca-speech.org/archive/interspeech_2020/tomashenko20_interspeech.html|
|The Privacy ZEBRA: Zero Evidence Biometric Recognition Assessment|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/nautsch20_interspeech.html|Voice Privacy Challenge|https://www.isca-speech.org/archive/interspeech_2020/nautsch20_interspeech.html|
|X-Vector Singular Value Modification and Statistical-Based Decomposition with Ensemble Regression Modeling for Speaker Anonymization System|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mawalim20_interspeech.html|Voice Privacy Challenge|https://www.isca-speech.org/archive/interspeech_2020/mawalim20_interspeech.html|
|A Comparative Study of Speech Anonymization Metrics|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/maouche20_interspeech.html|Voice Privacy Challenge|https://www.isca-speech.org/archive/interspeech_2020/maouche20_interspeech.html|
|Design Choices for X-Vector Based Speaker Anonymization|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/srivastava20_interspeech.html|Voice Privacy Challenge|https://www.isca-speech.org/archive/interspeech_2020/srivastava20_interspeech.html|
|Speech Pseudonymisation Assessment Using Voice Similarity Matrices|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/noe20_interspeech.html|Voice Privacy Challenge|https://www.isca-speech.org/archive/interspeech_2020/noe20_interspeech.html|
|g2pM: A Neural Grapheme-to-Phoneme Conversion Package for Mandarin Chinese Based on a New Open Benchmark Dataset|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/park20c_interspeech.html|Speech Synthesis: Text Processing, Data and Evaluation|https://www.isca-speech.org/archive/interspeech_2020/park20c_interspeech.html|
|A Mask-Based Model for Mandarin Chinese Polyphone Disambiguation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20n_interspeech.html|Speech Synthesis: Text Processing, Data and Evaluation|https://www.isca-speech.org/archive/interspeech_2020/zhang20n_interspeech.html|
|Perception of Concatenative vs. Neural Text-To-Speech (TTS): Differences in Intelligibility in Noise and Language Attitudes|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/cohn20_interspeech.html|Speech Synthesis: Text Processing, Data and Evaluation|https://www.isca-speech.org/archive/interspeech_2020/cohn20_interspeech.html|
|Enhancing Sequence-to-Sequence Text-to-Speech with Morphology|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/taylor20_interspeech.html|Speech Synthesis: Text Processing, Data and Evaluation|https://www.isca-speech.org/archive/interspeech_2020/taylor20_interspeech.html|
|Deep MOS Predictor for Synthetic Speech Using Cluster-Based Modeling|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/choi20b_interspeech.html|Speech Synthesis: Text Processing, Data and Evaluation|https://www.isca-speech.org/archive/interspeech_2020/choi20b_interspeech.html|
|Deep Learning Based Assessment of Synthetic Speech Naturalness|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mittag20_interspeech.html|Speech Synthesis: Text Processing, Data and Evaluation|https://www.isca-speech.org/archive/interspeech_2020/mittag20_interspeech.html|
|Distant Supervision for Polyphone Disambiguation in Mandarin Chinese|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20o_interspeech.html|Speech Synthesis: Text Processing, Data and Evaluation|https://www.isca-speech.org/archive/interspeech_2020/zhang20o_interspeech.html|
|An Unsupervised Method to Select a Speaker Subset from Large Multi-Speaker Speech Synthesis Datasets|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/gallegos20_interspeech.html|Speech Synthesis: Text Processing, Data and Evaluation|https://www.isca-speech.org/archive/interspeech_2020/gallegos20_interspeech.html|
|Understanding the Effect of Voice Quality and Accent on Talker Similarity|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/das20_interspeech.html|Speech Synthesis: Text Processing, Data and Evaluation|https://www.isca-speech.org/archive/interspeech_2020/das20_interspeech.html|
|Robust Beam Search for Encoder-Decoder Attention Based Speech Recognition Without Length Bias|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhou20c_interspeech.html|Search for Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/zhou20c_interspeech.html|
|Transformer with Bidirectional Decoder for Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chen20e_interspeech.html|Search for Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/chen20e_interspeech.html|
|An Investigation of Phone-Based Subword Units for End-to-End Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20r_interspeech.html|Search for Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/wang20r_interspeech.html|
|Combination of End-to-End and Hybrid Models for Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wong20_interspeech.html|Search for Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/wong20_interspeech.html|
|Evolved Speech-Transformer: Applying Neural Architecture Search to End-to-End Automatic Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kim20c_interspeech.html|Search for Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/kim20c_interspeech.html|
|Hierarchical Multi-Stage Word-to-Grapheme Named Entity Corrector for Automatic Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/garg20_interspeech.html|Search for Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/garg20_interspeech.html|
|LVCSR with Transformer Language Models|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/beck20_interspeech.html|Search for Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/beck20_interspeech.html|
|DARTS-ASR: Differentiable Architecture Search for Multilingual Speech Recognition and Adaptation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chen20f_interspeech.html|Search for Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/chen20f_interspeech.html|
|Uncertainty-Aware Machine Support for Paper Reviewing on the Interspeech 2019 Submission Corpus|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/stappen20_interspeech.html|Computational Paralinguistics I|https://www.isca-speech.org/archive/interspeech_2020/stappen20_interspeech.html|
|Individual Variation in Language Attitudes Toward Voice-AI: The Role of Listeners’ Autistic-Like Traits|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/cohn20b_interspeech.html|Computational Paralinguistics I|https://www.isca-speech.org/archive/interspeech_2020/cohn20b_interspeech.html|
|Differences in Gradient Emotion Perception: Human vs. Alexa Voices|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/cohn20c_interspeech.html|Computational Paralinguistics I|https://www.isca-speech.org/archive/interspeech_2020/cohn20c_interspeech.html|
|The MSP-Conversation Corpus|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/martinezlucas20_interspeech.html|Computational Paralinguistics I|https://www.isca-speech.org/archive/interspeech_2020/martinezlucas20_interspeech.html|
|Spotting the Traces of Depression in Read Speech: An Approach Based on Computational Paralinguistics and Social Signal Processing|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/tao20_interspeech.html|Computational Paralinguistics I|https://www.isca-speech.org/archive/interspeech_2020/tao20_interspeech.html|
|Speech Sentiment and Customer Satisfaction Estimation in Socialbot Conversations|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kim20d_interspeech.html|Computational Paralinguistics I|https://www.isca-speech.org/archive/interspeech_2020/kim20d_interspeech.html|
|Pardon the Interruption: An Analysis of Gender and Turn-Taking in U.S. Supreme Court Oral Arguments|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lepp20_interspeech.html|Computational Paralinguistics I|https://www.isca-speech.org/archive/interspeech_2020/lepp20_interspeech.html|
|Are Germans Better Haters Than Danes? Language-Specific Implicit Prosodies of Types of Hate Speech and How They Relate to Perceived Severity and Societal Rules|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/neitsch20_interspeech.html|Computational Paralinguistics I|https://www.isca-speech.org/archive/interspeech_2020/neitsch20_interspeech.html|
|An Objective Voice Gender Scoring System and Identification of the Salient Acoustic Measures|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chen20g_interspeech.html|Computational Paralinguistics I|https://www.isca-speech.org/archive/interspeech_2020/chen20g_interspeech.html|
|How Ordinal Are Your Data?|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/jayawardena20_interspeech.html|Computational Paralinguistics I|https://www.isca-speech.org/archive/interspeech_2020/jayawardena20_interspeech.html|
|Correlating Cepstra with Formant Frequencies: Implications for Phonetically-Informed Forensic Voice Comparison|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hughes20_interspeech.html|Acoustic Phonetics and Prosody|https://www.isca-speech.org/archive/interspeech_2020/hughes20_interspeech.html|
|Prosody and Breathing: A Comparison Between Rhetorical and Information-Seeking Questions in German and Brazilian Portuguese|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/neitsch20b_interspeech.html|Acoustic Phonetics and Prosody|https://www.isca-speech.org/archive/interspeech_2020/neitsch20b_interspeech.html|
|Scaling Processes of Clause Chains in Pitjantjatjara|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/defina20_interspeech.html|Acoustic Phonetics and Prosody|https://www.isca-speech.org/archive/interspeech_2020/defina20_interspeech.html|
|Neutralization of Voicing Distinction of Stops in Tohoku Dialects of Japanese: Field Work and Acoustic Measurements|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mizoguchi20_interspeech.html|Acoustic Phonetics and Prosody|https://www.isca-speech.org/archive/interspeech_2020/mizoguchi20_interspeech.html|
|Correlation Between Prosody and Pragmatics: Case Study of Discourse Markers in French and English|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lee20b_interspeech.html|Acoustic Phonetics and Prosody|https://www.isca-speech.org/archive/interspeech_2020/lee20b_interspeech.html|
|An Analysis of Prosodic Prominence Cues to Information Structure in Egyptian Arabic|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zarka20_interspeech.html|Acoustic Phonetics and Prosody|https://www.isca-speech.org/archive/interspeech_2020/zarka20_interspeech.html|
|Lexical Stress in Urdu|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mumtaz20_interspeech.html|Acoustic Phonetics and Prosody|https://www.isca-speech.org/archive/interspeech_2020/mumtaz20_interspeech.html|
|Vocal Markers from Sustained Phonation in Huntington’s Disease|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/riad20_interspeech.html|Acoustic Phonetics and Prosody|https://www.isca-speech.org/archive/interspeech_2020/riad20_interspeech.html|
|How Rhythm and Timbre Encode Mooré Language in Bendré Drummed Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/dentel20_interspeech.html|Acoustic Phonetics and Prosody|https://www.isca-speech.org/archive/interspeech_2020/dentel20_interspeech.html|
|Doing Something we Never could with Spoken Language Technologies-from early days to the era of deep learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lee20_interspeech.html|Keynote 3|https://www.isca-speech.org/archive/interspeech_2020/lee20_interspeech.html|
|Interaction of Tone and Voicing in Mizo|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lalhminghlui20_interspeech.html|Tonal Aspects of Acoustic Phonetics and Prosody|https://www.isca-speech.org/archive/interspeech_2020/lalhminghlui20_interspeech.html|
|Mandarin Lexical Tones: A Corpus-Based Study of Word Length, Syllable Position and Prosodic Position on Duration|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wu20h_interspeech.html|Tonal Aspects of Acoustic Phonetics and Prosody|https://www.isca-speech.org/archive/interspeech_2020/wu20h_interspeech.html|
|An Investigation of the Target Approximation Model for Tone Modeling and Recognition in Continuous Mandarin Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/gao20c_interspeech.html|Tonal Aspects of Acoustic Phonetics and Prosody|https://www.isca-speech.org/archive/interspeech_2020/gao20c_interspeech.html|
|Integrating the Application and Realization of Mandarin 3rd Tone Sandhi in the Resolution of Sentence Ambiguity|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lai20_interspeech.html|Tonal Aspects of Acoustic Phonetics and Prosody|https://www.isca-speech.org/archive/interspeech_2020/lai20_interspeech.html|
|Neutral Tone in Changde Mandarin|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20p_interspeech.html|Tonal Aspects of Acoustic Phonetics and Prosody|https://www.isca-speech.org/archive/interspeech_2020/zhang20p_interspeech.html|
|Pitch Declination and Final Lowering in Northeastern Mandarin|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/cui20_interspeech.html|Tonal Aspects of Acoustic Phonetics and Prosody|https://www.isca-speech.org/archive/interspeech_2020/cui20_interspeech.html|
|Variation in Spectral Slope and Interharmonic Noise in Cantonese Tones|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/rose20_interspeech.html|Tonal Aspects of Acoustic Phonetics and Prosody|https://www.isca-speech.org/archive/interspeech_2020/rose20_interspeech.html|
|The Acoustic Realization of Mandarin Tones in Fast Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/tang20_interspeech.html|Tonal Aspects of Acoustic Phonetics and Prosody|https://www.isca-speech.org/archive/interspeech_2020/tang20_interspeech.html|
|Do Face Masks Introduce Bias in Speech Technologies? The Case of Automated Scoring of Speaking Proficiency|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/loukina20_interspeech.html|Speech Classification|https://www.isca-speech.org/archive/interspeech_2020/loukina20_interspeech.html|
|A Low Latency ASR-Free End to End Spoken Language Understanding System|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mhiri20_interspeech.html|Speech Classification|https://www.isca-speech.org/archive/interspeech_2020/mhiri20_interspeech.html|
|An Audio-Based Wakeword-Independent Verification System|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20s_interspeech.html|Speech Classification|https://www.isca-speech.org/archive/interspeech_2020/wang20s_interspeech.html|
|Learnable Spectro-Temporal Receptive Fields for Robust Voice Type Discrimination|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/vuong20_interspeech.html|Speech Classification|https://www.isca-speech.org/archive/interspeech_2020/vuong20_interspeech.html|
|Low Latency Speech Recognition Using End-to-End Prefetching|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chang20b_interspeech.html|Speech Classification|https://www.isca-speech.org/archive/interspeech_2020/chang20b_interspeech.html|
|AutoSpeech 2020: The Second Automated Machine Learning Challenge for Speech Classification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20t_interspeech.html|Speech Classification|https://www.isca-speech.org/archive/interspeech_2020/wang20t_interspeech.html|
|Building a Robust Word-Level Wakeword Verification Network|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kumar20c_interspeech.html|Speech Classification|https://www.isca-speech.org/archive/interspeech_2020/kumar20c_interspeech.html|
|A Transformer-Based Audio Captioning Model with Keyword Estimation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/koizumi20_interspeech.html|Speech Classification|https://www.isca-speech.org/archive/interspeech_2020/koizumi20_interspeech.html|
|Neural Architecture Search for Keyword Spotting|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mo20_interspeech.html|Speech Classification|https://www.isca-speech.org/archive/interspeech_2020/mo20_interspeech.html|
|Small-Footprint Keyword Spotting with Multi-Scale Temporal Convolution|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20s_interspeech.html|Speech Classification|https://www.isca-speech.org/archive/interspeech_2020/li20s_interspeech.html|
|Using Cyclic Noise as the Source Signal for Neural Source-Filter-Based Speech Waveform Model|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20u_interspeech.html|Speech Synthesis Paradigms and Methods I|https://www.isca-speech.org/archive/interspeech_2020/wang20u_interspeech.html|
|Unconditional Audio Generation with Generative Adversarial Networks and Cycle Regularization|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/liu20i_interspeech.html|Speech Synthesis Paradigms and Methods I|https://www.isca-speech.org/archive/interspeech_2020/liu20i_interspeech.html|
|Complex-Valued Variational Autoencoder: A Novel Deep Generative Model for Direct Representation of Complex Spectra|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/nakashika20_interspeech.html|Speech Synthesis Paradigms and Methods I|https://www.isca-speech.org/archive/interspeech_2020/nakashika20_interspeech.html|
|Attentron: Few-Shot Text-to-Speech Utilizing Attention-Based Variable-Length Embedding|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/choi20c_interspeech.html|Speech Synthesis Paradigms and Methods I|https://www.isca-speech.org/archive/interspeech_2020/choi20c_interspeech.html|
|Reformer-TTS: Neural Speech Synthesis with Reformer Network|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ihm20_interspeech.html|Speech Synthesis Paradigms and Methods I|https://www.isca-speech.org/archive/interspeech_2020/ihm20_interspeech.html|
|CycleGAN-VC3: Examining and Improving CycleGAN-VCs for Mel-Spectrogram Conversion|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kaneko20_interspeech.html|Speech Synthesis Paradigms and Methods I|https://www.isca-speech.org/archive/interspeech_2020/kaneko20_interspeech.html|
|High Quality Streaming Speech Synthesis with Low, Sentence-Length-Independent Latency|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ellinas20_interspeech.html|Speech Synthesis Paradigms and Methods I|https://www.isca-speech.org/archive/interspeech_2020/ellinas20_interspeech.html|
|DurIAN: Duration Informed Attention Network for Speech Synthesis|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yu20c_interspeech.html|Speech Synthesis Paradigms and Methods I|https://www.isca-speech.org/archive/interspeech_2020/yu20c_interspeech.html|
|Multi-Speaker Text-to-Speech Synthesis Using Deep Gaussian Processes|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mitsui20_interspeech.html|Speech Synthesis Paradigms and Methods I|https://www.isca-speech.org/archive/interspeech_2020/mitsui20_interspeech.html|
|A Hybrid HMM-Waveglow Based Text-to-Speech Synthesizer Using Histogram Equalization for Low Resource Indian Languages|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/m20_interspeech.html|Speech Synthesis Paradigms and Methods I|https://www.isca-speech.org/archive/interspeech_2020/m20_interspeech.html|
|The INTERSPEECH 2020 Computational Paralinguistics Challenge: Elderly Emotion, Breathing & Masks|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/schuller20_interspeech.html|The INTERSPEECH 2020 Computational Paralinguistics ChallengE (ComParE)|https://www.isca-speech.org/archive/interspeech_2020/schuller20_interspeech.html|
|Learning Higher Representations from Pre-Trained Deep Models with Data Augmentation for the COMPARE 2020 Challenge Mask Task|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/koike20_interspeech.html|The INTERSPEECH 2020 Computational Paralinguistics ChallengE (ComParE)|https://www.isca-speech.org/archive/interspeech_2020/koike20_interspeech.html|
|Surgical Mask Detection with Convolutional Neural Networks and Data Augmentations on Spectrograms|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/illium20_interspeech.html|The INTERSPEECH 2020 Computational Paralinguistics ChallengE (ComParE)|https://www.isca-speech.org/archive/interspeech_2020/illium20_interspeech.html|
|Surgical Mask Detection with Deep Recurrent Phonetic Models|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/klumpp20_interspeech.html|The INTERSPEECH 2020 Computational Paralinguistics ChallengE (ComParE)|https://www.isca-speech.org/archive/interspeech_2020/klumpp20_interspeech.html|
|Phonetic, Frame Clustering and Intelligibility Analyses for the INTERSPEECH 2020 ComParE Challenge|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/montacie20_interspeech.html|The INTERSPEECH 2020 Computational Paralinguistics ChallengE (ComParE)|https://www.isca-speech.org/archive/interspeech_2020/montacie20_interspeech.html|
|Exploring Text and Audio Embeddings for Multi-Dimension Elderly Emotion Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/juliao20_interspeech.html|The INTERSPEECH 2020 Computational Paralinguistics ChallengE (ComParE)|https://www.isca-speech.org/archive/interspeech_2020/juliao20_interspeech.html|
|Ensembling End-to-End Deep Models for Computational Paralinguistics Tasks: ComParE 2020 Mask and Breathing Sub-Challenges|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/markitantov20_interspeech.html|The INTERSPEECH 2020 Computational Paralinguistics ChallengE (ComParE)|https://www.isca-speech.org/archive/interspeech_2020/markitantov20_interspeech.html|
|Analyzing Breath Signals for the Interspeech 2020 ComParE Challenge|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mendonca20_interspeech.html|The INTERSPEECH 2020 Computational Paralinguistics ChallengE (ComParE)|https://www.isca-speech.org/archive/interspeech_2020/mendonca20_interspeech.html|
|Deep Attentive End-to-End Continuous Breath Sensing from Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/macintyre20_interspeech.html|The INTERSPEECH 2020 Computational Paralinguistics ChallengE (ComParE)|https://www.isca-speech.org/archive/interspeech_2020/macintyre20_interspeech.html|
|Paralinguistic Classification of Mask Wearing by Image Classifiers and Fusion|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/szep20_interspeech.html|The INTERSPEECH 2020 Computational Paralinguistics ChallengE (ComParE)|https://www.isca-speech.org/archive/interspeech_2020/szep20_interspeech.html|
|Exploration of Acoustic and Lexical Cues for the INTERSPEECH 2020 Computational Paralinguistic Challenge|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yang20c_interspeech.html|The INTERSPEECH 2020 Computational Paralinguistics ChallengE (ComParE)|https://www.isca-speech.org/archive/interspeech_2020/yang20c_interspeech.html|
|Is Everything Fine, Grandma? Acoustic and Linguistic Modeling for Robust Elderly Speech Emotion Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/sogancoglu20_interspeech.html|The INTERSPEECH 2020 Computational Paralinguistics ChallengE (ComParE)|https://www.isca-speech.org/archive/interspeech_2020/sogancoglu20_interspeech.html|
|Are you Wearing a Mask? Improving Mask Detection from Speech Using Augmentation by Cycle-Consistent GANs|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ristea20_interspeech.html|The INTERSPEECH 2020 Computational Paralinguistics ChallengE (ComParE)|https://www.isca-speech.org/archive/interspeech_2020/ristea20_interspeech.html|
|1-D Row-Convolution LSTM: Fast Streaming ASR at Accuracy Parity with LC-BLSTM|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kumar20d_interspeech.html|Streaming ASR|https://www.isca-speech.org/archive/interspeech_2020/kumar20d_interspeech.html|
|Low Latency End-to-End Streaming Speech Recognition with a Scout Network|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20v_interspeech.html|Streaming ASR|https://www.isca-speech.org/archive/interspeech_2020/wang20v_interspeech.html|
|Knowledge Distillation from Offline to Streaming RNN Transducer for End-to-End Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kurata20_interspeech.html|Streaming ASR|https://www.isca-speech.org/archive/interspeech_2020/kurata20_interspeech.html|
|Parallel Rescoring with Transformer for Streaming On-Device Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20t_interspeech.html|Streaming ASR|https://www.isca-speech.org/archive/interspeech_2020/li20t_interspeech.html|
|Improved Hybrid Streaming ASR with Transformer Language Models|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/baqueroarnal20_interspeech.html|Streaming ASR|https://www.isca-speech.org/archive/interspeech_2020/baqueroarnal20_interspeech.html|
|Streaming Transformer-Based Acoustic Models Using Self-Attention with Augmented Memory|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wu20i_interspeech.html|Streaming ASR|https://www.isca-speech.org/archive/interspeech_2020/wu20i_interspeech.html|
|Enhancing Monotonic Multihead Attention for Streaming ASR|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/inaguma20b_interspeech.html|Streaming ASR|https://www.isca-speech.org/archive/interspeech_2020/inaguma20b_interspeech.html|
|Streaming Chunk-Aware Multihead Attention for Online End-to-End Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20q_interspeech.html|Streaming ASR|https://www.isca-speech.org/archive/interspeech_2020/zhang20q_interspeech.html|
|High Performance Sequence-to-Sequence Model for Streaming Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/nguyen20b_interspeech.html|Streaming ASR|https://www.isca-speech.org/archive/interspeech_2020/nguyen20b_interspeech.html|
|Transfer Learning Approaches for Streaming End-to-End Speech Recognition System|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/joshi20_interspeech.html|Streaming ASR|https://www.isca-speech.org/archive/interspeech_2020/joshi20_interspeech.html|
|Tackling the ADReSS Challenge: A Multimodal Approach to the Automated Recognition of Alzheimer’s Dementia|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/martinc20_interspeech.html|Alzheimer’s Dementia Recognition Through Spontaneous Speech|https://www.isca-speech.org/archive/interspeech_2020/martinc20_interspeech.html|
|Disfluencies and Fine-Tuning Pre-Trained Language Models for Detection of Alzheimer’s Disease|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yuan20_interspeech.html|Alzheimer’s Dementia Recognition Through Spontaneous Speech|https://www.isca-speech.org/archive/interspeech_2020/yuan20_interspeech.html|
|To BERT or not to BERT: Comparing Speech and Language-Based Approaches for Alzheimer’s Disease Detection|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/balagopalan20_interspeech.html|Alzheimer’s Dementia Recognition Through Spontaneous Speech|https://www.isca-speech.org/archive/interspeech_2020/balagopalan20_interspeech.html|
|Alzheimer’s Dementia Recognition Through Spontaneous Speech: The ADReSS Challenge|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/luz20_interspeech.html|Alzheimer’s Dementia Recognition Through Spontaneous Speech|https://www.isca-speech.org/archive/interspeech_2020/luz20_interspeech.html|
|Using State of the Art Speaker Recognition and Natural Language Processing Technologies to Detect Alzheimer’s Disease and Assess its Severity|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/pappagari20_interspeech.html|Alzheimer’s Dementia Recognition Through Spontaneous Speech|https://www.isca-speech.org/archive/interspeech_2020/pappagari20_interspeech.html|
|A Comparison of Acoustic and Linguistics Methodologies for Alzheimer’s Dementia Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/cummins20_interspeech.html|Alzheimer’s Dementia Recognition Through Spontaneous Speech|https://www.isca-speech.org/archive/interspeech_2020/cummins20_interspeech.html|
|Multi-Modal Fusion with Gating Using Audio, Lexical and Disfluency Features for Alzheimer’s Dementia Recognition from Spontaneous Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/rohanian20_interspeech.html|Alzheimer’s Dementia Recognition Through Spontaneous Speech|https://www.isca-speech.org/archive/interspeech_2020/rohanian20_interspeech.html|
|Comparing Natural Language Processing Techniques for Alzheimer’s Dementia Prediction in Spontaneous Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/searle20_interspeech.html|Alzheimer’s Dementia Recognition Through Spontaneous Speech|https://www.isca-speech.org/archive/interspeech_2020/searle20_interspeech.html|
|Multiscale System for Alzheimer’s Dementia Recognition Through Spontaneous Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/edwards20_interspeech.html|Alzheimer’s Dementia Recognition Through Spontaneous Speech|https://www.isca-speech.org/archive/interspeech_2020/edwards20_interspeech.html|
|The INESC-ID Multi-Modal System for the ADReSS 2020 Challenge|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/pompili20_interspeech.html|Alzheimer’s Dementia Recognition Through Spontaneous Speech|https://www.isca-speech.org/archive/interspeech_2020/pompili20_interspeech.html|
|Exploring MMSE Score Prediction Using Verbal and Non-Verbal Cues|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/farzana20_interspeech.html|Alzheimer’s Dementia Recognition Through Spontaneous Speech|https://www.isca-speech.org/archive/interspeech_2020/farzana20_interspeech.html|
|Multimodal Inductive Transfer Learning for Detection of Alzheimer’s Dementia and its Severity|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/sarawgi20_interspeech.html|Alzheimer’s Dementia Recognition Through Spontaneous Speech|https://www.isca-speech.org/archive/interspeech_2020/sarawgi20_interspeech.html|
|Exploiting Multi-Modal Features from Pre-Trained Networks for Alzheimer’s Dementia Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/koo20_interspeech.html|Alzheimer’s Dementia Recognition Through Spontaneous Speech|https://www.isca-speech.org/archive/interspeech_2020/koo20_interspeech.html|
|Automated Screening for Alzheimer’s Dementia Through Spontaneous Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/syed20_interspeech.html|Alzheimer’s Dementia Recognition Through Spontaneous Speech|https://www.isca-speech.org/archive/interspeech_2020/syed20_interspeech.html|
|NEC-TT Speaker Verification System for SRE’19 CTS Challenge|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lee20c_interspeech.html|Speaker Recognition Challenges and Applications|https://www.isca-speech.org/archive/interspeech_2020/lee20c_interspeech.html|
|THUEE System for NIST SRE19 CTS Challenge|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20u_interspeech.html|Speaker Recognition Challenges and Applications|https://www.isca-speech.org/archive/interspeech_2020/li20u_interspeech.html|
|Automatic Quality Assessment for Audio-Visual Verification Systems. The  LOVe Submission to NIST SRE Challenge 2019|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/antipov20_interspeech.html|Speaker Recognition Challenges and Applications|https://www.isca-speech.org/archive/interspeech_2020/antipov20_interspeech.html|
|Audio-Visual Speaker Recognition with a Cross-Modal Discriminative Network|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/tao20b_interspeech.html|Speaker Recognition Challenges and Applications|https://www.isca-speech.org/archive/interspeech_2020/tao20b_interspeech.html|
|Multimodal Association for Speaker Verification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/shon20_interspeech.html|Speaker Recognition Challenges and Applications|https://www.isca-speech.org/archive/interspeech_2020/shon20_interspeech.html|
|Multi-Modality Matters: A Performance Leap on VoxCeleb|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chen20h_interspeech.html|Speaker Recognition Challenges and Applications|https://www.isca-speech.org/archive/interspeech_2020/chen20h_interspeech.html|
|Cross-Domain Adaptation with Discrepancy Minimization for Text-Independent Forensic Speaker Verification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20w_interspeech.html|Speaker Recognition Challenges and Applications|https://www.isca-speech.org/archive/interspeech_2020/wang20w_interspeech.html|
|Open-Set Short Utterance Forensic Speaker Verification Using Teacher-Student Network with Explicit Inductive Bias|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/sang20_interspeech.html|Speaker Recognition Challenges and Applications|https://www.isca-speech.org/archive/interspeech_2020/sang20_interspeech.html|
|JukeBox: A Multilingual Singer Recognition Dataset|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chowdhury20b_interspeech.html|Speaker Recognition Challenges and Applications|https://www.isca-speech.org/archive/interspeech_2020/chowdhury20b_interspeech.html|
|Speaker Identification for Household Scenarios with Self-Attention and Adversarial Training|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20v_interspeech.html|Speaker Recognition Challenges and Applications|https://www.isca-speech.org/archive/interspeech_2020/li20v_interspeech.html|
|Streaming Keyword Spotting on Mobile Devices|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/rybakov20_interspeech.html|Applications of ASR|https://www.isca-speech.org/archive/interspeech_2020/rybakov20_interspeech.html|
|Metadata-Aware End-to-End Keyword Spotting|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/liu20j_interspeech.html|Applications of ASR|https://www.isca-speech.org/archive/interspeech_2020/liu20j_interspeech.html|
|Adversarial Audio: A New Information Hiding Method|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kong20_interspeech.html|Applications of ASR|https://www.isca-speech.org/archive/interspeech_2020/kong20_interspeech.html|
|S2IGAN: Speech-to-Image Generation via Adversarial Learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20x_interspeech.html|Applications of ASR|https://www.isca-speech.org/archive/interspeech_2020/wang20x_interspeech.html|
|Automatic Speech Recognition Benchmark for Air-Traffic Communications|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zuluagagomez20_interspeech.html|Applications of ASR|https://www.isca-speech.org/archive/interspeech_2020/zuluagagomez20_interspeech.html|
|Whisper Augmented End-to-End/Hybrid Speech Recognition System — CycleGAN Approach|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/gudepu20_interspeech.html|Applications of ASR|https://www.isca-speech.org/archive/interspeech_2020/gudepu20_interspeech.html|
|Risk Forecasting from Earnings Calls Acoustics and Network Correlations|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/sawhney20_interspeech.html|Applications of ASR|https://www.isca-speech.org/archive/interspeech_2020/sawhney20_interspeech.html|
|SpecMark: A Spectral Watermarking Framework for IP Protection of Speech Recognition Systems|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chen20i_interspeech.html|Applications of ASR|https://www.isca-speech.org/archive/interspeech_2020/chen20i_interspeech.html|
|Evaluating Automatically Generated Phoneme Captions for Images|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hout20_interspeech.html|Applications of ASR|https://www.isca-speech.org/archive/interspeech_2020/hout20_interspeech.html|
|An Efficient Temporal Modeling Approach for Speech Emotion Recognition by Mapping Varied Duration Sentences into Fixed Number of Chunks|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lin20d_interspeech.html|Speech Emotion Recognition II|https://www.isca-speech.org/archive/interspeech_2020/lin20d_interspeech.html|
|Deep Architecture Enhancing Robustness to Noise, Adversarial Attacks, and Cross-Corpus Setting for Speech Emotion Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/latif20b_interspeech.html|Speech Emotion Recognition II|https://www.isca-speech.org/archive/interspeech_2020/latif20b_interspeech.html|
|Meta-Learning for Speech Emotion Recognition Considering Ambiguity of Emotion Labels|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/fujioka20_interspeech.html|Speech Emotion Recognition II|https://www.isca-speech.org/archive/interspeech_2020/fujioka20_interspeech.html|
|Temporal Attention Convolutional Network for Speech Emotion Recognition with Latent Representation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/liu20k_interspeech.html|Speech Emotion Recognition II|https://www.isca-speech.org/archive/interspeech_2020/liu20k_interspeech.html|
|Reconciliation of Multiple Corpora for Speech Emotion Recognition by Multiple Classifiers with an Adversarial Corpus Discriminator|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhu20_interspeech.html|Speech Emotion Recognition II|https://www.isca-speech.org/archive/interspeech_2020/zhu20_interspeech.html|
|Conversational Emotion Recognition Using Self-Attention Mechanisms and Graph Neural Networks|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lian20c_interspeech.html|Speech Emotion Recognition II|https://www.isca-speech.org/archive/interspeech_2020/lian20c_interspeech.html|
|EigenEmo: Spectral Utterance Representation Using Dynamic Mode Decomposition for Speech Emotion Classification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mao20c_interspeech.html|Speech Emotion Recognition II|https://www.isca-speech.org/archive/interspeech_2020/mao20c_interspeech.html|
|Advancing Multiple Instance Learning with Attention Modeling for Categorical Speech Emotion Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mao20d_interspeech.html|Speech Emotion Recognition II|https://www.isca-speech.org/archive/interspeech_2020/mao20d_interspeech.html|
|The Effect of Language Proficiency on the Perception of Segmental Foreign Accent|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/perezramon20_interspeech.html|Bi- and Multilinguality|https://www.isca-speech.org/archive/interspeech_2020/perezramon20_interspeech.html|
|The Effect of Language Dominance on the Selective Attention of Segments and Tones in Urdu-Cantonese Speakers|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/liu20l_interspeech.html|Bi- and Multilinguality|https://www.isca-speech.org/archive/interspeech_2020/liu20l_interspeech.html|
|The Effect of Input on the Production of English Tense and Lax Vowels by Chinese Learners: Evidence from an Elementary School in China|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20w_interspeech.html|Bi- and Multilinguality|https://www.isca-speech.org/archive/interspeech_2020/li20w_interspeech.html|
|Exploring the Use of an Artificial Accent of English to Assess Phonetic Learning in Monolingual and Bilingual Speakers|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/spinu20_interspeech.html|Bi- and Multilinguality|https://www.isca-speech.org/archive/interspeech_2020/spinu20_interspeech.html|
|Effects of Dialectal Code-Switching on Speech Modules: A Study Using Egyptian Arabic Broadcast Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chowdhury20c_interspeech.html|Bi- and Multilinguality|https://www.isca-speech.org/archive/interspeech_2020/chowdhury20c_interspeech.html|
|Bilingual Acoustic Voice Variation is Similarly Structured Across Languages|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/johnson20_interspeech.html|Bi- and Multilinguality|https://www.isca-speech.org/archive/interspeech_2020/johnson20_interspeech.html|
|Monolingual Data Selection Analysis for English-Mandarin Hybrid Code-Switching Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20r_interspeech.html|Bi- and Multilinguality|https://www.isca-speech.org/archive/interspeech_2020/zhang20r_interspeech.html|
|Perception and Production of Mandarin Initial Stops by Native Urdu Speakers|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/du20b_interspeech.html|Bi- and Multilinguality|https://www.isca-speech.org/archive/interspeech_2020/du20b_interspeech.html|
|Now You’re Speaking My Language: Visual Language Identification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/afouras20_interspeech.html|Bi- and Multilinguality|https://www.isca-speech.org/archive/interspeech_2020/afouras20_interspeech.html|
|The Different Enhancement Roles of Covarying Cues in Thai and Mandarin Tones|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/rhee20_interspeech.html|Bi- and Multilinguality|https://www.isca-speech.org/archive/interspeech_2020/rhee20_interspeech.html|
|Singing Voice Extraction with Attention-Based Spectrograms Fusion|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/shi20c_interspeech.html|Single-Channel Speech Enhancement I|https://www.isca-speech.org/archive/interspeech_2020/shi20c_interspeech.html|
|Incorporating Broad Phonetic Information for Speech Enhancement|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lu20d_interspeech.html|Single-Channel Speech Enhancement I|https://www.isca-speech.org/archive/interspeech_2020/lu20d_interspeech.html|
|A Recursive Network with Dynamic Attention for Monaural Speech Enhancement|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20x_interspeech.html|Single-Channel Speech Enhancement I|https://www.isca-speech.org/archive/interspeech_2020/li20x_interspeech.html|
|Constrained Ratio Mask for Speech Enhancement Using DNN|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yu20d_interspeech.html|Single-Channel Speech Enhancement I|https://www.isca-speech.org/archive/interspeech_2020/yu20d_interspeech.html|
|SERIL: Noise Adaptive Speech Enhancement Using Regularization-Based Incremental Learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lee20d_interspeech.html|Single-Channel Speech Enhancement I|https://www.isca-speech.org/archive/interspeech_2020/lee20d_interspeech.html|
|Adaptive Neural Speech Enhancement with a Denoising Variational Autoencoder|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/bando20_interspeech.html|Single-Channel Speech Enhancement I|https://www.isca-speech.org/archive/interspeech_2020/bando20_interspeech.html|
|Low-Latency Single Channel Speech Dereverberation Using U-Net Convolutional Neural Networks|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/bulut20_interspeech.html|Single-Channel Speech Enhancement I|https://www.isca-speech.org/archive/interspeech_2020/bulut20_interspeech.html|
|Single-Channel Speech Enhancement by Subspace Affinity Minimization|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/tran20b_interspeech.html|Single-Channel Speech Enhancement I|https://www.isca-speech.org/archive/interspeech_2020/tran20b_interspeech.html|
|Noise Tokens: Learning Neural Noise Templates for Environment-Aware Speech Enhancement|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20y_interspeech.html|Single-Channel Speech Enhancement I|https://www.isca-speech.org/archive/interspeech_2020/li20y_interspeech.html|
|NAAGN: Noise-Aware Attention-Gated Network for Speech Enhancement|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/deng20_interspeech.html|Single-Channel Speech Enhancement I|https://www.isca-speech.org/archive/interspeech_2020/deng20_interspeech.html|
|Online Monaural Speech Enhancement Using Delayed Subband LSTM|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20z_interspeech.html|Deep Noise Suppression Challenge|https://www.isca-speech.org/archive/interspeech_2020/li20z_interspeech.html|
|INTERSPEECH 2020 Deep Noise Suppression Challenge: A Fully Convolutional Recurrent Network (FCRN) for Joint Dereverberation and Denoising|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/strake20_interspeech.html|Deep Noise Suppression Challenge|https://www.isca-speech.org/archive/interspeech_2020/strake20_interspeech.html|
|DCCRN: Deep Complex Convolution Recurrent Network for Phase-Aware Speech Enhancement|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hu20g_interspeech.html|Deep Noise Suppression Challenge|https://www.isca-speech.org/archive/interspeech_2020/hu20g_interspeech.html|
|Dual-Signal Transformation LSTM Network for Real-Time Noise Suppression|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/westhausen20_interspeech.html|Deep Noise Suppression Challenge|https://www.isca-speech.org/archive/interspeech_2020/westhausen20_interspeech.html|
|A Perceptually-Motivated Approach for Low-Complexity, Real-Time Enhancement of Fullband Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/valin20_interspeech.html|Deep Noise Suppression Challenge|https://www.isca-speech.org/archive/interspeech_2020/valin20_interspeech.html|
|PoCoNet: Better Speech Enhancement with Frequency-Positional Embeddings, Semi-Supervised Conversational Data, and Biased Loss|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/isik20_interspeech.html|Deep Noise Suppression Challenge|https://www.isca-speech.org/archive/interspeech_2020/isik20_interspeech.html|
|The INTERSPEECH 2020 Deep Noise Suppression Challenge: Datasets, Subjective Testing Framework, and Challenge Results|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/reddy20_interspeech.html|Deep Noise Suppression Challenge|https://www.isca-speech.org/archive/interspeech_2020/reddy20_interspeech.html|
|The Implication of Sound Level on Spatial Selective Auditory Attention for Cochlear Implant Users: Behavioral and Electrophysiological Measurement|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/akbarzadeh20_interspeech.html|Voice and Hearing Disorders|https://www.isca-speech.org/archive/interspeech_2020/akbarzadeh20_interspeech.html|
|Enhancing the Interaural Time Difference of Bilateral Cochlear Implants with the Temporal Limits Encoder|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wan20b_interspeech.html|Voice and Hearing Disorders|https://www.isca-speech.org/archive/interspeech_2020/wan20b_interspeech.html|
|Speech Clarity Improvement by Vocal Self-Training Using a Hearing Impairment Simulator and its Correlation with an Auditory Modulation Index|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/irino20_interspeech.html|Voice and Hearing Disorders|https://www.isca-speech.org/archive/interspeech_2020/irino20_interspeech.html|
|Investigation of Phase Distortion on Perceived Speech Quality for Hearing-Impaired Listeners|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20s_interspeech.html|Voice and Hearing Disorders|https://www.isca-speech.org/archive/interspeech_2020/zhang20s_interspeech.html|
|EEG-Based Short-Time Auditory Attention Detection Using Multi-Task Deep Learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20t_interspeech.html|Voice and Hearing Disorders|https://www.isca-speech.org/archive/interspeech_2020/zhang20t_interspeech.html|
|Towards Interpreting Deep Learning Models to Understand Loss of Speech Intelligibility in Speech Disorders — Step 1: CNN Model-Based Phone Classification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/abderrazek20_interspeech.html|Voice and Hearing Disorders|https://www.isca-speech.org/archive/interspeech_2020/abderrazek20_interspeech.html|
|Improving Cognitive Impairment Classification by Generative Neural Network-Based Feature Augmentation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mirheidari20_interspeech.html|Voice and Hearing Disorders|https://www.isca-speech.org/archive/interspeech_2020/mirheidari20_interspeech.html|
|UncommonVoice: A Crowdsourced Dataset of Dysphonic Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/moore20_interspeech.html|Voice and Hearing Disorders|https://www.isca-speech.org/archive/interspeech_2020/moore20_interspeech.html|
|Towards Automatic Assessment of Voice Disorders: A Clinical Approach|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/barche20_interspeech.html|Voice and Hearing Disorders|https://www.isca-speech.org/archive/interspeech_2020/barche20_interspeech.html|
|BlaBla: Linguistic Feature Extraction for Clinical Analysis in Multiple Languages|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/shivkumar20_interspeech.html|Voice and Hearing Disorders|https://www.isca-speech.org/archive/interspeech_2020/shivkumar20_interspeech.html|
|Depthwise Separable Convolutional ResNet with Squeeze-and-Excitation Blocks for Small-Footprint Keyword Spotting|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/xu20d_interspeech.html|Spoken Term Detection|https://www.isca-speech.org/archive/interspeech_2020/xu20d_interspeech.html|
|Predicting Detection Filters for Small Footprint Open-Vocabulary Keyword Spotting|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/bluche20_interspeech.html|Spoken Term Detection|https://www.isca-speech.org/archive/interspeech_2020/bluche20_interspeech.html|
|Deep Convolutional Spiking Neural Networks for Keyword Spotting|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ylmaz20_interspeech.html|Spoken Term Detection|https://www.isca-speech.org/archive/interspeech_2020/ylmaz20_interspeech.html|
|Domain Aware Training for Far-Field Small-Footprint Keyword Spotting|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wu20j_interspeech.html|Spoken Term Detection|https://www.isca-speech.org/archive/interspeech_2020/wu20j_interspeech.html|
|Re-Weighted Interval Loss for Handling Data Imbalance Problem of End-to-End Keyword Spotting|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20u_interspeech.html|Spoken Term Detection|https://www.isca-speech.org/archive/interspeech_2020/zhang20u_interspeech.html|
|Deep Template Matching for Small-Footprint and Configurable Keyword Spotting|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20v_interspeech.html|Spoken Term Detection|https://www.isca-speech.org/archive/interspeech_2020/zhang20v_interspeech.html|
|Multi-Scale Convolution for Robust Keyword Spotting|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yang20d_interspeech.html|Spoken Term Detection|https://www.isca-speech.org/archive/interspeech_2020/yang20d_interspeech.html|
|An Investigation of Few-Shot Learning in Spoken Term Classification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chen20j_interspeech.html|Spoken Term Detection|https://www.isca-speech.org/archive/interspeech_2020/chen20j_interspeech.html|
|End-to-End Keyword Search Based on Attention and Energy Scorer for Low Resource Languages|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhao20d_interspeech.html|Spoken Term Detection|https://www.isca-speech.org/archive/interspeech_2020/zhao20d_interspeech.html|
|Stacked 1D Convolutional Networks for End-to-End Small Footprint Voice Trigger Detection|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/higuchi20_interspeech.html|Spoken Term Detection|https://www.isca-speech.org/archive/interspeech_2020/higuchi20_interspeech.html|
|Statistical and Neural Network Based Speech Activity Detection in Non-Stationary Acoustic Environments|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/heitkaemper20_interspeech.html|The Fearless Steps Challenge Phase-02|https://www.isca-speech.org/archive/interspeech_2020/heitkaemper20_interspeech.html|
|Speaker Diarization System Based on DPCA Algorithm for Fearless Steps Challenge Phase-2|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20w_interspeech.html|The Fearless Steps Challenge Phase-02|https://www.isca-speech.org/archive/interspeech_2020/zhang20w_interspeech.html|
|The DKU Speech Activity Detection and Speaker Identification Systems for Fearless Steps Challenge Phase-02|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lin20e_interspeech.html|The Fearless Steps Challenge Phase-02|https://www.isca-speech.org/archive/interspeech_2020/lin20e_interspeech.html|
|“This is Houston. Say again, please”. The Behavox System for the Apollo-11 Fearless Steps Challenge (Phase II)|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/gorin20_interspeech.html|The Fearless Steps Challenge Phase-02|https://www.isca-speech.org/archive/interspeech_2020/gorin20_interspeech.html|
|FEARLESS STEPS Challenge (FS-2): Supervised Learning with Massive Naturalistic Apollo Data|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/joglekar20_interspeech.html|The Fearless Steps Challenge Phase-02|https://www.isca-speech.org/archive/interspeech_2020/joglekar20_interspeech.html|
|Separating Varying Numbers of Sources with Auxiliary Autoencoding Loss|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/luo20b_interspeech.html|Monaural Source Separation|https://www.isca-speech.org/archive/interspeech_2020/luo20b_interspeech.html|
|On Synthesis for Supervised Monaural Speech Separation in Time Domain|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chen20k_interspeech.html|Monaural Source Separation|https://www.isca-speech.org/archive/interspeech_2020/chen20k_interspeech.html|
|Learning Better Speech Representations by Worsening Interference|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20y_interspeech.html|Monaural Source Separation|https://www.isca-speech.org/archive/interspeech_2020/wang20y_interspeech.html|
|Asteroid: The PyTorch-Based Audio Source Separation Toolkit for Researchers|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/pariente20_interspeech.html|Monaural Source Separation|https://www.isca-speech.org/archive/interspeech_2020/pariente20_interspeech.html|
|Dual-Path Transformer Network: Direct Context-Aware Modeling for End-to-End Monaural Speech Separation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chen20l_interspeech.html|Monaural Source Separation|https://www.isca-speech.org/archive/interspeech_2020/chen20l_interspeech.html|
|Conv-TasSAN: Separative Adversarial Network Based on Conv-TasNet|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/deng20b_interspeech.html|Monaural Source Separation|https://www.isca-speech.org/archive/interspeech_2020/deng20b_interspeech.html|
|Multi-Path RNN for Hierarchical Modeling of Long Sequential Data and its Application to Speaker Stream Separation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kinoshita20_interspeech.html|Monaural Source Separation|https://www.isca-speech.org/archive/interspeech_2020/kinoshita20_interspeech.html|
|Unsupervised Audio Source Separation Using Generative Priors|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/narayanaswamy20_interspeech.html|Monaural Source Separation|https://www.isca-speech.org/archive/interspeech_2020/narayanaswamy20_interspeech.html|
|Adversarial Latent Representation Learning for Speech Enhancement|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/qiu20b_interspeech.html|Single-Channel Speech Enhancement II|https://www.isca-speech.org/archive/interspeech_2020/qiu20b_interspeech.html|
|An NMF-HMM Speech Enhancement Method Based on Kullback-Leibler Divergence|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/xiang20_interspeech.html|Single-Channel Speech Enhancement II|https://www.isca-speech.org/archive/interspeech_2020/xiang20_interspeech.html|
|Multi-Scale TCN: Exploring Better Temporal DNN Model for Causal Speech Enhancement|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20x_interspeech.html|Single-Channel Speech Enhancement II|https://www.isca-speech.org/archive/interspeech_2020/zhang20x_interspeech.html|
|VoiceFilter-Lite: Streaming Targeted Voice Separation for On-Device Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20z_interspeech.html|Single-Channel Speech Enhancement II|https://www.isca-speech.org/archive/interspeech_2020/wang20z_interspeech.html|
|Speech Separation Based on Multi-Stage Elaborated Dual-Path Deep BiLSTM with Auxiliary Identity Loss|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/shi20d_interspeech.html|Single-Channel Speech Enhancement II|https://www.isca-speech.org/archive/interspeech_2020/shi20d_interspeech.html|
|Sub-Band Knowledge Distillation Framework for Speech Enhancement|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hao20b_interspeech.html|Single-Channel Speech Enhancement II|https://www.isca-speech.org/archive/interspeech_2020/hao20b_interspeech.html|
|A Deep Learning-Based Kalman Filter for Speech Enhancement|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/roy20_interspeech.html|Single-Channel Speech Enhancement II|https://www.isca-speech.org/archive/interspeech_2020/roy20_interspeech.html|
|Subband Kalman Filtering with DNN Estimated Parameters for Speech Enhancement|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yu20e_interspeech.html|Single-Channel Speech Enhancement II|https://www.isca-speech.org/archive/interspeech_2020/yu20e_interspeech.html|
|Bidirectional LSTM Network with Ordered Neurons for Speech Enhancement|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20aa_interspeech.html|Single-Channel Speech Enhancement II|https://www.isca-speech.org/archive/interspeech_2020/li20aa_interspeech.html|
|Speaker-Conditional Chain Model for Speech Separation and Extraction|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/shi20e_interspeech.html|Single-Channel Speech Enhancement II|https://www.isca-speech.org/archive/interspeech_2020/shi20e_interspeech.html|
|Unsupervised vs. Transfer Learning for Multimodal One-Shot Matching of Speech and Images|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/nortje20_interspeech.html|Topics in ASR II|https://www.isca-speech.org/archive/interspeech_2020/nortje20_interspeech.html|
|Multimodal Speech Emotion Recognition Using Cross Attention with Aligned Audio and Text|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lee20e_interspeech.html|Topics in ASR II|https://www.isca-speech.org/archive/interspeech_2020/lee20e_interspeech.html|
|Speaker Dependent Articulatory-to-Acoustic Mapping Using Real-Time MRI of the Vocal Tract|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/csapo20_interspeech.html|Topics in ASR II|https://www.isca-speech.org/archive/interspeech_2020/csapo20_interspeech.html|
|Ultrasound-Based Articulatory-to-Acoustic Mapping with WaveGlow Speech Synthesis|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/csapo20b_interspeech.html|Topics in ASR II|https://www.isca-speech.org/archive/interspeech_2020/csapo20b_interspeech.html|
|Unsupervised Subword Modeling Using Autoregressive Pretraining and Cross-Lingual Phone-Aware Modeling|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/feng20d_interspeech.html|Topics in ASR II|https://www.isca-speech.org/archive/interspeech_2020/feng20d_interspeech.html|
|Generative Adversarial Training Data Adaptation for Very Low-Resource Automatic Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/matsuura20_interspeech.html|Topics in ASR II|https://www.isca-speech.org/archive/interspeech_2020/matsuura20_interspeech.html|
|Neural Speech Completion|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/tsunematsu20_interspeech.html|Topics in ASR II|https://www.isca-speech.org/archive/interspeech_2020/tsunematsu20_interspeech.html|
|Improving Unsupervised Sparsespeech Acoustic Models with Categorical Reparameterization|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/milde20_interspeech.html|Topics in ASR II|https://www.isca-speech.org/archive/interspeech_2020/milde20_interspeech.html|
|Multimodal Sign Language Recognition via Temporal Deformable Convolutional Sequence Learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/papadimitriou20_interspeech.html|Topics in ASR II|https://www.isca-speech.org/archive/interspeech_2020/papadimitriou20_interspeech.html|
|MLS: A Large-Scale Multilingual Dataset for Speech Research|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/pratap20_interspeech.html|Topics in ASR II|https://www.isca-speech.org/archive/interspeech_2020/pratap20_interspeech.html|
|Combining Audio and Brain Activity for Predicting Speech Quality|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/parmonangan20_interspeech.html|Neural Signals for Spoken Communication|https://www.isca-speech.org/archive/interspeech_2020/parmonangan20_interspeech.html|
|The “Sound of Silence” in EEG — Cognitive Voice Activity Detection|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/sharon20_interspeech.html|Neural Signals for Spoken Communication|https://www.isca-speech.org/archive/interspeech_2020/sharon20_interspeech.html|
|Low Latency Auditory Attention Detection with Common Spatial Pattern Analysis of EEG Signals|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/cai20_interspeech.html|Neural Signals for Spoken Communication|https://www.isca-speech.org/archive/interspeech_2020/cai20_interspeech.html|
|Speech Spectrogram Estimation from Intracranial Brain Activity Using a Quantization Approach|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/angrick20_interspeech.html|Neural Signals for Spoken Communication|https://www.isca-speech.org/archive/interspeech_2020/angrick20_interspeech.html|
|Neural Speech Decoding for Amyotrophic Lateral Sclerosis|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/dash20_interspeech.html|Neural Signals for Spoken Communication|https://www.isca-speech.org/archive/interspeech_2020/dash20_interspeech.html|
|Semi-Supervised ASR by End-to-End Self-Training|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chen20m_interspeech.html|Training Strategies for ASR|https://www.isca-speech.org/archive/interspeech_2020/chen20m_interspeech.html|
|Improved Training Strategies for End-to-End Speech Recognition in Digital Voice Assistants|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/tulsiani20_interspeech.html|Training Strategies for ASR|https://www.isca-speech.org/archive/interspeech_2020/tulsiani20_interspeech.html|
|Serialized Output Training for End-to-End Overlapped Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kanda20b_interspeech.html|Training Strategies for ASR|https://www.isca-speech.org/archive/interspeech_2020/kanda20b_interspeech.html|
|Semi-Supervised Learning with Data Augmentation for End-to-End ASR|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/weninger20_interspeech.html|Training Strategies for ASR|https://www.isca-speech.org/archive/interspeech_2020/weninger20_interspeech.html|
|Efficient Minimum Word Error Rate Training of RNN-Transducer for End-to-End Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/guo20_interspeech.html|Training Strategies for ASR|https://www.isca-speech.org/archive/interspeech_2020/guo20_interspeech.html|
|A New Training Pipeline for an Improved Neural Transducer|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zeyer20_interspeech.html|Training Strategies for ASR|https://www.isca-speech.org/archive/interspeech_2020/zeyer20_interspeech.html|
|Improved Noisy Student Training for Automatic Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/park20d_interspeech.html|Training Strategies for ASR|https://www.isca-speech.org/archive/interspeech_2020/park20d_interspeech.html|
|Phoneme-to-Grapheme Conversion Based Large-Scale Pre-Training for End-to-End Automatic Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/masumura20_interspeech.html|Training Strategies for ASR|https://www.isca-speech.org/archive/interspeech_2020/masumura20_interspeech.html|
|Utterance Invariant Training for Hybrid Two-Pass End-to-End Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/gowda20_interspeech.html|Training Strategies for ASR|https://www.isca-speech.org/archive/interspeech_2020/gowda20_interspeech.html|
|SCADA: Stochastic, Consistent and Adversarial Data Augmentation to Improve ASR|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20aa_interspeech.html|Training Strategies for ASR|https://www.isca-speech.org/archive/interspeech_2020/wang20aa_interspeech.html|
|Fundamental Frequency Model for Postfiltering at Low Bitrates in a Transform-Domain Speech and Audio Codec|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/das20b_interspeech.html|Speech Transmission & Coding|https://www.isca-speech.org/archive/interspeech_2020/das20b_interspeech.html|
|Hearing-Impaired Bio-Inspired Cochlear Models for Real-Time Auditory Applications|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/broucke20_interspeech.html|Speech Transmission & Coding|https://www.isca-speech.org/archive/interspeech_2020/broucke20_interspeech.html|
|Improving Opus Low Bit Rate Quality with Neural Speech Synthesis|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/skoglund20_interspeech.html|Speech Transmission & Coding|https://www.isca-speech.org/archive/interspeech_2020/skoglund20_interspeech.html|
|A Differentiable Perceptual Audio Metric Learned from Just Noticeable Differences|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/manocha20_interspeech.html|Speech Transmission & Coding|https://www.isca-speech.org/archive/interspeech_2020/manocha20_interspeech.html|
|StoRIR: Stochastic Room Impulse Response Generation for Audio Data Augmentation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/masztalski20_interspeech.html|Speech Transmission & Coding|https://www.isca-speech.org/archive/interspeech_2020/masztalski20_interspeech.html|
|An Open Source Implementation of ITU-T Recommendation P.808 with Validation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/naderi20_interspeech.html|Speech Transmission & Coding|https://www.isca-speech.org/archive/interspeech_2020/naderi20_interspeech.html|
|DNN No-Reference PSTN Speech Quality Prediction|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mittag20b_interspeech.html|Speech Transmission & Coding|https://www.isca-speech.org/archive/interspeech_2020/mittag20b_interspeech.html|
|Non-Intrusive Diagnostic Monitoring of Fullband Speech Quality|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/moller20_interspeech.html|Speech Transmission & Coding|https://www.isca-speech.org/archive/interspeech_2020/moller20_interspeech.html|
|Transfer Learning of Articulatory Information Through Phone Information|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/shahrebabaki20_interspeech.html|Bioacoustics and Articulation|https://www.isca-speech.org/archive/interspeech_2020/shahrebabaki20_interspeech.html|
|Sequence-to-Sequence Articulatory Inversion Through Time Convolution of Sub-Band Frequency Signals|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/shahrebabaki20b_interspeech.html|Bioacoustics and Articulation|https://www.isca-speech.org/archive/interspeech_2020/shahrebabaki20b_interspeech.html|
|Discriminative Singular Spectrum Analysis for Bioacoustic Classification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/gatto20_interspeech.html|Bioacoustics and Articulation|https://www.isca-speech.org/archive/interspeech_2020/gatto20_interspeech.html|
|Speech Rate Task-Specific Representation Learning from Acoustic-Articulatory Data|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mannem20b_interspeech.html|Bioacoustics and Articulation|https://www.isca-speech.org/archive/interspeech_2020/mannem20b_interspeech.html|
|Dysarthria Detection and Severity Assessment Using Rhythm-Based Metrics|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hernandez20_interspeech.html|Bioacoustics and Articulation|https://www.isca-speech.org/archive/interspeech_2020/hernandez20_interspeech.html|
|LungRN+NL: An Improved Adventitious Lung Sound Classification Using Non-Local Block ResNet Neural Network with Mixup Data Augmentation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ma20_interspeech.html|Bioacoustics and Articulation|https://www.isca-speech.org/archive/interspeech_2020/ma20_interspeech.html|
|Attention and Encoder-Decoder Based Models for Transforming Articulatory Movements at Different Speaking Rates|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/singh20b_interspeech.html|Bioacoustics and Articulation|https://www.isca-speech.org/archive/interspeech_2020/singh20b_interspeech.html|
|Adventitious Respiratory Classification Using Attentive Residual Neural Networks|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yang20e_interspeech.html|Bioacoustics and Articulation|https://www.isca-speech.org/archive/interspeech_2020/yang20e_interspeech.html|
|Surfboard: Audio Feature Extraction for Modern Machine Learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lenain20_interspeech.html|Bioacoustics and Articulation|https://www.isca-speech.org/archive/interspeech_2020/lenain20_interspeech.html|
|Whisper Activity Detection Using CNN-LSTM Based Attention Pooling Network Trained for a Speaker Identification Task|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/naini20_interspeech.html|Bioacoustics and Articulation|https://www.isca-speech.org/archive/interspeech_2020/naini20_interspeech.html|
|Towards Natural Bilingual and Code-Switched Speech Synthesis Based on Mix of Monolingual Recordings and Cross-Lingual Voice Conversion|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhao20e_interspeech.html|Speech Synthesis: Multilingual and Cross-Lingual Approaches|https://www.isca-speech.org/archive/interspeech_2020/zhao20e_interspeech.html|
|Multi-Lingual Multi-Speaker Text-to-Speech Synthesis for Voice Cloning with Online Speaker Enrollment|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/liu20m_interspeech.html|Speech Synthesis: Multilingual and Cross-Lingual Approaches|https://www.isca-speech.org/archive/interspeech_2020/liu20m_interspeech.html|
|Dynamic Soft Windowing and Language Dependent Style Token for Code-Switching End-to-End Speech Synthesis|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/fu20b_interspeech.html|Speech Synthesis: Multilingual and Cross-Lingual Approaches|https://www.isca-speech.org/archive/interspeech_2020/fu20b_interspeech.html|
|Phonological Features for 0-Shot Multilingual Speech Synthesis|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/staib20_interspeech.html|Speech Synthesis: Multilingual and Cross-Lingual Approaches|https://www.isca-speech.org/archive/interspeech_2020/staib20_interspeech.html|
|Cross-Lingual Text-To-Speech Synthesis via Domain Adaptation and Perceptual Similarity Regression in Speaker Space|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/xin20_interspeech.html|Speech Synthesis: Multilingual and Cross-Lingual Approaches|https://www.isca-speech.org/archive/interspeech_2020/xin20_interspeech.html|
|Tone Learning in Low-Resource Bilingual TTS|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/liu20n_interspeech.html|Speech Synthesis: Multilingual and Cross-Lingual Approaches|https://www.isca-speech.org/archive/interspeech_2020/liu20n_interspeech.html|
|On Improving Code Mixed Speech Synthesis with Mixlingual Grapheme-to-Phoneme Model|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/bansal20_interspeech.html|Speech Synthesis: Multilingual and Cross-Lingual Approaches|https://www.isca-speech.org/archive/interspeech_2020/bansal20_interspeech.html|
|Generic Indic Text-to-Speech Synthesisers with Rapid Adaptation in an End-to-End Framework|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/prakash20_interspeech.html|Speech Synthesis: Multilingual and Cross-Lingual Approaches|https://www.isca-speech.org/archive/interspeech_2020/prakash20_interspeech.html|
|Efficient Neural Speech Synthesis for Low-Resource Languages Through Multilingual Modeling|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/korte20_interspeech.html|Speech Synthesis: Multilingual and Cross-Lingual Approaches|https://www.isca-speech.org/archive/interspeech_2020/korte20_interspeech.html|
|One Model, Many Languages: Meta-Learning for Multilingual Text-to-Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/nekvinda20_interspeech.html|Speech Synthesis: Multilingual and Cross-Lingual Approaches|https://www.isca-speech.org/archive/interspeech_2020/nekvinda20_interspeech.html|
|In Defence of Metric Learning for Speaker Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chung20b_interspeech.html|Learning Techniques for Speaker Recognition I|https://www.isca-speech.org/archive/interspeech_2020/chung20b_interspeech.html|
|Meta-Learning for Short Utterance Speaker Recognition with Imbalance Length Pairs|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kye20_interspeech.html|Learning Techniques for Speaker Recognition I|https://www.isca-speech.org/archive/interspeech_2020/kye20_interspeech.html|
|Segment-Level Effects of Gender, Nationality and Emotion Information on Text-Independent Speaker Verification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20ba_interspeech.html|Learning Techniques for Speaker Recognition I|https://www.isca-speech.org/archive/interspeech_2020/li20ba_interspeech.html|
|Weakly Supervised Training of Hierarchical Attention Networks for Speaker Identification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/shi20f_interspeech.html|Learning Techniques for Speaker Recognition I|https://www.isca-speech.org/archive/interspeech_2020/shi20f_interspeech.html|
|Multi-Task Learning for Voice Related Recognition Tasks|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/montalvo20_interspeech.html|Learning Techniques for Speaker Recognition I|https://www.isca-speech.org/archive/interspeech_2020/montalvo20_interspeech.html|
|Unsupervised Training of Siamese Networks for Speaker Verification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/khan20_interspeech.html|Learning Techniques for Speaker Recognition I|https://www.isca-speech.org/archive/interspeech_2020/khan20_interspeech.html|
|An Effective Speaker Recognition Method Based on Joint Identification and Verification Supervisions|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/liu20o_interspeech.html|Learning Techniques for Speaker Recognition I|https://www.isca-speech.org/archive/interspeech_2020/liu20o_interspeech.html|
|Speaker-Aware Linear Discriminant Analysis in Speaker Verification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zheng20c_interspeech.html|Learning Techniques for Speaker Recognition I|https://www.isca-speech.org/archive/interspeech_2020/zheng20c_interspeech.html|
|Adversarial Domain Adaptation for Speaker Verification Using Partially Shared Network|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chen20n_interspeech.html|Learning Techniques for Speaker Recognition I|https://www.isca-speech.org/archive/interspeech_2020/chen20n_interspeech.html|
|Automatic Scoring at Multi-Granularity for L2 Pronunciation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lin20f_interspeech.html|Pronunciation|https://www.isca-speech.org/archive/interspeech_2020/lin20f_interspeech.html|
|An Effective End-to-End Modeling Approach for Mispronunciation Detection|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lo20b_interspeech.html|Pronunciation|https://www.isca-speech.org/archive/interspeech_2020/lo20b_interspeech.html|
|An End-to-End Mispronunciation Detection System for L2 English Speech Leveraging Novel Anti-Phone Modeling|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yan20_interspeech.html|Pronunciation|https://www.isca-speech.org/archive/interspeech_2020/yan20_interspeech.html|
|Unsupervised Feature Adaptation Using Adversarial Multi-Task Training for Automatic Evaluation of Children’s Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/duan20_interspeech.html|Pronunciation|https://www.isca-speech.org/archive/interspeech_2020/duan20_interspeech.html|
|Pronunciation Erroneous Tendency Detection with Language Adversarial Represent Learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yang20f_interspeech.html|Pronunciation|https://www.isca-speech.org/archive/interspeech_2020/yang20f_interspeech.html|
|ASR-Free Pronunciation Assessment|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/cheng20_interspeech.html|Pronunciation|https://www.isca-speech.org/archive/interspeech_2020/cheng20_interspeech.html|
|Automatic Detection of Accent and Lexical Pronunciation Errors in Spontaneous Non-Native English Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kyriakopoulos20_interspeech.html|Pronunciation|https://www.isca-speech.org/archive/interspeech_2020/kyriakopoulos20_interspeech.html|
|Context-Aware Goodness of Pronunciation for Computer-Assisted Pronunciation Training|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/shi20g_interspeech.html|Pronunciation|https://www.isca-speech.org/archive/interspeech_2020/shi20g_interspeech.html|
|Recognize Mispronunciations to Improve Non-Native Acoustic Modeling Through a Phone Decoder Built from One Edit Distance Finite State Automaton|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chu20_interspeech.html|Pronunciation|https://www.isca-speech.org/archive/interspeech_2020/chu20_interspeech.html|
|Partial AUC Optimisation Using Recurrent Neural Networks for Music Detection with Limited Training Data|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/gimeno20_interspeech.html|Diarization|https://www.isca-speech.org/archive/interspeech_2020/gimeno20_interspeech.html|
|An Open-Source Voice Type Classifier for Child-Centered Daylong Recordings|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lavechin20_interspeech.html|Diarization|https://www.isca-speech.org/archive/interspeech_2020/lavechin20_interspeech.html|
|Competing Speaker Count Estimation on the Fusion of the Spectral and Spatial Embedding Space|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/peng20_interspeech.html|Diarization|https://www.isca-speech.org/archive/interspeech_2020/peng20_interspeech.html|
|Audio-Visual Multi-Speaker Tracking Based on the GLMB Framework|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lin20g_interspeech.html|Diarization|https://www.isca-speech.org/archive/interspeech_2020/lin20g_interspeech.html|
|Towards Speech Robustness for Acoustic Scene Classification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/liu20p_interspeech.html|Diarization|https://www.isca-speech.org/archive/interspeech_2020/liu20p_interspeech.html|
|Identify Speakers in Cocktail Parties with End-to-End Attention|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhu20b_interspeech.html|Diarization|https://www.isca-speech.org/archive/interspeech_2020/zhu20b_interspeech.html|
|Multi-Talker ASR for an Unknown Number of Sources: Joint Training of Source Counting, Separation and ASR|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/neumann20_interspeech.html|Diarization|https://www.isca-speech.org/archive/interspeech_2020/neumann20_interspeech.html|
|Attentive Convolutional Recurrent Neural Network Using Phoneme-Level Acoustic Representation for Rare Sound Event Detection|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/upadhyay20_interspeech.html|Diarization|https://www.isca-speech.org/archive/interspeech_2020/upadhyay20_interspeech.html|
|Detecting and Counting Overlapping Speakers in Distant Speech Scenarios|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/cornell20_interspeech.html|Diarization|https://www.isca-speech.org/archive/interspeech_2020/cornell20_interspeech.html|
|All-in-One Transformer: Unifying Speech Recognition, Audio Tagging, and Event Detection|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/moritz20_interspeech.html|Diarization|https://www.isca-speech.org/archive/interspeech_2020/moritz20_interspeech.html|
|Towards Silent Paralinguistics: Deriving Speaking Mode and Speaker ID from Electromyographic Signals|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/diener20_interspeech.html|Computational Paralinguistics II|https://www.isca-speech.org/archive/interspeech_2020/diener20_interspeech.html|
|Predicting Collaborative Task Performance Using Graph Interlocutor Acoustic Network in Small Group Interaction|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhong20_interspeech.html|Computational Paralinguistics II|https://www.isca-speech.org/archive/interspeech_2020/zhong20_interspeech.html|
|Very Short-Term Conflict Intensity Estimation Using Fisher Vectors|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/gosztolya20_interspeech.html|Computational Paralinguistics II|https://www.isca-speech.org/archive/interspeech_2020/gosztolya20_interspeech.html|
|Gaming Corpus for Studying Social Screams|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mori20_interspeech.html|Computational Paralinguistics II|https://www.isca-speech.org/archive/interspeech_2020/mori20_interspeech.html|
|Speaker Discrimination in Humans and Machines: Effects of Speaking Style Variability|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/afshan20_interspeech.html|Computational Paralinguistics II|https://www.isca-speech.org/archive/interspeech_2020/afshan20_interspeech.html|
|Automatic Prediction of Confidence Level from Children’s Oral Reading Recordings|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/sabu20_interspeech.html|Computational Paralinguistics II|https://www.isca-speech.org/archive/interspeech_2020/sabu20_interspeech.html|
|Towards a Comprehensive Assessment of Speech Intelligibility for Pathological Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/xue20_interspeech.html|Computational Paralinguistics II|https://www.isca-speech.org/archive/interspeech_2020/xue20_interspeech.html|
|Effects of Communication Channels and Actor’s Gender on Emotion Identification by Native Mandarin Speakers|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lin20h_interspeech.html|Computational Paralinguistics II|https://www.isca-speech.org/archive/interspeech_2020/lin20h_interspeech.html|
|Detection of Voicing and Place of Articulation of Fricatives with Deep Learning in a Virtual Speech and Language Therapy Tutor|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/anjos20_interspeech.html|Computational Paralinguistics II|https://www.isca-speech.org/archive/interspeech_2020/anjos20_interspeech.html|
|Unsupervised Learning for Sequence-to-Sequence Text-to-Speech for Low-Resource Languages|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20y_interspeech.html|Speech Synthesis Paradigms and Methods II|https://www.isca-speech.org/archive/interspeech_2020/zhang20y_interspeech.html|
|Conditional Spoken Digit Generation with StyleGAN|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/palkama20_interspeech.html|Speech Synthesis Paradigms and Methods II|https://www.isca-speech.org/archive/interspeech_2020/palkama20_interspeech.html|
|Towards Universal Text-to-Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yang20g_interspeech.html|Speech Synthesis Paradigms and Methods II|https://www.isca-speech.org/archive/interspeech_2020/yang20g_interspeech.html|
|Speaker-Independent Mel-Cepstrum Estimation from Articulator Movements Using D-Vector Input|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/katsurada20_interspeech.html|Speech Synthesis Paradigms and Methods II|https://www.isca-speech.org/archive/interspeech_2020/katsurada20_interspeech.html|
|Enhancing Monotonicity for Robust Autoregressive Transformer TTS|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/liang20_interspeech.html|Speech Synthesis Paradigms and Methods II|https://www.isca-speech.org/archive/interspeech_2020/liang20_interspeech.html|
|Incremental Text to Speech for Neural Sequence-to-Sequence Models Using Reinforcement Learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mohan20_interspeech.html|Speech Synthesis Paradigms and Methods II|https://www.isca-speech.org/archive/interspeech_2020/mohan20_interspeech.html|
|Semi-Supervised Learning for Multi-Speaker Text-to-Speech Synthesis Using Discrete Speech Representation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/tu20b_interspeech.html|Speech Synthesis Paradigms and Methods II|https://www.isca-speech.org/archive/interspeech_2020/tu20b_interspeech.html|
|Learning Joint Articulatory-Acoustic Representations with Normalizing Flows|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/saha20_interspeech.html|Speech Synthesis Paradigms and Methods II|https://www.isca-speech.org/archive/interspeech_2020/saha20_interspeech.html|
|Investigating Effective Additional Contextual Factors in DNN-Based Spontaneous Speech Synthesis|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yamashita20_interspeech.html|Speech Synthesis Paradigms and Methods II|https://www.isca-speech.org/archive/interspeech_2020/yamashita20_interspeech.html|
|Hider-Finder-Combiner: An Adversarial Architecture for General Speech Signal Modification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/webber20_interspeech.html|Speech Synthesis Paradigms and Methods II|https://www.isca-speech.org/archive/interspeech_2020/webber20_interspeech.html|
|Wav2Spk: A Simple DNN Architecture for Learning Speaker Embeddings from Waveforms|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lin20i_interspeech.html|Speaker Embedding|https://www.isca-speech.org/archive/interspeech_2020/lin20i_interspeech.html|
|How Does Label Noise Affect the Quality of Speaker Embeddings?|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/pham20b_interspeech.html|Speaker Embedding|https://www.isca-speech.org/archive/interspeech_2020/pham20b_interspeech.html|
|A Comparative Re-Assessment of Feature Extractors for Deep Speaker Embeddings|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/liu20q_interspeech.html|Speaker Embedding|https://www.isca-speech.org/archive/interspeech_2020/liu20q_interspeech.html|
|Speaker Representation Learning Using Global Context Guided Channel and Time-Frequency Transformations|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/xia20_interspeech.html|Speaker Embedding|https://www.isca-speech.org/archive/interspeech_2020/xia20_interspeech.html|
|Intra-Class Variation Reduction of Speaker Representation in Disentanglement Framework|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kwon20_interspeech.html|Speaker Embedding|https://www.isca-speech.org/archive/interspeech_2020/kwon20_interspeech.html|
|Compact Speaker Embedding: lrx-Vector|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/georges20_interspeech.html|Speaker Embedding|https://www.isca-speech.org/archive/interspeech_2020/georges20_interspeech.html|
|Cosine-Distance Virtual Adversarial Training for Semi-Supervised Speaker-Discriminative Acoustic Embeddings|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kreyssig20_interspeech.html|Speaker Embedding|https://www.isca-speech.org/archive/interspeech_2020/kreyssig20_interspeech.html|
|Deep Speaker Embedding with Long Short Term Centroid Learning for Text-Independent Speaker Verification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/peng20b_interspeech.html|Speaker Embedding|https://www.isca-speech.org/archive/interspeech_2020/peng20b_interspeech.html|
|Neural Discriminant Analysis for Deep Speaker Embedding|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20ca_interspeech.html|Speaker Embedding|https://www.isca-speech.org/archive/interspeech_2020/li20ca_interspeech.html|
|Learning Speaker Embedding from Text-to-Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/cho20b_interspeech.html|Speaker Embedding|https://www.isca-speech.org/archive/interspeech_2020/cho20b_interspeech.html|
|Noisy-Reverberant Speech Enhancement Using DenseUNet with Time-Frequency Attention|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhao20f_interspeech.html|Single-Channel Speech Enhancement III|https://www.isca-speech.org/archive/interspeech_2020/zhao20f_interspeech.html|
|On Loss Functions and Recurrency Training for GAN-Based Speech Enhancement Systems|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20z_interspeech.html|Single-Channel Speech Enhancement III|https://www.isca-speech.org/archive/interspeech_2020/zhang20z_interspeech.html|
|Self-Supervised Adversarial Multi-Task Learning for Vocoder-Based Monaural Speech Enhancement|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/du20c_interspeech.html|Single-Channel Speech Enhancement III|https://www.isca-speech.org/archive/interspeech_2020/du20c_interspeech.html|
|Deep Speech Inpainting of Time-Frequency Masks|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kegler20_interspeech.html|Single-Channel Speech Enhancement III|https://www.isca-speech.org/archive/interspeech_2020/kegler20_interspeech.html|
|Real-Time Single-Channel Deep Neural Network-Based Speech Enhancement on Edge Devices|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/shankar20_interspeech.html|Single-Channel Speech Enhancement III|https://www.isca-speech.org/archive/interspeech_2020/shankar20_interspeech.html|
|Improved Speech Enhancement Using a Time-Domain GAN with Mask Learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lin20j_interspeech.html|Single-Channel Speech Enhancement III|https://www.isca-speech.org/archive/interspeech_2020/lin20j_interspeech.html|
|Real Time Speech Enhancement in the Waveform Domain|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/defossez20_interspeech.html|Single-Channel Speech Enhancement III|https://www.isca-speech.org/archive/interspeech_2020/defossez20_interspeech.html|
|Efficient Low-Latency Speech Enhancement with Mobile Audio Streaming Networks|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/romaniuk20_interspeech.html|Single-Channel Speech Enhancement III|https://www.isca-speech.org/archive/interspeech_2020/romaniuk20_interspeech.html|
|Multi-Stream Attention-Based BLSTM with Feature Segmentation for Speech Emotion Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chiba20_interspeech.html|Multi-Channel Audio and Emotion Recognition|https://www.isca-speech.org/archive/interspeech_2020/chiba20_interspeech.html|
|Microphone Array Post-Filter for Target Speech Enhancement Without a Prior Information of Point Interferers|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20da_interspeech.html|Multi-Channel Audio and Emotion Recognition|https://www.isca-speech.org/archive/interspeech_2020/li20da_interspeech.html|
|Similarity-and-Independence-Aware Beamformer: Method for Target Source Extraction Using Magnitude Spectrogram as Reference|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hiroe20_interspeech.html|Multi-Channel Audio and Emotion Recognition|https://www.isca-speech.org/archive/interspeech_2020/hiroe20_interspeech.html|
|The Method of Random Directions Optimization for Stereo Audio Source Separation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/golokolenko20_interspeech.html|Multi-Channel Audio and Emotion Recognition|https://www.isca-speech.org/archive/interspeech_2020/golokolenko20_interspeech.html|
|Gated Recurrent Fusion of Spatial and Spectral Features for Multi-Channel Speech Separation with Deep Embedding Representations|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/fan20b_interspeech.html|Multi-Channel Audio and Emotion Recognition|https://www.isca-speech.org/archive/interspeech_2020/fan20b_interspeech.html|
|Generalized Minimal Distortion Principle for Blind Source Separation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/scheibler20_interspeech.html|Multi-Channel Audio and Emotion Recognition|https://www.isca-speech.org/archive/interspeech_2020/scheibler20_interspeech.html|
|A Lightweight Model Based on Separable Convolution for Speech Emotion Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhong20b_interspeech.html|Multi-Channel Audio and Emotion Recognition|https://www.isca-speech.org/archive/interspeech_2020/zhong20b_interspeech.html|
|Meta Multi-Task Learning for Speech Emotion Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/cai20b_interspeech.html|Multi-Channel Audio and Emotion Recognition|https://www.isca-speech.org/archive/interspeech_2020/cai20b_interspeech.html|
|GEV Beamforming Supported by DOA-Based Masks Generated on Pairs of Microphones|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/grondin20_interspeech.html|Multi-Channel Audio and Emotion Recognition|https://www.isca-speech.org/archive/interspeech_2020/grondin20_interspeech.html|
|Accurate Detection of Wake Word Start and End Using a CNN|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/jose20_interspeech.html|Computational Resource Constrained Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/jose20_interspeech.html|
|Hybrid Transformer/CTC Networks for Hardware Efficient Voice Triggering|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/adya20_interspeech.html|Computational Resource Constrained Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/adya20_interspeech.html|
|MatchboxNet: 1D Time-Channel Separable Convolutional Neural Network Architecture for Speech Commands Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/majumdar20_interspeech.html|Computational Resource Constrained Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/majumdar20_interspeech.html|
|Iterative Compression of End-to-End ASR Model Using AutoML|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mehrotra20_interspeech.html|Computational Resource Constrained Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/mehrotra20_interspeech.html|
|Quantization Aware Training with Absolute-Cosine Regularization for Automatic Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/nguyen20c_interspeech.html|Computational Resource Constrained Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/nguyen20c_interspeech.html|
|Streaming On-Device End-to-End ASR System for Privacy-Sensitive Voice-Typing|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/garg20b_interspeech.html|Computational Resource Constrained Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/garg20b_interspeech.html|
|Scaling Up Online Speech Recognition Using ConvNets|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/pratap20b_interspeech.html|Computational Resource Constrained Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/pratap20b_interspeech.html|
|Listen Attentively, and Spell Once: Whole Sentence Generation via a Non-Autoregressive Architecture for Low-Latency Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/bai20_interspeech.html|Computational Resource Constrained Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/bai20_interspeech.html|
|Rescore in a Flash: Compact, Cache Efficient Hashing Data Structures for n-Gram Language Models|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/strimel20_interspeech.html|Computational Resource Constrained Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/strimel20_interspeech.html|
|Multi-Speaker Emotion Conversion via Latent Variable Regularization and a Chained Encoder-Decoder-Predictor Network|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/shankar20b_interspeech.html|Speech Synthesis: Prosody and Emotion|https://www.isca-speech.org/archive/interspeech_2020/shankar20b_interspeech.html|
|Non-Parallel Emotion Conversion Using a Deep-Generative Hybrid Network and an Adversarial Pair Discriminator|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/shankar20c_interspeech.html|Speech Synthesis: Prosody and Emotion|https://www.isca-speech.org/archive/interspeech_2020/shankar20c_interspeech.html|
|Laughter Synthesis: Combining Seq2seq Modeling with Transfer Learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/tits20b_interspeech.html|Speech Synthesis: Prosody and Emotion|https://www.isca-speech.org/archive/interspeech_2020/tits20b_interspeech.html|
|Nonparallel Emotional Speech Conversion Using VAE-GAN|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/cao20b_interspeech.html|Speech Synthesis: Prosody and Emotion|https://www.isca-speech.org/archive/interspeech_2020/cao20b_interspeech.html|
|Principal Style Components: Expressive Style Control and Cross-Speaker Transfer in Neural TTS|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/sorin20_interspeech.html|Speech Synthesis: Prosody and Emotion|https://www.isca-speech.org/archive/interspeech_2020/sorin20_interspeech.html|
|Converting Anyone’s Emotion: Towards Speaker-Independent Emotional Voice Conversion|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhou20d_interspeech.html|Speech Synthesis: Prosody and Emotion|https://www.isca-speech.org/archive/interspeech_2020/zhou20d_interspeech.html|
|Controlling the Strength of Emotions in Speech-Like Emotional Sound Generated by WaveNet|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/matsumoto20_interspeech.html|Speech Synthesis: Prosody and Emotion|https://www.isca-speech.org/archive/interspeech_2020/matsumoto20_interspeech.html|
|Learning Syllable-Level Discrete Prosodic Representation for Expressive Speech Generation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20aa_interspeech.html|Speech Synthesis: Prosody and Emotion|https://www.isca-speech.org/archive/interspeech_2020/zhang20aa_interspeech.html|
|Simultaneous Conversion of Speaker Identity and Emotion Based on Multiple-Domain Adaptive RBM|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kishida20_interspeech.html|Speech Synthesis: Prosody and Emotion|https://www.isca-speech.org/archive/interspeech_2020/kishida20_interspeech.html|
|Exploiting Deep Sentential Context for Expressive End-to-End Speech Synthesis|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yang20h_interspeech.html|Speech Synthesis: Prosody and Emotion|https://www.isca-speech.org/archive/interspeech_2020/yang20h_interspeech.html|
|Hierarchical Multi-Grained Generative Model for Expressive Speech Synthesis|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hono20_interspeech.html|Speech Synthesis: Prosody and Emotion|https://www.isca-speech.org/archive/interspeech_2020/hono20_interspeech.html|
|GAN-Based Data Generation for Speech Emotion Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/eskimez20_interspeech.html|Speech Synthesis: Prosody and Emotion|https://www.isca-speech.org/archive/interspeech_2020/eskimez20_interspeech.html|
|The Phonetic Bases of Vocal Expressed Emotion: Natural versus Acted|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/dhamyal20_interspeech.html|Speech Synthesis: Prosody and Emotion|https://www.isca-speech.org/archive/interspeech_2020/dhamyal20_interspeech.html|
|The INTERSPEECH 2020 Far-Field Speaker Verification Challenge|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/qin20_interspeech.html|The Interspeech 2020 Far Field Speaker Verification Challenge|https://www.isca-speech.org/archive/interspeech_2020/qin20_interspeech.html|
|Deep Embedding Learning for Text-Dependent Speaker Verification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20ba_interspeech.html|The Interspeech 2020 Far Field Speaker Verification Challenge|https://www.isca-speech.org/archive/interspeech_2020/zhang20ba_interspeech.html|
|STC-Innovation Speaker Recognition Systems for Far-Field Speaker Verification Challenge 2020|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/gusev20_interspeech.html|The Interspeech 2020 Far Field Speaker Verification Challenge|https://www.isca-speech.org/archive/interspeech_2020/gusev20_interspeech.html|
|NPU Speaker Verification System for INTERSPEECH 2020 Far-Field Speaker Verification Challenge|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20ca_interspeech.html|The Interspeech 2020 Far Field Speaker Verification Challenge|https://www.isca-speech.org/archive/interspeech_2020/zhang20ca_interspeech.html|
|The JD AI Speaker Verification System for the FFSVC 2020 Challenge|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/tong20_interspeech.html|The Interspeech 2020 Far Field Speaker Verification Challenge|https://www.isca-speech.org/archive/interspeech_2020/tong20_interspeech.html|
|FaceFilter: Audio-Visual Speech Separation Using Still Images|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chung20c_interspeech.html|Multimodal Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/chung20c_interspeech.html|
|Seeing Voices and Hearing Voices: Learning Discriminative Embeddings Using Cross-Modal Self-Supervision|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chung20d_interspeech.html|Multimodal Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/chung20d_interspeech.html|
|Fusion Architectures for Word-Based Audiovisual Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wand20_interspeech.html|Multimodal Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/wand20_interspeech.html|
|Audio-Visual Multi-Channel Recognition of Overlapped Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yu20f_interspeech.html|Multimodal Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/yu20f_interspeech.html|
|TMT: A Transformer-Based Modal Translator for Improving Multimodal Sequence Representations in Audio Visual Scene-Aware Dialog|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20ea_interspeech.html|Multimodal Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/li20ea_interspeech.html|
|Should we Hard-Code the Recurrence Concept or Learn it Instead ? Exploring the Transformer Architecture for Audio-Visual Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/sterpu20_interspeech.html|Multimodal Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/sterpu20_interspeech.html|
|Resource-Adaptive Deep Learning for Visual Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/koumparoulis20_interspeech.html|Multimodal Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/koumparoulis20_interspeech.html|
|Speech-Image Semantic Alignment Does Not Depend on Any Prior Classification Tasks|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mortazavi20_interspeech.html|Multimodal Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/mortazavi20_interspeech.html|
|Lip Graph Assisted Audio-Visual Speech Recognition Using Bidirectional Synchronous Fusion|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/liu20r_interspeech.html|Multimodal Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/liu20r_interspeech.html|
|Caption Alignment for Low Resource Audio-Visual Data|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/konda20_interspeech.html|Multimodal Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/konda20_interspeech.html|
|Successes, Challenges and Opportunities for Speech Technology in Conversational Agents|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mevawalla20_interspeech.html|Keynote 4|https://www.isca-speech.org/archive/interspeech_2020/mevawalla20_interspeech.html|
|Vocoder-Based Speech Synthesis from Silent Videos|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/michelsanti20_interspeech.html|Speech Synthesis: Neural Waveform Generation II|https://www.isca-speech.org/archive/interspeech_2020/michelsanti20_interspeech.html|
|Quasi-Periodic Parallel WaveGAN Vocoder: A Non-Autoregressive Pitch-Dependent Dilated Convolution Model for Parametric Speech Generation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wu20k_interspeech.html|Speech Synthesis: Neural Waveform Generation II|https://www.isca-speech.org/archive/interspeech_2020/wu20k_interspeech.html|
|A Cyclical Post-Filtering Approach to Mismatch Refinement of Neural Vocoder for Text-to-Speech Systems|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wu20l_interspeech.html|Speech Synthesis: Neural Waveform Generation II|https://www.isca-speech.org/archive/interspeech_2020/wu20l_interspeech.html|
|Audio Dequantization for High Fidelity Audio Generation in Flow-Based Neural Vocoder|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yoon20_interspeech.html|Speech Synthesis: Neural Waveform Generation II|https://www.isca-speech.org/archive/interspeech_2020/yoon20_interspeech.html|
|StrawNet: Self-Training WaveNet for TTS in Low-Data Regimes|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/sharma20b_interspeech.html|Speech Synthesis: Neural Waveform Generation II|https://www.isca-speech.org/archive/interspeech_2020/sharma20b_interspeech.html|
|An Efficient Subband Linear Prediction for LPCNet-Based Neural Synthesis|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/cui20b_interspeech.html|Speech Synthesis: Neural Waveform Generation II|https://www.isca-speech.org/archive/interspeech_2020/cui20b_interspeech.html|
|Reverberation Modeling for Source-Filter-Based Neural Vocoder|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ai20b_interspeech.html|Speech Synthesis: Neural Waveform Generation II|https://www.isca-speech.org/archive/interspeech_2020/ai20b_interspeech.html|
|Bunched LPCNet: Vocoder for Low-Cost Neural Text-To-Speech Systems|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/vipperla20_interspeech.html|Speech Synthesis: Neural Waveform Generation II|https://www.isca-speech.org/archive/interspeech_2020/vipperla20_interspeech.html|
|Neural Text-to-Speech with a Modeling-by-Generation Excitation Vocoder|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/song20c_interspeech.html|Speech Synthesis: Neural Waveform Generation II|https://www.isca-speech.org/archive/interspeech_2020/song20c_interspeech.html|
|SpeedySpeech: Efficient Neural Speech Synthesis|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/vainer20_interspeech.html|Speech Synthesis: Neural Waveform Generation II|https://www.isca-speech.org/archive/interspeech_2020/vainer20_interspeech.html|
|Semi-Supervised End-to-End ASR via Teacher-Student Learning with Conditional Posterior Distribution|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20da_interspeech.html|ASR Neural Network Architectures and Training II|https://www.isca-speech.org/archive/interspeech_2020/zhang20da_interspeech.html|
|Leveraging Unlabeled Speech for Sequence Discriminative Training of Acoustic Models|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/sapru20_interspeech.html|ASR Neural Network Architectures and Training II|https://www.isca-speech.org/archive/interspeech_2020/sapru20_interspeech.html|
|Developing RNN-T Models Surpassing High-Performance Hybrid Models with Customization Capability|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20fa_interspeech.html|ASR Neural Network Architectures and Training II|https://www.isca-speech.org/archive/interspeech_2020/li20fa_interspeech.html|
|End-to-End ASR with Adaptive Span Self-Attention|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chang20c_interspeech.html|ASR Neural Network Architectures and Training II|https://www.isca-speech.org/archive/interspeech_2020/chang20c_interspeech.html|
|Subword Regularization: An Analysis of Scalability and Generalization for End-to-End Automatic Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lakomkin20_interspeech.html|ASR Neural Network Architectures and Training II|https://www.isca-speech.org/archive/interspeech_2020/lakomkin20_interspeech.html|
|Early Stage LM Integration Using Local and Global Log-Linear Combination|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/michel20_interspeech.html|ASR Neural Network Architectures and Training II|https://www.isca-speech.org/archive/interspeech_2020/michel20_interspeech.html|
|ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/han20_interspeech.html|ASR Neural Network Architectures and Training II|https://www.isca-speech.org/archive/interspeech_2020/han20_interspeech.html|
|Emitting Word Timings with End-to-End Models|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/sainath20_interspeech.html|ASR Neural Network Architectures and Training II|https://www.isca-speech.org/archive/interspeech_2020/sainath20_interspeech.html|
|Low-Latency Sequence-to-Sequence Speech Recognition and Translation by Partial Hypothesis Selection|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/liu20s_interspeech.html|ASR Neural Network Architectures and Training II|https://www.isca-speech.org/archive/interspeech_2020/liu20s_interspeech.html|
|Neural Language Modeling with Implicit Cache Pointers|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20ga_interspeech.html|Neural Networks for Language Modeling|https://www.isca-speech.org/archive/interspeech_2020/li20ga_interspeech.html|
|Finnish ASR with Deep Transformer Models|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/jain20b_interspeech.html|Neural Networks for Language Modeling|https://www.isca-speech.org/archive/interspeech_2020/jain20b_interspeech.html|
|Distilling the Knowledge of BERT for Sequence-to-Sequence ASR|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/futami20_interspeech.html|Neural Networks for Language Modeling|https://www.isca-speech.org/archive/interspeech_2020/futami20_interspeech.html|
|Stochastic Convolutional Recurrent Networks for Language Modeling|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chien20_interspeech.html|Neural Networks for Language Modeling|https://www.isca-speech.org/archive/interspeech_2020/chien20_interspeech.html|
|Investigation of Large-Margin Softmax in Neural Language Modeling|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/huo20_interspeech.html|Neural Networks for Language Modeling|https://www.isca-speech.org/archive/interspeech_2020/huo20_interspeech.html|
|Contextualizing ASR Lattice Rescoring with Hybrid Pointer Network Language Model|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/liu20t_interspeech.html|Neural Networks for Language Modeling|https://www.isca-speech.org/archive/interspeech_2020/liu20t_interspeech.html|
|Mask CTC: Non-Autoregressive End-to-End ASR with CTC and Mask Predict|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/higuchi20b_interspeech.html|Neural Networks for Language Modeling|https://www.isca-speech.org/archive/interspeech_2020/higuchi20b_interspeech.html|
|Insertion-Based Modeling for End-to-End Automatic Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/fujita20_interspeech.html|Neural Networks for Language Modeling|https://www.isca-speech.org/archive/interspeech_2020/fujita20_interspeech.html|
|Voice Activity Detection in the Wild via Weakly Supervised Sound Event Detection|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chen20o_interspeech.html|Phonetic Event Detection and Segmentation|https://www.isca-speech.org/archive/interspeech_2020/chen20o_interspeech.html|
|Dual Attention in Time and Frequency Domain for Voice Activity Detection|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lee20f_interspeech.html|Phonetic Event Detection and Segmentation|https://www.isca-speech.org/archive/interspeech_2020/lee20f_interspeech.html|
|Polishing the Classical Likelihood Ratio Test by Supervised Learning for Voice Activity Detection|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/xu20e_interspeech.html|Phonetic Event Detection and Segmentation|https://www.isca-speech.org/archive/interspeech_2020/xu20e_interspeech.html|
|A Noise Robust Technique for Detecting Vowels in Speech Signals|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kumar20e_interspeech.html|Phonetic Event Detection and Segmentation|https://www.isca-speech.org/archive/interspeech_2020/kumar20e_interspeech.html|
|End-to-End Domain-Adversarial Voice Activity Detection|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lavechin20b_interspeech.html|Phonetic Event Detection and Segmentation|https://www.isca-speech.org/archive/interspeech_2020/lavechin20b_interspeech.html|
|VOP Detection in Variable Speech Rate Condition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/agarwal20_interspeech.html|Phonetic Event Detection and Segmentation|https://www.isca-speech.org/archive/interspeech_2020/agarwal20_interspeech.html|
|MLNET: An Adaptive Multiple Receptive-Field Attention Neural Network for Voice Activity Detection|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zheng20d_interspeech.html|Phonetic Event Detection and Segmentation|https://www.isca-speech.org/archive/interspeech_2020/zheng20d_interspeech.html|
|Self-Supervised Contrastive Learning for Unsupervised Phoneme Segmentation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kreuk20_interspeech.html|Phonetic Event Detection and Segmentation|https://www.isca-speech.org/archive/interspeech_2020/kreuk20_interspeech.html|
|That Sounds Familiar: An Analysis of Phonetic Representations Transfer Across Languages|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zelasko20_interspeech.html|Phonetic Event Detection and Segmentation|https://www.isca-speech.org/archive/interspeech_2020/zelasko20_interspeech.html|
|Analyzing Read Aloud Speech by Primary School Pupils: Insights for Research and Development|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/limonard20_interspeech.html|Phonetic Event Detection and Segmentation|https://www.isca-speech.org/archive/interspeech_2020/limonard20_interspeech.html|
|Discovering Articulatory Speech Targets from Synthesized Random Babble|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/rasilo20_interspeech.html|Human Speech Production II|https://www.isca-speech.org/archive/interspeech_2020/rasilo20_interspeech.html|
|Speaker Dependent Acoustic-to-Articulatory Inversion Using Real-Time MRI of the Vocal Tract|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/csapo20c_interspeech.html|Human Speech Production II|https://www.isca-speech.org/archive/interspeech_2020/csapo20c_interspeech.html|
|Acoustic-to-Articulatory Inversion with Deep Autoregressive Articulatory-WaveNet|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/bozorg20_interspeech.html|Human Speech Production II|https://www.isca-speech.org/archive/interspeech_2020/bozorg20_interspeech.html|
|Using Silence MR Image to Synthesise Dynamic MRI Vocal Tract Data of CV|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/douros20_interspeech.html|Human Speech Production II|https://www.isca-speech.org/archive/interspeech_2020/douros20_interspeech.html|
|Quantification of Transducer Misalignment in Ultrasound Tongue Imaging|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/csapo20d_interspeech.html|Human Speech Production II|https://www.isca-speech.org/archive/interspeech_2020/csapo20d_interspeech.html|
|Independent and Automatic Evaluation of Speaker-Independent Acoustic-to-Articulatory Reconstruction|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/parrot20_interspeech.html|Human Speech Production II|https://www.isca-speech.org/archive/interspeech_2020/parrot20_interspeech.html|
|CSL-EMG_Array: An Open Access Corpus for EMG-to-Speech Conversion|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/diener20b_interspeech.html|Human Speech Production II|https://www.isca-speech.org/archive/interspeech_2020/diener20b_interspeech.html|
|Links Between Production and Perception of Glottalisation in Individual Australian English Speaker/Listeners|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/penney20_interspeech.html|Human Speech Production II|https://www.isca-speech.org/archive/interspeech_2020/penney20_interspeech.html|
|Jointly Fine-Tuning “BERT-Like” Self Supervised Models to Improve Multimodal Speech Emotion Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/siriwardhana20_interspeech.html|New Trends in Self-Supervised Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/siriwardhana20_interspeech.html|
|Vector-Quantized Autoregressive Predictive Coding|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chung20e_interspeech.html|New Trends in Self-Supervised Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/chung20e_interspeech.html|
|Speech-XLNet: Unsupervised Acoustic Model Pretraining for Self-Attention Networks|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/song20d_interspeech.html|New Trends in Self-Supervised Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/song20d_interspeech.html|
|Large Scale Weakly and Semi-Supervised Learning for Low-Resource Video ASR|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/singh20c_interspeech.html|New Trends in Self-Supervised Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/singh20c_interspeech.html|
|Sequence-Level Self-Learning with Multiple Hypotheses|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kumatani20_interspeech.html|New Trends in Self-Supervised Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/kumatani20_interspeech.html|
|Defense for Black-Box Attacks on Anti-Spoofing Models by Self-Supervised Learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wu20m_interspeech.html|New Trends in Self-Supervised Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/wu20m_interspeech.html|
|Understanding Self-Attention of Self-Supervised Audio Transformers|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yang20i_interspeech.html|New Trends in Self-Supervised Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/yang20i_interspeech.html|
|A Convolutional Deep Markov Model for Unsupervised Speech Representation Learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/khurana20_interspeech.html|New Trends in Self-Supervised Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/khurana20_interspeech.html|
|Automatic Speech Recognition for ILSE-Interviews: Longitudinal Conversational Speech Recordings Covering Aging and Cognitive Decline|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/abulimiti20_interspeech.html|New Trends in Self-Supervised Speech Processing|https://www.isca-speech.org/archive/interspeech_2020/abulimiti20_interspeech.html|
|Dynamic Margin Softmax Loss for Speaker Verification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhou20e_interspeech.html|Learning Techniques for Speaker Recognition II|https://www.isca-speech.org/archive/interspeech_2020/zhou20e_interspeech.html|
|On Parameter Adaptation in Softmax-Based Cross-Entropy Loss for Improved Convergence Speed and Accuracy in DNN-Based Speaker Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/rybicka20_interspeech.html|Learning Techniques for Speaker Recognition II|https://www.isca-speech.org/archive/interspeech_2020/rybicka20_interspeech.html|
|Training Speaker Enrollment Models by Network Optimization|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mingote20_interspeech.html|Learning Techniques for Speaker Recognition II|https://www.isca-speech.org/archive/interspeech_2020/mingote20_interspeech.html|
|Supervised Domain Adaptation for Text-Independent Speaker Verification Using Limited Data|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/sarfjoo20_interspeech.html|Learning Techniques for Speaker Recognition II|https://www.isca-speech.org/archive/interspeech_2020/sarfjoo20_interspeech.html|
|Angular Margin Centroid Loss for Text-Independent Speaker Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wei20b_interspeech.html|Learning Techniques for Speaker Recognition II|https://www.isca-speech.org/archive/interspeech_2020/wei20b_interspeech.html|
|Domain-Invariant Speaker Vector Projection by Model-Agnostic Meta-Learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kang20_interspeech.html|Learning Techniques for Speaker Recognition II|https://www.isca-speech.org/archive/interspeech_2020/kang20_interspeech.html|
|ECAPA-TDNN: Emphasized Channel Attention, Propagation and Aggregation in TDNN Based Speaker Verification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/desplanques20_interspeech.html|Learning Techniques for Speaker Recognition II|https://www.isca-speech.org/archive/interspeech_2020/desplanques20_interspeech.html|
|Length- and Noise-Aware Training Techniques for Short-Utterance Speaker Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chen20p_interspeech.html|Learning Techniques for Speaker Recognition II|https://www.isca-speech.org/archive/interspeech_2020/chen20p_interspeech.html|
|Spoken Language ‘Grammatical Error Correction’|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lu20e_interspeech.html|Spoken Language Evaluatiosn|https://www.isca-speech.org/archive/interspeech_2020/lu20e_interspeech.html|
|Mixtures of Deep Neural Experts for Automated Speech Scoring|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/papi20_interspeech.html|Spoken Language Evaluatiosn|https://www.isca-speech.org/archive/interspeech_2020/papi20_interspeech.html|
|Targeted Content Feedback in Spoken Language Learning and Assessment|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20ba_interspeech.html|Spoken Language Evaluatiosn|https://www.isca-speech.org/archive/interspeech_2020/wang20ba_interspeech.html|
|Universal Adversarial Attacks on Spoken Language Assessment Systems|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/raina20_interspeech.html|Spoken Language Evaluatiosn|https://www.isca-speech.org/archive/interspeech_2020/raina20_interspeech.html|
|Ensemble Approaches for Uncertainty in Spoken Language Assessment|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wu20n_interspeech.html|Spoken Language Evaluatiosn|https://www.isca-speech.org/archive/interspeech_2020/wu20n_interspeech.html|
|Shadowability Annotation with Fine Granularity on L2 Utterances and its Improvement with Native Listeners’ Script-Shadowing|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lin20k_interspeech.html|Spoken Language Evaluatiosn|https://www.isca-speech.org/archive/interspeech_2020/lin20k_interspeech.html|
|ASR-Based Evaluation and Feedback for Individualized Reading Practice|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/bai20b_interspeech.html|Spoken Language Evaluatiosn|https://www.isca-speech.org/archive/interspeech_2020/bai20b_interspeech.html|
|Domain Adversarial Neural Networks for Dysarthric Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/woszczyk20_interspeech.html|Spoken Language Evaluatiosn|https://www.isca-speech.org/archive/interspeech_2020/woszczyk20_interspeech.html|
|Automatic Estimation of Pathological Voice Quality Based on Recurrent Neural Network Using Amplitude and Phase Spectrogram|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hidaka20_interspeech.html|Spoken Language Evaluatiosn|https://www.isca-speech.org/archive/interspeech_2020/hidaka20_interspeech.html|
|Stochastic Curiosity Exploration for Dialogue Systems|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chien20b_interspeech.html|Spoken Dialogue System|https://www.isca-speech.org/archive/interspeech_2020/chien20b_interspeech.html|
|Conditional Response Augmentation for Dialogue Using Knowledge Distillation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/jeong20_interspeech.html|Spoken Dialogue System|https://www.isca-speech.org/archive/interspeech_2020/jeong20_interspeech.html|
|Prototypical Q Networks for Automatic Conversational Diagnosis and Few-Shot New Disease Adaption|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/luo20c_interspeech.html|Spoken Dialogue System|https://www.isca-speech.org/archive/interspeech_2020/luo20c_interspeech.html|
|End-to-End Task-Oriented Dialog System Through Template Slot Value Generation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hong20b_interspeech.html|Spoken Dialogue System|https://www.isca-speech.org/archive/interspeech_2020/hong20b_interspeech.html|
|Task-Oriented Dialog Generation with Enhanced Entity Representation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/he20_interspeech.html|Spoken Dialogue System|https://www.isca-speech.org/archive/interspeech_2020/he20_interspeech.html|
|End-to-End Speech-to-Dialog-Act Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/dang20_interspeech.html|Spoken Dialogue System|https://www.isca-speech.org/archive/interspeech_2020/dang20_interspeech.html|
|Discriminative Transfer Learning for Optimizing ASR and Semantic Labeling in Task-Oriented Spoken Dialog|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/qian20_interspeech.html|Spoken Dialogue System|https://www.isca-speech.org/archive/interspeech_2020/qian20_interspeech.html|
|Datasets and Benchmarks for Task-Oriented Log Dialogue Ranking Task|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/xu20f_interspeech.html|Spoken Dialogue System|https://www.isca-speech.org/archive/interspeech_2020/xu20f_interspeech.html|
|A Semi-Blind Source Separation Approach for Speech Dereverberation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20ca_interspeech.html|Dereverberation and Echo Cancellation|https://www.isca-speech.org/archive/interspeech_2020/wang20ca_interspeech.html|
|Virtual Acoustic Channel Expansion Based on Neural Networks for Weighted Prediction Error-Based Speech Dereverberation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yang20j_interspeech.html|Dereverberation and Echo Cancellation|https://www.isca-speech.org/archive/interspeech_2020/yang20j_interspeech.html|
|SkipConvNet: Skip Convolutional Neural Network for Speech Dereverberation Using Optimally Smoothed Spectral Mapping|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kothapally20_interspeech.html|Dereverberation and Echo Cancellation|https://www.isca-speech.org/archive/interspeech_2020/kothapally20_interspeech.html|
|A Robust and Cascaded Acoustic Echo Cancellation Based on Deep Learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20ea_interspeech.html|Dereverberation and Echo Cancellation|https://www.isca-speech.org/archive/interspeech_2020/zhang20ea_interspeech.html|
|Generative Adversarial Network Based Acoustic Echo Cancellation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20fa_interspeech.html|Dereverberation and Echo Cancellation|https://www.isca-speech.org/archive/interspeech_2020/zhang20fa_interspeech.html|
|Nonlinear Residual Echo Suppression Using a Recurrent Neural Network|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/pfeifenberger20_interspeech.html|Dereverberation and Echo Cancellation|https://www.isca-speech.org/archive/interspeech_2020/pfeifenberger20_interspeech.html|
|Independent Echo Path Modeling for Stereophonic Acoustic Echo Cancellation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/gao20d_interspeech.html|Dereverberation and Echo Cancellation|https://www.isca-speech.org/archive/interspeech_2020/gao20d_interspeech.html|
|Nonlinear Residual Echo Suppression Based on Multi-Stream Conv-TasNet|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chen20q_interspeech.html|Dereverberation and Echo Cancellation|https://www.isca-speech.org/archive/interspeech_2020/chen20q_interspeech.html|
|Improving Partition-Block-Based Acoustic Echo Canceler in Under-Modeling Scenarios|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/fan20c_interspeech.html|Dereverberation and Echo Cancellation|https://www.isca-speech.org/archive/interspeech_2020/fan20c_interspeech.html|
|Attention Wave-U-Net for Acoustic Echo Cancellation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kim20e_interspeech.html|Dereverberation and Echo Cancellation|https://www.isca-speech.org/archive/interspeech_2020/kim20e_interspeech.html|
|From Speaker Verification to Multispeaker Speech Synthesis, Deep Transfer with Feedback Constraint|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/cai20c_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis|https://www.isca-speech.org/archive/interspeech_2020/cai20c_interspeech.html|
|Can Speaker Augmentation Improve Multi-Speaker End-to-End TTS?|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/cooper20_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis|https://www.isca-speech.org/archive/interspeech_2020/cooper20_interspeech.html|
|Non-Autoregressive End-to-End TTS with Coarse-to-Fine Decoding|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20da_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis|https://www.isca-speech.org/archive/interspeech_2020/wang20da_interspeech.html|
|Bi-Level Speaker Supervision for One-Shot Speech Synthesis|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20ea_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis|https://www.isca-speech.org/archive/interspeech_2020/wang20ea_interspeech.html|
|Naturalness Enhancement with Linguistic Information in End-to-End TTS Using Unsupervised Parallel Encoding|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/peirolilja20_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis|https://www.isca-speech.org/archive/interspeech_2020/peirolilja20_interspeech.html|
|MoBoAligner: A Neural Alignment Model for Non-Autoregressive TTS with Monotonic Boundary Search|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20ha_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis|https://www.isca-speech.org/archive/interspeech_2020/li20ha_interspeech.html|
|JDI-T: Jointly Trained Duration Informed Transformer for Text-To-Speech without Explicit Alignment|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lim20_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis|https://www.isca-speech.org/archive/interspeech_2020/lim20_interspeech.html|
|End-to-End Text-to-Speech Synthesis with Unaligned Multiple Language Units Based on Attention|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/aso20_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis|https://www.isca-speech.org/archive/interspeech_2020/aso20_interspeech.html|
|Attention Forcing for Speech Synthesis|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/dou20_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis|https://www.isca-speech.org/archive/interspeech_2020/dou20_interspeech.html|
|Testing the Limits of Representation Mixing for Pronunciation Correction in End-to-End Speech Synthesis|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/fong20_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis|https://www.isca-speech.org/archive/interspeech_2020/fong20_interspeech.html|
|MultiSpeech: Multi-Speaker Text to Speech with Transformer|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chen20r_interspeech.html|Speech Synthesis: Toward End-to-End Synthesis|https://www.isca-speech.org/archive/interspeech_2020/chen20r_interspeech.html|
|Exploiting Conic Affinity Measures to Design Speech Enhancement Systems Operating in Unseen Noise Conditions|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/papadopoulos20_interspeech.html|Speech Enhancement, Bandwidth Extension and Hearing Aids|https://www.isca-speech.org/archive/interspeech_2020/papadopoulos20_interspeech.html|
|Adversarial Dictionary Learning for Monaural Speech Enhancement|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ji20_interspeech.html|Speech Enhancement, Bandwidth Extension and Hearing Aids|https://www.isca-speech.org/archive/interspeech_2020/ji20_interspeech.html|
|Semi-Supervised Self-Produced Speech Enhancement and Suppression Based on Joint Source Modeling of Air- and Body-Conducted Signals Using Variational Autoencoder|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/seki20_interspeech.html|Speech Enhancement, Bandwidth Extension and Hearing Aids|https://www.isca-speech.org/archive/interspeech_2020/seki20_interspeech.html|
|Spatial Covariance Matrix Estimation for Reverberant Speech with Application to Speech Enhancement|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/weisman20_interspeech.html|Speech Enhancement, Bandwidth Extension and Hearing Aids|https://www.isca-speech.org/archive/interspeech_2020/weisman20_interspeech.html|
|A Cross-Channel Attention-Based Wave-U-Net for Multi-Channel Speech Enhancement|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ho20_interspeech.html|Speech Enhancement, Bandwidth Extension and Hearing Aids|https://www.isca-speech.org/archive/interspeech_2020/ho20_interspeech.html|
|TinyLSTMs: Efficient Neural Speech Enhancement for Hearing Aids|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/fedorov20_interspeech.html|Speech Enhancement, Bandwidth Extension and Hearing Aids|https://www.isca-speech.org/archive/interspeech_2020/fedorov20_interspeech.html|
|Intelligibility Enhancement Based on Speech Waveform Modification Using Hearing Impairment|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hikosaka20_interspeech.html|Speech Enhancement, Bandwidth Extension and Hearing Aids|https://www.isca-speech.org/archive/interspeech_2020/hikosaka20_interspeech.html|
|Speaker and Phoneme-Aware Speech Bandwidth Extension with Residual Dual-Path Network|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hou20c_interspeech.html|Speech Enhancement, Bandwidth Extension and Hearing Aids|https://www.isca-speech.org/archive/interspeech_2020/hou20c_interspeech.html|
|Multi-Task Learning for End-to-End Noise-Robust Bandwidth Extension|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hou20d_interspeech.html|Speech Enhancement, Bandwidth Extension and Hearing Aids|https://www.isca-speech.org/archive/interspeech_2020/hou20d_interspeech.html|
|Phase-Aware Music Super-Resolution Using Generative Adversarial Networks|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hu20h_interspeech.html|Speech Enhancement, Bandwidth Extension and Hearing Aids|https://www.isca-speech.org/archive/interspeech_2020/hu20h_interspeech.html|
|Learning Utterance-Level Representations with Label Smoothing for Speech Emotion Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/huang20d_interspeech.html|Speech Emotion Recognition III|https://www.isca-speech.org/archive/interspeech_2020/huang20d_interspeech.html|
|Removing Bias with Residual Mixture of Multi-View Attention for Speech Emotion Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/jalal20_interspeech.html|Speech Emotion Recognition III|https://www.isca-speech.org/archive/interspeech_2020/jalal20_interspeech.html|
|Adaptive Domain-Aware Representation Learning for Speech Emotion Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/fan20d_interspeech.html|Speech Emotion Recognition III|https://www.isca-speech.org/archive/interspeech_2020/fan20d_interspeech.html|
|Speech Emotion Recognition with Discriminative Feature Learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhou20f_interspeech.html|Speech Emotion Recognition III|https://www.isca-speech.org/archive/interspeech_2020/zhou20f_interspeech.html|
|Using Speech Enhancement Preprocessing for Speech Emotion Recognition in Realistic Noisy Conditions|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhou20g_interspeech.html|Speech Emotion Recognition III|https://www.isca-speech.org/archive/interspeech_2020/zhou20g_interspeech.html|
|Comparison of Glottal Source Parameter Values in Emotional Vowels|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20ia_interspeech.html|Speech Emotion Recognition III|https://www.isca-speech.org/archive/interspeech_2020/li20ia_interspeech.html|
|Learning to Recognize Per-Rater’s Emotion Perception Using Co-Rater Training Strategy with Soft and Hard Labels|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chou20_interspeech.html|Speech Emotion Recognition III|https://www.isca-speech.org/archive/interspeech_2020/chou20_interspeech.html|
|Empirical Interpretation of Speech Emotion Perception with Attention Based Model for Speech Emotion Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/jalal20b_interspeech.html|Speech Emotion Recognition III|https://www.isca-speech.org/archive/interspeech_2020/jalal20b_interspeech.html|
|Phonetic Accommodation of L2 German Speakers to the Virtual Language Learning Tutor Mirabella|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/gessinger20_interspeech.html|Accoustic Phonetics of L1-L2 and Other Interactions|https://www.isca-speech.org/archive/interspeech_2020/gessinger20_interspeech.html|
|Characterization of Singaporean Children’s English: Comparisons to American and British Counterparts Using Archetypal Analysis|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/gu20b_interspeech.html|Accoustic Phonetics of L1-L2 and Other Interactions|https://www.isca-speech.org/archive/interspeech_2020/gu20b_interspeech.html|
|Rhythmic Convergence in Canadian French Varieties?|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kaminskaia20_interspeech.html|Accoustic Phonetics of L1-L2 and Other Interactions|https://www.isca-speech.org/archive/interspeech_2020/kaminskaia20_interspeech.html|
|Malayalam-English Code-Switched: Grapheme to Phoneme System|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/manghat20_interspeech.html|Accoustic Phonetics of L1-L2 and Other Interactions|https://www.isca-speech.org/archive/interspeech_2020/manghat20_interspeech.html|
|Ongoing Phonologization of Word-Final Voicing Alternations in Two Romance Languages: Romanian and French|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hutin20_interspeech.html|Accoustic Phonetics of L1-L2 and Other Interactions|https://www.isca-speech.org/archive/interspeech_2020/hutin20_interspeech.html|
|Cues for Perception of Gender in Synthetic Voices and the Role of Identity|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hope20_interspeech.html|Accoustic Phonetics of L1-L2 and Other Interactions|https://www.isca-speech.org/archive/interspeech_2020/hope20_interspeech.html|
|Phonetic Entrainment in Cooperative Dialogues: A Case of Russian|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/menshikova20_interspeech.html|Accoustic Phonetics of L1-L2 and Other Interactions|https://www.isca-speech.org/archive/interspeech_2020/menshikova20_interspeech.html|
|Prosodic Characteristics of Genuine and Mock (Im)polite Mandarin Utterances|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/xu20g_interspeech.html|Accoustic Phonetics of L1-L2 and Other Interactions|https://www.isca-speech.org/archive/interspeech_2020/xu20g_interspeech.html|
|Tone Variations in Regionally Accented Mandarin|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20ja_interspeech.html|Accoustic Phonetics of L1-L2 and Other Interactions|https://www.isca-speech.org/archive/interspeech_2020/li20ja_interspeech.html|
|F0 Patterns in Mandarin Statements of Mandarin and Cantonese Speakers|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yang20k_interspeech.html|Accoustic Phonetics of L1-L2 and Other Interactions|https://www.isca-speech.org/archive/interspeech_2020/yang20k_interspeech.html|
|SpeechBERT: An Audio-and-Text Jointly Learned Language Model for End-to-End Spoken Question Answering|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chuang20b_interspeech.html|Conversational Systems|https://www.isca-speech.org/archive/interspeech_2020/chuang20b_interspeech.html|
|An Audio-Enriched BERT-Based Framework for Spoken Multiple-Choice Question Answering|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kuo20b_interspeech.html|Conversational Systems|https://www.isca-speech.org/archive/interspeech_2020/kuo20b_interspeech.html|
|Entity Linking for Short Text Using Structured Knowledge Graph via Multi-Grained Text Matching|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/huang20e_interspeech.html|Conversational Systems|https://www.isca-speech.org/archive/interspeech_2020/huang20e_interspeech.html|
|Sound-Image Grounding Based Focusing Mechanism for Efficient Automatic Spoken Language Acquisition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20ga_interspeech.html|Conversational Systems|https://www.isca-speech.org/archive/interspeech_2020/zhang20ga_interspeech.html|
|Semi-Supervised Learning for Character Expression of Spoken Dialogue Systems|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yamamoto20_interspeech.html|Conversational Systems|https://www.isca-speech.org/archive/interspeech_2020/yamamoto20_interspeech.html|
|Dimensional Emotion Prediction Based on Interactive Context in Conversation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/shi20h_interspeech.html|Conversational Systems|https://www.isca-speech.org/archive/interspeech_2020/shi20h_interspeech.html|
|HRI-RNN: A User-Robot Dynamics-Oriented RNN for Engagement Decrease Detection|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/atamna20_interspeech.html|Conversational Systems|https://www.isca-speech.org/archive/interspeech_2020/atamna20_interspeech.html|
|Neural Representations of Dialogical History for Improving Upcoming Turn Acoustic Parameters Prediction|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/fuscone20_interspeech.html|Conversational Systems|https://www.isca-speech.org/archive/interspeech_2020/fuscone20_interspeech.html|
|Detecting Domain-Specific Credibility and Expertise in Text and Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hu20i_interspeech.html|Conversational Systems|https://www.isca-speech.org/archive/interspeech_2020/hu20i_interspeech.html|
|The Attacker’s Perspective on Automatic Speaker Verification: An Overview|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/das20c_interspeech.html|The Attacker’s Perpective on Automatic Speaker Verification|https://www.isca-speech.org/archive/interspeech_2020/das20c_interspeech.html|
|Extrapolating False Alarm Rates in Automatic Speaker Verification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/sholokhov20_interspeech.html|The Attacker’s Perpective on Automatic Speaker Verification|https://www.isca-speech.org/archive/interspeech_2020/sholokhov20_interspeech.html|
|Self-Supervised Spoofing Audio Detection Scheme|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/jiang20b_interspeech.html|The Attacker’s Perpective on Automatic Speaker Verification|https://www.isca-speech.org/archive/interspeech_2020/jiang20b_interspeech.html|
|Inaudible Adversarial Perturbations for Targeted Attack in Speaker Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20fa_interspeech.html|The Attacker’s Perpective on Automatic Speaker Verification|https://www.isca-speech.org/archive/interspeech_2020/wang20fa_interspeech.html|
|x-Vectors Meet Adversarial Attacks: Benchmarking Adversarial Robustness in Speaker Verification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/villalba20_interspeech.html|The Attacker’s Perpective on Automatic Speaker Verification|https://www.isca-speech.org/archive/interspeech_2020/villalba20_interspeech.html|
|Black-Box Attacks on Spoofing Countermeasures Using Transferability of Adversarial Examples|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20ha_interspeech.html|The Attacker’s Perpective on Automatic Speaker Verification|https://www.isca-speech.org/archive/interspeech_2020/zhang20ha_interspeech.html|
|Multimodal Emotion Recognition Using Cross-Modal Attention and 1D Convolutional Neural Networks|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/n20_interspeech.html|Summarization, Semantic Analysis and Classification|https://www.isca-speech.org/archive/interspeech_2020/n20_interspeech.html|
|Abstractive Spoken Document Summarization Using Hierarchical Model with Multi-Stage Attention Diversity Optimization|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/manakul20_interspeech.html|Summarization, Semantic Analysis and Classification|https://www.isca-speech.org/archive/interspeech_2020/manakul20_interspeech.html|
|Improved Learning of Word Embeddings with Word Definitions and Semantic Injection|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20ia_interspeech.html|Summarization, Semantic Analysis and Classification|https://www.isca-speech.org/archive/interspeech_2020/zhang20ia_interspeech.html|
|Wake Word Detection with Alignment-Free Lattice-Free MMI|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20ga_interspeech.html|Summarization, Semantic Analysis and Classification|https://www.isca-speech.org/archive/interspeech_2020/wang20ga_interspeech.html|
|Improving Vietnamese Named Entity Recognition from Speech Using Word Capitalization and Punctuation Recovery Models|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/nguyen20d_interspeech.html|Summarization, Semantic Analysis and Classification|https://www.isca-speech.org/archive/interspeech_2020/nguyen20d_interspeech.html|
|End-to-End Named Entity Recognition from English Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yadav20b_interspeech.html|Summarization, Semantic Analysis and Classification|https://www.isca-speech.org/archive/interspeech_2020/yadav20b_interspeech.html|
|Semantic Complexity in End-to-End Spoken Language Understanding|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mckenna20_interspeech.html|Summarization, Semantic Analysis and Classification|https://www.isca-speech.org/archive/interspeech_2020/mckenna20_interspeech.html|
|Analysis of Disfluency in Children’s Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/tran20c_interspeech.html|Summarization, Semantic Analysis and Classification|https://www.isca-speech.org/archive/interspeech_2020/tran20c_interspeech.html|
|Representation Based Meta-Learning for Few-Shot Spoken Intent Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mittal20_interspeech.html|Summarization, Semantic Analysis and Classification|https://www.isca-speech.org/archive/interspeech_2020/mittal20_interspeech.html|
|Complementary Language Model and Parallel Bi-LRNN for False Trigger Mitigation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/agarwal20b_interspeech.html|Summarization, Semantic Analysis and Classification|https://www.isca-speech.org/archive/interspeech_2020/agarwal20b_interspeech.html|
|Speaker-Utterance Dual Attention for Speaker and Utterance Verification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/liu20u_interspeech.html|Speaker Recognition II|https://www.isca-speech.org/archive/interspeech_2020/liu20u_interspeech.html|
|Adversarial Separation and Adaptation Network for Far-Field Speaker Verification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yi20b_interspeech.html|Speaker Recognition II|https://www.isca-speech.org/archive/interspeech_2020/yi20b_interspeech.html|
|MIRNet: Learning Multiple Identities Representations in Overlapped Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/han20b_interspeech.html|Speaker Recognition II|https://www.isca-speech.org/archive/interspeech_2020/han20b_interspeech.html|
|Strategies for End-to-End Text-Independent Speaker Verification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lin20l_interspeech.html|Speaker Recognition II|https://www.isca-speech.org/archive/interspeech_2020/lin20l_interspeech.html|
|Why Did the x-Vector System Miss a Target Speaker? Impact of Acoustic Mismatch Upon Target Score on VoxCeleb Data|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hautamaki20_interspeech.html|Speaker Recognition II|https://www.isca-speech.org/archive/interspeech_2020/hautamaki20_interspeech.html|
|Variable Frame Rate-Based Data Augmentation to Handle Speaking-Style Variability for Automatic Speaker Verification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/afshan20b_interspeech.html|Speaker Recognition II|https://www.isca-speech.org/archive/interspeech_2020/afshan20b_interspeech.html|
|A Machine of Few Words: Interactive Speaker Recognition with Reinforcement Learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/seurin20_interspeech.html|Speaker Recognition II|https://www.isca-speech.org/archive/interspeech_2020/seurin20_interspeech.html|
|Improving On-Device Speaker Verification Using Federated Learning with Privacy|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/granqvist20_interspeech.html|Speaker Recognition II|https://www.isca-speech.org/archive/interspeech_2020/granqvist20_interspeech.html|
|Neural PLDA Modeling for End-to-End Speaker Verification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ramoji20_interspeech.html|Speaker Recognition II|https://www.isca-speech.org/archive/interspeech_2020/ramoji20_interspeech.html|
|State Sequence Pooling Training of Acoustic Models for Keyword Spotting|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/opatka20_interspeech.html|General Topics in Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/opatka20_interspeech.html|
|Training Keyword Spotting Models on Non-IID Data with Federated Learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hard20_interspeech.html|General Topics in Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/hard20_interspeech.html|
|Class LM and Word Mapping for Contextual Biasing in End-to-End ASR|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/huang20f_interspeech.html|General Topics in Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/huang20f_interspeech.html|
|Do End-to-End Speech Recognition Models Care About Context?|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/borgholt20_interspeech.html|General Topics in Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/borgholt20_interspeech.html|
|Utterance Confidence Measure for End-to-End Speech Recognition with Applications to Distributed Speech Recognition Scenarios|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kumar20f_interspeech.html|General Topics in Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/kumar20f_interspeech.html|
|Speaker Code Based Speaker Adaptive Training Using Model Agnostic Meta-Learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wu20o_interspeech.html|General Topics in Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/wu20o_interspeech.html|
|Domain Adaptation Using Class Similarity for Robust Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhu20c_interspeech.html|General Topics in Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/zhu20c_interspeech.html|
|Incremental Machine Speech Chain Towards Enabling Listening While Speaking in Real-Time|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/novitasari20_interspeech.html|General Topics in Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/novitasari20_interspeech.html|
|Context-Dependent Acoustic Modeling Without Explicit Phone Clustering|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/raissi20_interspeech.html|General Topics in Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/raissi20_interspeech.html|
|Voice Conversion Based Data Augmentation to Improve Children’s Speech Recognition in Limited Data Scenario|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/shahnawazuddin20_interspeech.html|General Topics in Speech Recognition|https://www.isca-speech.org/archive/interspeech_2020/shahnawazuddin20_interspeech.html|
|CopyCat: Many-to-Many Fine-Grained Prosody Transfer for Neural Text-to-Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/karlapati20_interspeech.html|Speech Synthesis: Prosody Modeling|https://www.isca-speech.org/archive/interspeech_2020/karlapati20_interspeech.html|
|Joint Detection of Sentence Stress and Phrase Boundary for Prosody|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lin20m_interspeech.html|Speech Synthesis: Prosody Modeling|https://www.isca-speech.org/archive/interspeech_2020/lin20m_interspeech.html|
|Transfer Learning of the Expressivity Using FLOW Metric Learning in Multispeaker Text-to-Speech Synthesis|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kulkarni20_interspeech.html|Speech Synthesis: Prosody Modeling|https://www.isca-speech.org/archive/interspeech_2020/kulkarni20_interspeech.html|
|Speaking Speed Control of End-to-End Speech Synthesis Using Sentence-Level Conditioning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/bae20_interspeech.html|Speech Synthesis: Prosody Modeling|https://www.isca-speech.org/archive/interspeech_2020/bae20_interspeech.html|
|Dynamic Prosody Generation for Speech Synthesis Using Linguistics-Driven Acoustic Embedding Selection|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/tyagi20_interspeech.html|Speech Synthesis: Prosody Modeling|https://www.isca-speech.org/archive/interspeech_2020/tyagi20_interspeech.html|
|Improving the Prosody of RNN-Based English Text-To-Speech Synthesis by Incorporating a BERT Model|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kenter20_interspeech.html|Speech Synthesis: Prosody Modeling|https://www.isca-speech.org/archive/interspeech_2020/kenter20_interspeech.html|
|Improved Prosody from Learned F0 Codebook Representations for VQ-VAE Speech Waveform Reconstruction|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhao20g_interspeech.html|Speech Synthesis: Prosody Modeling|https://www.isca-speech.org/archive/interspeech_2020/zhao20g_interspeech.html|
|Prosody Learning Mechanism for Speech Synthesis System Without Text Length Limit|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zeng20b_interspeech.html|Speech Synthesis: Prosody Modeling|https://www.isca-speech.org/archive/interspeech_2020/zeng20b_interspeech.html|
|Discriminative Method to Extract Coarse Prosodic Structure and its Application for Statistical Phrase/Accent Command Estimation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/shirahata20_interspeech.html|Speech Synthesis: Prosody Modeling|https://www.isca-speech.org/archive/interspeech_2020/shirahata20_interspeech.html|
|Controllable Neural Text-to-Speech Synthesis Using Intuitive Prosodic Features|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/raitio20_interspeech.html|Speech Synthesis: Prosody Modeling|https://www.isca-speech.org/archive/interspeech_2020/raitio20_interspeech.html|
|Controllable Neural Prosody Synthesis|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/morrison20_interspeech.html|Speech Synthesis: Prosody Modeling|https://www.isca-speech.org/archive/interspeech_2020/morrison20_interspeech.html|
|Multi-Reference Neural TTS Stylization with Adversarial Cycle Consistency|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/whitehill20_interspeech.html|Speech Synthesis: Prosody Modeling|https://www.isca-speech.org/archive/interspeech_2020/whitehill20_interspeech.html|
|Interactive Text-to-Speech System via Joint Style Analysis|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/gao20e_interspeech.html|Speech Synthesis: Prosody Modeling|https://www.isca-speech.org/archive/interspeech_2020/gao20e_interspeech.html|
|Mobile-Assisted Prosody Training for Limited English Proficiency: Learner Background and Speech Learning Pattern|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hirschi20_interspeech.html|Language Learning|https://www.isca-speech.org/archive/interspeech_2020/hirschi20_interspeech.html|
|Finding Intelligible Consonant-Vowel Sounds Using High-Quality Articulatory Synthesis|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/niekerk20_interspeech.html|Language Learning|https://www.isca-speech.org/archive/interspeech_2020/niekerk20_interspeech.html|
|Audiovisual Correspondence Learning in Humans and Machines|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/krishnamohan20_interspeech.html|Language Learning|https://www.isca-speech.org/archive/interspeech_2020/krishnamohan20_interspeech.html|
|Perception of English Fricatives and Affricates by Advanced Chinese Learners of English|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lan20_interspeech.html|Language Learning|https://www.isca-speech.org/archive/interspeech_2020/lan20_interspeech.html|
|Perception of Japanese Consonant Length by Native Speakers of Korean Differing in Japanese Learning Experience|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/tsukada20_interspeech.html|Language Learning|https://www.isca-speech.org/archive/interspeech_2020/tsukada20_interspeech.html|
|Automatic Detection of Phonological Errors in Child Speech Using Siamese Recurrent Autoencoder|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ng20b_interspeech.html|Language Learning|https://www.isca-speech.org/archive/interspeech_2020/ng20b_interspeech.html|
|A Comparison of English Rhythm Produced by Native American Speakers and Mandarin ESL Primary School Learners|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ding20e_interspeech.html|Language Learning|https://www.isca-speech.org/archive/interspeech_2020/ding20e_interspeech.html|
|Cross-Linguistic Interaction Between Phonological Categorization and Orthography Predicts Prosodic Effects in the Acquisition of Portuguese Liquids by L1-Mandarin Learners|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhou20h_interspeech.html|Language Learning|https://www.isca-speech.org/archive/interspeech_2020/zhou20h_interspeech.html|
|Cross-Linguistic Perception of Utterances with Willingness and Reluctance in Mandarin by Korean L2 Learners|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20ka_interspeech.html|Language Learning|https://www.isca-speech.org/archive/interspeech_2020/li20ka_interspeech.html|
|Speech Enhancement Based on Beamforming and Post-Filtering by Combining Phase Information|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/cheng20b_interspeech.html|Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2020/cheng20b_interspeech.html|
|A Noise-Aware Memory-Attention Network Architecture for Regression-Based Speech Enhancement|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20ha_interspeech.html|Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2020/wang20ha_interspeech.html|
|HiFi-GAN: High-Fidelity Denoising and Dereverberation Based on Speech Deep Features in Adversarial Networks|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/su20b_interspeech.html|Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2020/su20b_interspeech.html|
|Learning Complex Spectral Mapping for Speech Enhancement with Improved Cross-Corpus Generalization|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/pandey20_interspeech.html|Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2020/pandey20_interspeech.html|
|Speech Enhancement with Stochastic Temporal Convolutional Networks|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/richter20_interspeech.html|Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2020/richter20_interspeech.html|
|Visual Speech In Real Noisy Environments (VISION): A Novel Benchmark Dataset and Deep Learning-Based Baseline System|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/gogate20_interspeech.html|Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2020/gogate20_interspeech.html|
|Sparse Mixture of Local Experts for Efficient Speech Enhancement|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/sivaraman20_interspeech.html|Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2020/sivaraman20_interspeech.html|
|Improved Speech Enhancement Using TCN with Multiple Encoder-Decoder Layers|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kishore20_interspeech.html|Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2020/kishore20_interspeech.html|
|Joint Training for Simultaneous Speech Denoising and Dereverberation with Deep Embedding Representations|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/fan20e_interspeech.html|Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2020/fan20e_interspeech.html|
|Unsupervised Robust Speech Enhancement Based on Alpha-Stable Fast Multichannel Nonnegative Matrix Factorization|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/fontaine20_interspeech.html|Speech Enhancement|https://www.isca-speech.org/archive/interspeech_2020/fontaine20_interspeech.html|
|Squeeze for Sneeze: Compact Neural Networks for Cold and Flu Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/albes20_interspeech.html|Speech in Health II|https://www.isca-speech.org/archive/interspeech_2020/albes20_interspeech.html|
|Extended Study on the Use of Vocal Tract Variables to Quantify Neuromotor Coordination in Depression|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/seneviratne20_interspeech.html|Speech in Health II|https://www.isca-speech.org/archive/interspeech_2020/seneviratne20_interspeech.html|
|Affective Conditioning on Hierarchical Attention Networks Applied to Depression Detection from Transcribed Clinical Interviews|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/xezonaki20_interspeech.html|Speech in Health II|https://www.isca-speech.org/archive/interspeech_2020/xezonaki20_interspeech.html|
|Domain Adaptation for Enhancing Speech-Based Depression Detection in Natural Environmental Conditions Using Dilated CNNs|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/huang20g_interspeech.html|Speech in Health II|https://www.isca-speech.org/archive/interspeech_2020/huang20g_interspeech.html|
|Making a Distinction Between Schizophrenia and Bipolar Disorder Based on Temporal Parameters in Spontaneous Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/gosztolya20b_interspeech.html|Speech in Health II|https://www.isca-speech.org/archive/interspeech_2020/gosztolya20b_interspeech.html|
|Prediction of Sleepiness Ratings from Voice by Man and Machine|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/huckvale20_interspeech.html|Speech in Health II|https://www.isca-speech.org/archive/interspeech_2020/huckvale20_interspeech.html|
|Tongue and Lip Motion Patterns in Alaryngeal Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/teplansky20_interspeech.html|Speech in Health II|https://www.isca-speech.org/archive/interspeech_2020/teplansky20_interspeech.html|
|Autoencoder Bottleneck Features with Multi-Task Optimisation for Improved Continuous Dysarthric Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/yue20b_interspeech.html|Speech in Health II|https://www.isca-speech.org/archive/interspeech_2020/yue20b_interspeech.html|
|Raw Speech Waveform Based Classification of Patients with ALS, Parkinson’s Disease and Healthy Controls Using CNN-BLSTM|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mallela20_interspeech.html|Speech in Health II|https://www.isca-speech.org/archive/interspeech_2020/mallela20_interspeech.html|
|Assessment of Parkinson’s Disease Medication State Through Automatic Speech Analysis|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/pompili20b_interspeech.html|Speech in Health II|https://www.isca-speech.org/archive/interspeech_2020/pompili20b_interspeech.html|
|Improving Replay Detection System with Channel Consistency DenseNeXt for the ASVspoof 2019 Challenge|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhang20ja_interspeech.html|Speech and Audio Quality Assessment|https://www.isca-speech.org/archive/interspeech_2020/zhang20ja_interspeech.html|
|Subjective Quality Evaluation of Speech Signals Transmitted via BPL-PLC Wired System|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/falkowskigilski20_interspeech.html|Speech and Audio Quality Assessment|https://www.isca-speech.org/archive/interspeech_2020/falkowskigilski20_interspeech.html|
|Investigating the Visual Lombard Effect with Gabor Based Features|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chiu20_interspeech.html|Speech and Audio Quality Assessment|https://www.isca-speech.org/archive/interspeech_2020/chiu20_interspeech.html|
|Exploration of Audio Quality Assessment and Anomaly Localisation Using Attention Models|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/huang20h_interspeech.html|Speech and Audio Quality Assessment|https://www.isca-speech.org/archive/interspeech_2020/huang20h_interspeech.html|
|Development of a Speech Quality Database Under Uncontrolled Conditions|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ragano20_interspeech.html|Speech and Audio Quality Assessment|https://www.isca-speech.org/archive/interspeech_2020/ragano20_interspeech.html|
|Evaluating the Reliability of Acoustic Speech Embeddings|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/algayres20_interspeech.html|Speech and Audio Quality Assessment|https://www.isca-speech.org/archive/interspeech_2020/algayres20_interspeech.html|
|Frame-Level Signal-to-Noise Ratio Estimation Using Deep Learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20la_interspeech.html|Speech and Audio Quality Assessment|https://www.isca-speech.org/archive/interspeech_2020/li20la_interspeech.html|
|A Pyramid Recurrent Network for Predicting Crowdsourced Speech-Quality Ratings of Real-World Signals|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/dong20_interspeech.html|Speech and Audio Quality Assessment|https://www.isca-speech.org/archive/interspeech_2020/dong20_interspeech.html|
|Effect of Spectral Complexity Reduction and Number of Instruments on Musical Enjoyment with Cochlear Implants|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/brueggeman20_interspeech.html|Speech and Audio Quality Assessment|https://www.isca-speech.org/archive/interspeech_2020/brueggeman20_interspeech.html|
|Spectrum Correction: Acoustic Scene Classification with Mismatched Recording Devices|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kosmider20_interspeech.html|Speech and Audio Quality Assessment|https://www.isca-speech.org/archive/interspeech_2020/kosmider20_interspeech.html|
|Distributed Summation Privacy for Speech Enhancement|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/oconnor20_interspeech.html|Privacy and Security in Speech Communication|https://www.isca-speech.org/archive/interspeech_2020/oconnor20_interspeech.html|
|Perception of Privacy Measured in the Crowd — Paired Comparison on the Effect of Background Noises|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/leschanowsky20_interspeech.html|Privacy and Security in Speech Communication|https://www.isca-speech.org/archive/interspeech_2020/leschanowsky20_interspeech.html|
|Hide and Speak: Towards Deep Neural Networks for Speech Steganography|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kreuk20b_interspeech.html|Privacy and Security in Speech Communication|https://www.isca-speech.org/archive/interspeech_2020/kreuk20b_interspeech.html|
|Detecting Adversarial Examples for Speech Recognition via Uncertainty Quantification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/daubener20_interspeech.html|Privacy and Security in Speech Communication|https://www.isca-speech.org/archive/interspeech_2020/daubener20_interspeech.html|
|Privacy Guarantees for De-Identifying Text Transformations|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/adelani20_interspeech.html|Privacy and Security in Speech Communication|https://www.isca-speech.org/archive/interspeech_2020/adelani20_interspeech.html|
|Detecting Audio Attacks on ASR Systems with Dropout Uncertainty|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/jayashankar20_interspeech.html|Privacy and Security in Speech Communication|https://www.isca-speech.org/archive/interspeech_2020/jayashankar20_interspeech.html|
|Voice Transformer Network: Sequence-to-Sequence Voice Conversion Using Transformer with Text-to-Speech Pretraining|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/huang20i_interspeech.html|Voice Conversion and Adaptation II|https://www.isca-speech.org/archive/interspeech_2020/huang20i_interspeech.html|
|Nonparallel Training of Exemplar-Based Voice Conversion System Using INCA-Based Alignment Technique|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/suda20_interspeech.html|Voice Conversion and Adaptation II|https://www.isca-speech.org/archive/interspeech_2020/suda20_interspeech.html|
|Enhancing Intelligibility of Dysarthric Speech Using Gated Convolutional-Based Voice Conversion System|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chen20s_interspeech.html|Voice Conversion and Adaptation II|https://www.isca-speech.org/archive/interspeech_2020/chen20s_interspeech.html|
|VQVC+: One-Shot Voice Conversion by Vector Quantization and U-Net Architecture|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wu20p_interspeech.html|Voice Conversion and Adaptation II|https://www.isca-speech.org/archive/interspeech_2020/wu20p_interspeech.html|
|Cotatron: Transcription-Guided Speech Encoder for Any-to-Many Voice Conversion Without Parallel Data|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/park20e_interspeech.html|Voice Conversion and Adaptation II|https://www.isca-speech.org/archive/interspeech_2020/park20e_interspeech.html|
|Dynamic Speaker Representations Adjustment and Decoder Factorization for Speaker Adaptation in End-to-End Speech Synthesis|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/fu20c_interspeech.html|Voice Conversion and Adaptation II|https://www.isca-speech.org/archive/interspeech_2020/fu20c_interspeech.html|
|ARVC: An Auto-Regressive Voice Conversion System Without Parallel Training Data|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lian20d_interspeech.html|Voice Conversion and Adaptation II|https://www.isca-speech.org/archive/interspeech_2020/lian20d_interspeech.html|
|Improved Zero-Shot Voice Conversion Using Explicit Conditioning Signals|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/nercessian20_interspeech.html|Voice Conversion and Adaptation II|https://www.isca-speech.org/archive/interspeech_2020/nercessian20_interspeech.html|
|Non-Parallel Voice Conversion with Fewer Labeled Data by Conditional Generative Adversarial Networks|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chen20t_interspeech.html|Voice Conversion and Adaptation II|https://www.isca-speech.org/archive/interspeech_2020/chen20t_interspeech.html|
|Transferring Source Style in Non-Parallel Voice Conversion|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/liu20v_interspeech.html|Voice Conversion and Adaptation II|https://www.isca-speech.org/archive/interspeech_2020/liu20v_interspeech.html|
|Voice Conversion Using Speech-to-Speech Neuro-Style Transfer|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/albadawy20_interspeech.html|Voice Conversion and Adaptation II|https://www.isca-speech.org/archive/interspeech_2020/albadawy20_interspeech.html|
|Improving Cross-Lingual Transfer Learning for End-to-End Speech Recognition with Speech Translation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20ia_interspeech.html|Multilingual and Code-Switched ASR|https://www.isca-speech.org/archive/interspeech_2020/wang20ia_interspeech.html|
|Transliteration Based Data Augmentation for Training Multilingual ASR Acoustic Models in Low Resource Settings|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/thomas20_interspeech.html|Multilingual and Code-Switched ASR|https://www.isca-speech.org/archive/interspeech_2020/thomas20_interspeech.html|
|Multilingual Speech Recognition with Self-Attention Structured Parameterization|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhu20d_interspeech.html|Multilingual and Code-Switched ASR|https://www.isca-speech.org/archive/interspeech_2020/zhu20d_interspeech.html|
|Lattice-Free Maximum Mutual Information Training of Multilingual Speech Recognition Systems|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/madikeri20_interspeech.html|Multilingual and Code-Switched ASR|https://www.isca-speech.org/archive/interspeech_2020/madikeri20_interspeech.html|
|Massively Multilingual ASR: 50 Languages, 1 Model, 1 Billion Parameters|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/pratap20c_interspeech.html|Multilingual and Code-Switched ASR|https://www.isca-speech.org/archive/interspeech_2020/pratap20c_interspeech.html|
|Multilingual Speech Recognition Using Language-Specific Phoneme Recognition as Auxiliary Task for Indian Languages|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/sailor20_interspeech.html|Multilingual and Code-Switched ASR|https://www.isca-speech.org/archive/interspeech_2020/sailor20_interspeech.html|
|Style Variation as a Vantage Point for Code-Switching|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chandu20_interspeech.html|Multilingual and Code-Switched ASR|https://www.isca-speech.org/archive/interspeech_2020/chandu20_interspeech.html|
|Bi-Encoder Transformer Network for Mandarin-English Code-Switching Speech Recognition Using Mixture of Experts|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lu20f_interspeech.html|Multilingual and Code-Switched ASR|https://www.isca-speech.org/archive/interspeech_2020/lu20f_interspeech.html|
|Improving Low Resource Code-Switched ASR Using Augmented Code-Switched TTS|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/sharma20c_interspeech.html|Multilingual and Code-Switched ASR|https://www.isca-speech.org/archive/interspeech_2020/sharma20c_interspeech.html|
|Towards Context-Aware End-to-End Code-Switching Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/qiu20c_interspeech.html|Multilingual and Code-Switched ASR|https://www.isca-speech.org/archive/interspeech_2020/qiu20c_interspeech.html|
|Increasing the Intelligibility and Naturalness of Alaryngeal Speech Using Voice Conversion and Synthetic Fundamental Frequency|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/dinh20b_interspeech.html|Speech and Voice Disorders|https://www.isca-speech.org/archive/interspeech_2020/dinh20b_interspeech.html|
|Automatic Assessment of Dysarthric Severity Level Using Audio-Video Cross-Modal Approach in Deep Learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/tong20b_interspeech.html|Speech and Voice Disorders|https://www.isca-speech.org/archive/interspeech_2020/tong20b_interspeech.html|
|Staged Knowledge Distillation for End-to-End Dysarthric Speech Recognition and Speech Attribute Transcription|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lin20n_interspeech.html|Speech and Voice Disorders|https://www.isca-speech.org/archive/interspeech_2020/lin20n_interspeech.html|
|Dysarthric Speech Recognition Based on Deep Metric Learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/takashima20_interspeech.html|Speech and Voice Disorders|https://www.isca-speech.org/archive/interspeech_2020/takashima20_interspeech.html|
|Automatic Glottis Detection and Segmentation in Stroboscopic Videos Using Convolutional Networks|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/degala20_interspeech.html|Speech and Voice Disorders|https://www.isca-speech.org/archive/interspeech_2020/degala20_interspeech.html|
|Acoustic Feature Extraction with Interpretable Deep Neural Network for Neurodegenerative Related Disorder Classification|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/pan20c_interspeech.html|Speech and Voice Disorders|https://www.isca-speech.org/archive/interspeech_2020/pan20c_interspeech.html|
|Coswara — A Database of Breathing, Cough, and Voice Sounds for COVID-19 Diagnosis|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/sharma20d_interspeech.html|Speech and Voice Disorders|https://www.isca-speech.org/archive/interspeech_2020/sharma20d_interspeech.html|
|Acoustic-Based Articulatory Phenotypes of Amyotrophic Lateral Sclerosis and Parkinson’s Disease: Towards an Interpretable, Hypothesis-Driven Framework of Motor Control|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/rowe20_interspeech.html|Speech and Voice Disorders|https://www.isca-speech.org/archive/interspeech_2020/rowe20_interspeech.html|
|Recognising Emotions in Dysarthric Speech Using Typical Speech Data|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/alhinti20_interspeech.html|Speech and Voice Disorders|https://www.isca-speech.org/archive/interspeech_2020/alhinti20_interspeech.html|
|Detecting and Analysing Spontaneous Oral Cancer Speech in the Wild|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/halpern20_interspeech.html|Speech and Voice Disorders|https://www.isca-speech.org/archive/interspeech_2020/halpern20_interspeech.html|
|The Zero Resource Speech Challenge 2020: Discovering Discrete Subword and Word Units|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/dunbar20_interspeech.html|The Zero Resource Speech Challenge 2020|https://www.isca-speech.org/archive/interspeech_2020/dunbar20_interspeech.html|
|Vector-Quantized Neural Networks for Acoustic Unit Discovery in the ZeroSpeech 2020 Challenge|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/niekerk20b_interspeech.html|The Zero Resource Speech Challenge 2020|https://www.isca-speech.org/archive/interspeech_2020/niekerk20b_interspeech.html|
|Exploration of End-to-End Synthesisers for Zero Resource Speech Challenge 2020|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ds20_interspeech.html|The Zero Resource Speech Challenge 2020|https://www.isca-speech.org/archive/interspeech_2020/ds20_interspeech.html|
|Vector Quantized Temporally-Aware Correspondence Sparse Autoencoders for Zero-Resource Acoustic Unit Discovery|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/gundogdu20_interspeech.html|The Zero Resource Speech Challenge 2020|https://www.isca-speech.org/archive/interspeech_2020/gundogdu20_interspeech.html|
|Transformer VQ-VAE for Unsupervised Unit Discovery and Speech Synthesis: ZeroSpeech 2020 Challenge|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/tjandra20_interspeech.html|The Zero Resource Speech Challenge 2020|https://www.isca-speech.org/archive/interspeech_2020/tjandra20_interspeech.html|
|Exploring TTS Without T Using Biologically/Psychologically Motivated Neural Network Modules (ZeroSpeech 2020)|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/morita20_interspeech.html|The Zero Resource Speech Challenge 2020|https://www.isca-speech.org/archive/interspeech_2020/morita20_interspeech.html|
|Cyclic Spectral Modeling for Unsupervised Unit Discovery into Voice Conversion with Excitation and Waveform Modeling|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/tobing20_interspeech.html|The Zero Resource Speech Challenge 2020|https://www.isca-speech.org/archive/interspeech_2020/tobing20_interspeech.html|
|Unsupervised Acoustic Unit Representation Learning for Voice Conversion Using WaveNet Auto-Encoders|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/chen20u_interspeech.html|The Zero Resource Speech Challenge 2020|https://www.isca-speech.org/archive/interspeech_2020/chen20u_interspeech.html|
|Unsupervised Discovery of Recurring Speech Patterns Using Probabilistic Adaptive Metrics|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/rasanen20_interspeech.html|The Zero Resource Speech Challenge 2020|https://www.isca-speech.org/archive/interspeech_2020/rasanen20_interspeech.html|
|Self-Expressing Autoencoders for Unsupervised Spoken Term Discovery|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/bhati20_interspeech.html|The Zero Resource Speech Challenge 2020|https://www.isca-speech.org/archive/interspeech_2020/bhati20_interspeech.html|
|Perceptimatic: A Human Speech Perception Benchmark for Unsupervised Subword Modelling|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/millet20_interspeech.html|The Zero Resource Speech Challenge 2020|https://www.isca-speech.org/archive/interspeech_2020/millet20_interspeech.html|
|Decoding Imagined, Heard, and Spoken Speech: Classification and Regression of EEG Using a 14-Channel Dry-Contact Mobile Headset|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/clayton20_interspeech.html|The Zero Resource Speech Challenge 2020|https://www.isca-speech.org/archive/interspeech_2020/clayton20_interspeech.html|
|Glottal Closure Instants Detection from EGG Signal by Classification Approach|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/m20b_interspeech.html|The Zero Resource Speech Challenge 2020|https://www.isca-speech.org/archive/interspeech_2020/m20b_interspeech.html|
|Classify Imaginary Mandarin Tones with Cortical EEG Signals|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20ma_interspeech.html|The Zero Resource Speech Challenge 2020|https://www.isca-speech.org/archive/interspeech_2020/li20ma_interspeech.html|
|Augmenting Images for ASR and TTS Through Single-Loop and Dual-Loop Multimodal Chain Framework|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/effendi20_interspeech.html|LM Adaptation, Lexical Units and Punctuation|https://www.isca-speech.org/archive/interspeech_2020/effendi20_interspeech.html|
|Punctuation Prediction in Spontaneous Conversations: Can We Mitigate ASR Errors with Retrofitted Word Embeddings?|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/augustyniak20_interspeech.html|LM Adaptation, Lexical Units and Punctuation|https://www.isca-speech.org/archive/interspeech_2020/augustyniak20_interspeech.html|
|Multimodal Semi-Supervised Learning Framework for Punctuation Prediction in Conversational Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/sunkara20_interspeech.html|LM Adaptation, Lexical Units and Punctuation|https://www.isca-speech.org/archive/interspeech_2020/sunkara20_interspeech.html|
|Efficient MDI Adaptation for n-Gram Language Models|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/huang20j_interspeech.html|LM Adaptation, Lexical Units and Punctuation|https://www.isca-speech.org/archive/interspeech_2020/huang20j_interspeech.html|
|Improving Tail Performance of a Deliberation E2E ASR Model Using a Large Text Corpus|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/peyser20_interspeech.html|LM Adaptation, Lexical Units and Punctuation|https://www.isca-speech.org/archive/interspeech_2020/peyser20_interspeech.html|
|Language Model Data Augmentation Based on Text Domain Transfer|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/ogawa20_interspeech.html|LM Adaptation, Lexical Units and Punctuation|https://www.isca-speech.org/archive/interspeech_2020/ogawa20_interspeech.html|
|Contemporary Polish Language Model (Version 2) Using Big Data and Sub-Word Approach|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wok20_interspeech.html|LM Adaptation, Lexical Units and Punctuation|https://www.isca-speech.org/archive/interspeech_2020/wok20_interspeech.html|
|Improving Speech Recognition of Compound-Rich Languages|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/pandey20b_interspeech.html|LM Adaptation, Lexical Units and Punctuation|https://www.isca-speech.org/archive/interspeech_2020/pandey20b_interspeech.html|
|Language Modeling for Speech Analytics in Under-Resourced Languages|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wills20_interspeech.html|LM Adaptation, Lexical Units and Punctuation|https://www.isca-speech.org/archive/interspeech_2020/wills20_interspeech.html|
|An Early Study on Intelligent Analysis of Speech Under COVID-19: Severity, Sleep Quality, Fatigue, and Anxiety|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/han20c_interspeech.html|Speech in Health I|https://www.isca-speech.org/archive/interspeech_2020/han20c_interspeech.html|
|An Evaluation of the Effect of Anxiety on Speech — Computational Prediction of Anxiety from Sustained Vowels|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/baird20_interspeech.html|Speech in Health I|https://www.isca-speech.org/archive/interspeech_2020/baird20_interspeech.html|
|Hybrid Network Feature Extraction for Depression Assessment from Speech|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhao20h_interspeech.html|Speech in Health I|https://www.isca-speech.org/archive/interspeech_2020/zhao20h_interspeech.html|
|Improving Detection of Alzheimer’s Disease Using Automatic Speech Recognition to Identify High-Quality Segments for More Robust Feature Extraction|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/pan20d_interspeech.html|Speech in Health I|https://www.isca-speech.org/archive/interspeech_2020/pan20d_interspeech.html|
|Classification of Manifest Huntington Disease Using Vowel Distortion Measures|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/romana20_interspeech.html|Speech in Health I|https://www.isca-speech.org/archive/interspeech_2020/romana20_interspeech.html|
|Parkinson’s Disease Detection from Speech Using Single Frequency Filtering Cepstral Coefficients|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kadiri20_interspeech.html|Speech in Health I|https://www.isca-speech.org/archive/interspeech_2020/kadiri20_interspeech.html|
|Automatic Prediction of Speech Intelligibility Based on X-Vectors in the Context of Head and Neck Cancer|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/quintas20_interspeech.html|Speech in Health I|https://www.isca-speech.org/archive/interspeech_2020/quintas20_interspeech.html|
|Spectral Moment and Duration of Burst of Plosives in Speech of Children with Hearing Impairment and Typically Developing Children — A Comparative Study|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/abraham20_interspeech.html|Speech in Health I|https://www.isca-speech.org/archive/interspeech_2020/abraham20_interspeech.html|
|Aphasic Speech Recognition Using a Mixture of Speech Intelligibility Experts|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/perez20_interspeech.html|Speech in Health I|https://www.isca-speech.org/archive/interspeech_2020/perez20_interspeech.html|
|Automatic Discrimination of Apraxia of Speech and Dysarthria Using a Minimalistic Set of Handcrafted Features|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/kodrasi20_interspeech.html|Speech in Health I|https://www.isca-speech.org/archive/interspeech_2020/kodrasi20_interspeech.html|
|Weak-Attention Suppression for Transformer Based Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/shi20i_interspeech.html|ASR Neural Network Architectures II — Transformers|https://www.isca-speech.org/archive/interspeech_2020/shi20i_interspeech.html|
|Conv-Transformer Transducer: Low Latency, Low Frame Rate, Streamable End-to-End Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/huang20k_interspeech.html|ASR Neural Network Architectures II — Transformers|https://www.isca-speech.org/archive/interspeech_2020/huang20k_interspeech.html|
|Improving Transformer-Based Speech Recognition with Unsupervised Pre-Training and Multi-Task Semantic Knowledge Learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/li20na_interspeech.html|ASR Neural Network Architectures II — Transformers|https://www.isca-speech.org/archive/interspeech_2020/li20na_interspeech.html|
|Transformer-Based Long-Context End-to-End Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hori20_interspeech.html|ASR Neural Network Architectures II — Transformers|https://www.isca-speech.org/archive/interspeech_2020/hori20_interspeech.html|
|Self-and-Mixed Attention Decoder with Deep Acoustic Structure for Transformer-Based LVCSR|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhou20i_interspeech.html|ASR Neural Network Architectures II — Transformers|https://www.isca-speech.org/archive/interspeech_2020/zhou20i_interspeech.html|
|Universal Speech Transformer|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhao20i_interspeech.html|ASR Neural Network Architectures II — Transformers|https://www.isca-speech.org/archive/interspeech_2020/zhao20i_interspeech.html|
|Spike-Triggered Non-Autoregressive Transformer for End-to-End Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/tian20c_interspeech.html|ASR Neural Network Architectures II — Transformers|https://www.isca-speech.org/archive/interspeech_2020/tian20c_interspeech.html|
|Cross Attention with Monotonic Alignment for Speech Transformer|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhao20j_interspeech.html|ASR Neural Network Architectures II — Transformers|https://www.isca-speech.org/archive/interspeech_2020/zhao20j_interspeech.html|
|Conformer: Convolution-augmented Transformer for Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/gulati20_interspeech.html|ASR Neural Network Architectures II — Transformers|https://www.isca-speech.org/archive/interspeech_2020/gulati20_interspeech.html|
|Exploring Transformers for Large-Scale Speech Recognition|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/lu20g_interspeech.html|ASR Neural Network Architectures II — Transformers|https://www.isca-speech.org/archive/interspeech_2020/lu20g_interspeech.html|
|Sparseness-Aware DOA Estimation with Majorization Minimization|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/togami20_interspeech.html|Spatial Audio|https://www.isca-speech.org/archive/interspeech_2020/togami20_interspeech.html|
|Spatial Resolution of Early Reflection for Speech and White Noise|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/zhong20c_interspeech.html|Spatial Audio|https://www.isca-speech.org/archive/interspeech_2020/zhong20c_interspeech.html|
|Effect of Microphone Position Measurement Error on RIR and its Impact on Speech Intelligibility and Quality|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/raikar20_interspeech.html|Spatial Audio|https://www.isca-speech.org/archive/interspeech_2020/raikar20_interspeech.html|
|Online Blind Reverberation Time Estimation Using CRNNs|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/deng20c_interspeech.html|Spatial Audio|https://www.isca-speech.org/archive/interspeech_2020/deng20c_interspeech.html|
|Single-Channel Blind Direct-to-Reverberation Ratio Estimation Using Masking|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/mack20_interspeech.html|Spatial Audio|https://www.isca-speech.org/archive/interspeech_2020/mack20_interspeech.html|
|The Importance of Time-Frequency Averaging for Binaural Speaker Localization in Reverberant Environments|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/beiton20_interspeech.html|Spatial Audio|https://www.isca-speech.org/archive/interspeech_2020/beiton20_interspeech.html|
|Acoustic Signal Enhancement Using Relative Harmonic Coefficients: Spherical Harmonics Domain Approach|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/hu20j_interspeech.html|Spatial Audio|https://www.isca-speech.org/archive/interspeech_2020/hu20j_interspeech.html|
|Instantaneous Time Delay Estimation of Broadband Signals|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/murthy20_interspeech.html|Spatial Audio|https://www.isca-speech.org/archive/interspeech_2020/murthy20_interspeech.html|
|U-Net Based Direct-Path Dominance Test for Robust Direction-of-Arrival Estimation|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/wang20ja_interspeech.html|Spatial Audio|https://www.isca-speech.org/archive/interspeech_2020/wang20ja_interspeech.html|
|Sound Event Localization and Detection Based on Multiple DOA Beamforming and Multi-Task Learning|interspeech20|https://www.isca-speech.org/archive/interspeech_2020/xue20b_interspeech.html|Spatial Audio|https://www.isca-speech.org/archive/interspeech_2020/xue20b_interspeech.html|
