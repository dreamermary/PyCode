|Streaming Align-Refine for Non-autoregressive Deliberation|interspeech22||https://arxiv.org/abs/2204.07556|
|Improving Rare Word Recognition with LM-aware MWER Training|interspeech22||https://arxiv.org/abs/2204.07553|
|Speaker-Aware Mixture of Mixtures Training for Weakly Supervised Speaker Extraction|interspeech22||https://arxiv.org/abs/2204.07375|
|Applying Feature Underspecified Lexicon Phonological Features in Multilingual Text-to-Speech|interspeech22||https://arxiv.org/abs/2204.07228|
|Predicting score distribution to improve non-intrusive speech quality estimation|interspeech22||https://arxiv.org/abs/2204.06616|
|Is Speech Pathology a Biomarker in Automatic Speaker Verification?|interspeech22||https://arxiv.org/abs/2204.06450|
|HuBERT-EE: Early Exiting HuBERT for Efficient Speech Recognition|interspeech22||https://arxiv.org/abs/2204.06328|
|Production federated keyword spotting via distillation, filtering, and joint federated-centralized training|interspeech22||https://arxiv.org/abs/2204.06322|
|A Unified Cascaded Encoder ASR Model for Dynamic Model Sizes|interspeech22||https://arxiv.org/abs/2204.06164|
|VoiceFixer: A Unified Framework for High-Fidelity Speech Restoration|interspeech22||https://arxiv.org/abs/2204.05841|
|Enhancement of Pitch Controllability using Timbre-Preserving Pitch Augmentation in FastPitch|interspeech22||https://arxiv.org/abs/2204.05753|
|Text-Driven Separation of Arbitrary Sounds|interspeech22||https://arxiv.org/abs/2204.05738|
|CorrectSpeech: A Fully Automated System for Speech Correction and Accent Reduction|interspeech22||https://arxiv.org/abs/2204.05460|
|Small Footprint Multi-channel ConvMixer for Keyword Spotting with Centroid Based Awareness|interspeech22||https://arxiv.org/abs/2204.05445|
|Can Self-Supervised Learning solve the problem of child speech recognition?|interspeech22||https://arxiv.org/abs/2204.05419|
|Large-Scale Streaming End-to-End Speech Translation with Neural Transducers|interspeech22||https://arxiv.org/abs/2204.05352|
||interspeech22|INTERSPEECH 2022 Audio Deep Packet Loss Concealment Challenge|https://arxiv.org/abs/2204.05222|
|How to Listen? Rethinking Visual Sound Localization|interspeech22||https://arxiv.org/abs/2204.05156|
|Fine-grained Noise Control for Multispeaker Speech Synthesis|interspeech22||https://arxiv.org/abs/2204.05070|
|On the pragmatism of using binary classifiers over data intensive neural network classifiers for detection of COVID-19 from voice|interspeech22||https://arxiv.org/abs/2204.04802|
|Deep Conditional Representation Learning for Drum Sample Retrieval by Vocalisation|interspeech22||https://arxiv.org/abs/2204.04651|
|Inferring Pitch from Coarse Spectral Features|interspeech22||https://arxiv.org/abs/2204.04579|
|Multichannel Speech Separation with Narrow-band Conformer|interspeech22||https://arxiv.org/abs/2204.04464|
|A Study of Using Cepstrogram for Countermeasure Against Replay Attacks|interspeech22||https://arxiv.org/abs/2204.04333|
|Automatic Data Augmentation Selection and Parametrization in Contrastive Self-Supervised Speech Representation Learning|interspeech22||https://arxiv.org/abs/2204.04170|
|Self-supervised Speaker Diarization|interspeech22||https://arxiv.org/abs/2204.04166|
|Karaoker: Alignment-free singing voice synthesis with speech training data|interspeech22||https://arxiv.org/abs/2204.04127|
|Analysis and transformations of intensity in singing voice|interspeech22||https://arxiv.org/abs/2204.04006|
|Hierarchical and Multi-Scale Variational Autoencoder for Diverse and Natural Non-Autoregressive Text-to-Speech|interspeech22||https://arxiv.org/abs/2204.04004|
|The Sillwood Technologies System for the VoiceMOS Challenge|interspeech22||https://arxiv.org/abs/2204.03967|
|GigaST: A 10,000-hour Pseudo Speech Translation Corpus|interspeech22||https://arxiv.org/abs/2204.03939|
|Adding Connectionist Temporal Summarization into Conformer to Improve Its Decoder Efficiency For Speech Recognition|interspeech22||https://arxiv.org/abs/2204.03889|
|Transducer-based language embedding for spoken language identification|interspeech22||https://arxiv.org/abs/2204.03888|
|A Study of Different Ways to Use The Conformer Model For Spoken Language Understanding|interspeech22||https://arxiv.org/abs/2204.03879|
|Automatic Pronunciation Assessment using Self-Supervised Speech Representation Learning|interspeech22||https://arxiv.org/abs/2204.03863|
|Hierarchical Softmax for End-to-End Low-resource Multilingual Speech Recognition|interspeech22||https://arxiv.org/abs/2204.03855|
|Reliable Visualization for Deep Speaker Recognition|interspeech22||https://arxiv.org/abs/2204.03852|
|Defense against Adversarial Attacks on Hybrid Speech Recognition using Joint Adversarial Fine-tuning with Denoiser|interspeech22||https://arxiv.org/abs/2204.03851|
|AdvEst: Adversarial Perturbation Estimation to Classify and Detect Adversarial Attacks against Speaker Identification|interspeech22||https://arxiv.org/abs/2204.03848|
|Enhanced exemplar autoencoder with cycle consistency loss in any-to-one voice conversion|interspeech22||https://arxiv.org/abs/2204.03847|
|Personal VAD 2.0: Optimizing Personal Voice Activity Detection for On-Device Speech Recognition|interspeech22||https://arxiv.org/abs/2204.03793|
|Heterogeneous Target Speech Separation|interspeech22||https://arxiv.org/abs/2204.03594|
|Detecting Vocal Fatigue with Neural Embeddings|interspeech22||https://arxiv.org/abs/2204.03428|
|Self supervised learning for robust voice cloning|interspeech22||https://arxiv.org/abs/2204.03421|
|Detecting Dysfluencies in Stuttering Therapy Using wav2vec 2.0|interspeech22||https://arxiv.org/abs/2204.03417|
|MAESTRO: Matched Speech Text Representations through Modality Matching|interspeech22||https://arxiv.org/abs/2204.03409|
|Linguistic-Acoustic Similarity Based Accent Shift for Accent Recognition|interspeech22||https://arxiv.org/abs/2204.03398|
|Correcting Misproducted Speech using Spectrogram Inpainting|interspeech22||https://arxiv.org/abs/2204.03379|
|Boosting Self-Supervised Embeddings for Speech Enhancement|interspeech22||https://arxiv.org/abs/2204.03339|
|Three-Module Modeling For End-to-End Spoken Language Understanding Using Pre-trained DNN-HMM-Based Acoustic-Phonetic Model|interspeech22||https://arxiv.org/abs/2204.03315|
|MTI-Net: A Multi-Target Speech Intelligibility Prediction Model|interspeech22||https://arxiv.org/abs/2204.03310|
|MBI-Net: A Non-Intrusive Multi-Branched Speech Intelligibility Prediction Model for Hearing Aids|interspeech22||https://arxiv.org/abs/2204.03305|
|Expressive Singing Synthesis Using Local Style Token and Dual-path Pitch Encoder|interspeech22||https://arxiv.org/abs/2204.03249|
|Speech Pre-training with Acoustic Piece|interspeech22||https://arxiv.org/abs/2204.03240|
|Leveraging Real Conversational Data for Multi-Channel Continuous Speech Separation|interspeech22||https://arxiv.org/abs/2204.03232|
|DDOS: A MOS Prediction Framework utilizing Domain Adaptive Pre-training and Distribution of Opinion Scores|interspeech22||https://arxiv.org/abs/2204.03219|
|3M: Multi-loss, Multi-path and Multi-level Neural Networks for speech recognition|interspeech22||https://arxiv.org/abs/2204.03178|
|ByT5 model for massively multilingual grapheme-to-phoneme conversion|interspeech22||https://arxiv.org/abs/2204.03067|
|FFC-SE: Fast Fourier Convolution for Speech Enhancement|interspeech22||https://arxiv.org/abs/2204.03042|
|SOMOS: The Samsung Open MOS Dataset for the Evaluation of Neural Text-to-Speech Synthesis|interspeech22||https://arxiv.org/abs/2204.03040|
|Enhanced Direct Speech-to-Speech Translation Using Self-supervised Pre-training and Data Augmentation|interspeech22||https://arxiv.org/abs/2204.02967|
|Towards Multi-Scale Speaking Style Modelling with Hierarchical Context Information for Mandarin Speech Synthesis|interspeech22||https://arxiv.org/abs/2204.02743|
|Neural Network-augmented Kalman Filtering for Robust Online Speech Dereverberation in Noisy Reverberant Environments|interspeech22||https://arxiv.org/abs/2204.02741|
|Representation Selective Self-distillation and wav2vec 2.0 Feature Exploration for Spoof-aware Speaker Verification|interspeech22||https://arxiv.org/abs/2204.02639|
|Global HRTF Interpolation via Learned Affine Transformation of Hyper-conditioned Features|interspeech22||https://arxiv.org/abs/2204.02637|
|Prosodic Alignment for off-screen automatic dubbing|interspeech22||https://arxiv.org/abs/2204.02530|
|Combining Spectral and Self-Supervised Features for Low Resource Speech Recognition and Translation|interspeech22||https://arxiv.org/abs/2204.02470|
|Improving Voice Trigger Detection with Metric Learning|interspeech22||https://arxiv.org/abs/2204.02455|
|Leveraging Speech Separation for Conversational Telephone Speaker Diarization|interspeech22||https://arxiv.org/abs/2204.02306|
|How Information on Acoustic Scenes and Sound Events Mutually Benefits Event Detection and Scene Classification Tasks|interspeech22||https://arxiv.org/abs/2204.02279|
|Multilingual and Multimodal Abuse Detection|interspeech22||https://arxiv.org/abs/2204.02263|
|A Comparison of Deep Learning MOS Predictors for Speech Synthesis Quality|interspeech22||https://arxiv.org/abs/2204.02249|
|Complex Recurrent Variational Autoencoder for Speech Enhancement|interspeech22||https://arxiv.org/abs/2204.02195|
|AILTTS: Adversarial Learning of Intermediate Acoustic Feature for End-to-End Lightweight Text-to-Speech|interspeech22||https://arxiv.org/abs/2204.02172|
|UTMOS: UTokyo-SaruLab System for VoiceMOS Challenge|interspeech22||https://arxiv.org/abs/2204.02152|
|Exploring the influence of fine-tuning data on wav2vec 2.0 model for blind speech quality prediction|interspeech22||https://arxiv.org/abs/2204.02135|
|VocaLiST: An Audio-Visual Synchronisation Model for Lips and Voices|interspeech22||https://arxiv.org/abs/2204.02090|
|Unsupervised Data Selection via Discrete Speech Representation for ASR|interspeech22||https://arxiv.org/abs/2204.01981|
|Deliberation Model for On-Device Spoken Language Understanding|interspeech22||https://arxiv.org/abs/2204.01893|
|Self-Supervised Speech Representations Preserve Speech Characteristics while Anonymizing Voices|interspeech22||https://arxiv.org/abs/2204.01677|
|Cross-lingual Self-Supervised Speech Representations for Improved Dysarthric Speech Recognition|interspeech22||https://arxiv.org/abs/2204.01670|
|Introducing ECAPA-TDNN and Wav2Vec2.0 Embeddings to Stuttering Detection|interspeech22||https://arxiv.org/abs/2204.01564|
|The Vicomtech Spoofing-Aware Biometric System for the SASV Challenge|interspeech22||https://arxiv.org/abs/2204.01399|
|A Study of Gender Impact in Self-supervised Models for Speech-to-Text Systems|interspeech22||https://arxiv.org/abs/2204.01397|
|Anti-Spoofing Using Transfer Learning with Variational Information Bottleneck|interspeech22||https://arxiv.org/abs/2204.01387|
|Target Confusion in End-to-end Speaker Extraction: Analysis and Approaches|interspeech22||https://arxiv.org/abs/2204.01355|
|MOSRA: Joint Mean Opinion Score and Room Acoustics Speech Quality Assessment|interspeech22||https://arxiv.org/abs/2204.01345|
|An Initialization Scheme for Meeting Separation with Spatial Mixture Models|interspeech22||https://arxiv.org/abs/2204.01338|
|tPLCnet: Real-time Deep Packet Loss Concealment in the Time Domain Using a Short Temporal Context|interspeech22||https://arxiv.org/abs/2204.01300|
|Into-TTS : Intonation Template based Prosody Control System|interspeech22||https://arxiv.org/abs/2204.01271|
|Analysis of Joint Speech-Text Embeddings for Semantic Matching|interspeech22||https://arxiv.org/abs/2204.01235|
|On incorporating social speaker characteristics in synthetic speech|interspeech22||https://arxiv.org/abs/2204.01115|
|Selective Kernel Attention for Robust Speaker Verification|interspeech22||https://arxiv.org/abs/2204.01005|
|Content-Dependent Fine-Grained Speaker Embedding for Zero-Shot Speaker Adaptation in Text-to-Speech Synthesis|interspeech22||https://arxiv.org/abs/2204.00990|
|Automatic Dialect Density Estimation for African American English|interspeech22||https://arxiv.org/abs/2204.00967|
|From Simulated Mixtures to Simulated Conversations as Training Data for End-to-End Neural Diarization|interspeech22||https://arxiv.org/abs/2204.00890|
|Leveraging Phone Mask Training for Phonetic-Reduction-Robust E2E Uyghur Speech Recognition|interspeech22||https://arxiv.org/abs/2204.00819|
|End-to-end model for named entity recognition from speech without paired training data|interspeech22||https://arxiv.org/abs/2204.00803|
|Fast Real-time Personalized Speech Enhancement: End-to-End Enhancement Network (E3Net) and Knowledge Distillation|interspeech22||https://arxiv.org/abs/2204.00771|
|Speaker adaptation for Wav2vec2 based dysarthric ASR|interspeech22||https://arxiv.org/abs/2204.00770|
|Multimodal Clustering with Role Induced Constraints for Speaker Diarization|interspeech22||https://arxiv.org/abs/2204.00657|
|A single speaker is almost all you need for automatic speech recognition|interspeech22||https://arxiv.org/abs/2204.00618|
|End-to-End Integration of Speech Recognition, Speech Enhancement, and Self-Supervised Learning Representation|interspeech22||https://arxiv.org/abs/2204.00540|
|Deep Neural Convolutive Matrix Factorization for Articulatory Representation Decomposition|interspeech22||https://arxiv.org/abs/2204.00465|
|Zero-Shot Cross-lingual Aphasia Detection using Automatic Speech Recognition|interspeech22||https://arxiv.org/abs/2204.00448|
|AdaSpeech 4: Adaptive Text to Speech in Zero-Shot Scenarios|interspeech22||https://arxiv.org/abs/2204.00436|
|Probing Speech Emotion Recognition Transformers for Linguistic Knowledge|interspeech22||https://arxiv.org/abs/2204.00400|
|On the Efficiency of Integrating Self-supervised Learning and Meta-learning for User-defined Few-shot Keyword Spotting|interspeech22||https://arxiv.org/abs/2204.00352|
|Effect and Analysis of Large-scale Language Model Rescoring on Competitive ASR Systems|interspeech22||https://arxiv.org/abs/2204.00212|
|Multi-sequence Intermediate Conditioning for CTC-based ASR|interspeech22||https://arxiv.org/abs/2204.00175|
|Universal Adaptor: Converting Mel-Spectrograms Between Different Configurations for Speech Synthesis|interspeech22||https://arxiv.org/abs/2204.00170|
|Speech and the n-Back task as a lens into depression. How combining both may allow us to isolate different core symptoms of depression|interspeech22||https://arxiv.org/abs/2204.00088|
|Importance of Different Temporal Modulations of Speech: A Tale of Two Perspectives|interspeech22||https://arxiv.org/abs/2204.00065|
|Data-augmented cross-lingual synthesis in a teacher-student framework|interspeech22||https://arxiv.org/abs/2204.00061|
|Automatic Detection of Expressed Emotion from Five-Minute Speech Samples: Challenges and Opportunities|interspeech22||https://arxiv.org/abs/2203.17242|
|Improved Relation Networks for End-to-End Speaker Verification and Identification|interspeech22||https://arxiv.org/abs/2203.17218|
|Mixed-Phoneme BERT: Improving BERT with Mixed Phoneme and Sup-Phoneme Representations for Text to Speech|interspeech22||https://arxiv.org/abs/2203.17190|
|Efficient Non-Autoregressive GAN Voice Conversion using VQWav2vec Features and Dynamic Convolution|interspeech22||https://arxiv.org/abs/2203.17172|
|Perceptual Contrast Stretching on Target Feature for Speech Enhancement|interspeech22||https://arxiv.org/abs/2203.17152|
|Pre-Training Transformer Decoder for End-to-End ASR Model with Unpaired Speech Data|interspeech22||https://arxiv.org/abs/2203.17113|
|Impact of Acoustic Noise on Alzheimer's Disease Detection from Speech: Should You Let Baby Cry?|interspeech22||https://arxiv.org/abs/2203.17110|
|Manipulation of oral cancer speech using neural articulatory synthesis|interspeech22||https://arxiv.org/abs/2203.17072|
|EEND-SS: Joint End-to-End Neural Speaker Diarization and Speech Separation for Flexible Number of Speakers|interspeech22||https://arxiv.org/abs/2203.17068|
|Partial Coupling of Optimal Transport for Spoken Language Identification|interspeech22||https://arxiv.org/abs/2203.17036|
|CTA-RNN: Channel and Temporal-wise Attention RNN Leveraging Pre-trained ASR Embeddings for Speech Emotion Recognition|interspeech22||https://arxiv.org/abs/2203.17023|
|DeepFry: Identifying Vocal Fry Using Deep Neural Networks|interspeech22||https://arxiv.org/abs/2203.17019|
|Speech Enhancement with Score-Based Generative Models in the Complex STFT Domain|interspeech22||https://arxiv.org/abs/2203.17004|
|Analyzing the factors affecting usefulness of Self-Supervised Pre-trained Representations for Speech Recognition|interspeech22||https://arxiv.org/abs/2203.16973|
|Improving Language Identification of Accented Speech|interspeech22||https://arxiv.org/abs/2203.16972|
|A Comparative Study of Fusion Methods for SASV Challenge|interspeech22||https://arxiv.org/abs/2203.16970|
|PADA: Pruning Assisted Domain Adaptation for Self-Supervised Speech Representations|interspeech22||https://arxiv.org/abs/2203.16965|
|HiFi-VC: High Quality ASR-Based Voice Conversion|interspeech22||https://arxiv.org/abs/2203.16937|
|WavThruVec: Latent speech representation as intermediate features for neural speech synthesis|interspeech22||https://arxiv.org/abs/2203.16930|
|Memory-Efficient Training of RNN-Transducer with Sampled Softmax|interspeech22||https://arxiv.org/abs/2203.16868|
|Investigating Modality Bias in Audio Visual Video Parsing|interspeech22||https://arxiv.org/abs/2203.16860|
|JETS: Jointly Training FastSpeech2 and HiFi-GAN for End to End Text to Speech|interspeech22||https://arxiv.org/abs/2203.16852|
|Hierarchical Attention Network for Evaluating Therapist Empathy in Counseling Session|interspeech22||https://arxiv.org/abs/2203.16847|
|A Comparative Study on Speaker-attributed Automatic Speech Recognition in Multi-party Meetings|interspeech22||https://arxiv.org/abs/2203.16834|
|indic-punct: An automatic punctuation restoration and inverse text normalization framework for Indic languages|interspeech22||https://arxiv.org/abs/2203.16825|
|Effectiveness of text to speech pseudo labels for forced alignment and cross lingual pretrained models for low resource speech recognition|interspeech22||https://arxiv.org/abs/2203.16823|
|How Does Pre-trained Wav2Vec2.0 Perform on Domain Shifted ASR? An Extensive Benchmark on Air Traffic Control Communications|interspeech22||https://arxiv.org/abs/2203.16822|
|A Discourse Aware Sequence Learning Approach for Emotion Recognition in Conversations|interspeech22||https://arxiv.org/abs/2203.16799|
|MMER: Multimodal Multi-task learning for Emotion Recognition in Spoken Utterances|interspeech22||https://arxiv.org/abs/2203.16794|
|An Empirical Study of Language Model Integration for Transducer based Speech Recognition|interspeech22||https://arxiv.org/abs/2203.16776|
|An Exploration of Prompt Tuning on Generative Spoken Language Model for Speech Processing Tasks|interspeech22||https://arxiv.org/abs/2203.16773|
|Subjective intelligibility of speech sounds enhanced by ideal ratio mask via crowdsourced remote experiments with effective data screening|interspeech22||https://arxiv.org/abs/2203.16760|
|CUSIDE: Chunking, Simulating Future Context and Decoding for Streaming ASR|interspeech22||https://arxiv.org/abs/2203.16758|
|Exploiting Single-Channel Speech for Multi-Channel End-to-End Speech Recognition: A Comparative Study|interspeech22||https://arxiv.org/abs/2203.16757|
|SpecGrad: Diffusion Probabilistic Model based Neural Vocoder with Adaptive Noise Spectral Shaping|interspeech22||https://arxiv.org/abs/2203.16749|
|MAE-AST: Masked Autoencoding Audio Spectrogram Transformer|interspeech22||https://arxiv.org/abs/2203.16691|
|Streaming Speaker-Attributed ASR with Token-Level Speaker Embeddings|interspeech22||https://arxiv.org/abs/2203.16685|
|Hybrid Handcrafted and Learnable Audio Representation for Analysis of Speech Under Cognitive and Physical Load|interspeech22||https://arxiv.org/abs/2203.16637|
|Joint domain adaptation and speech bandwidth extension using time-domain GANs for speaker verification|interspeech22||https://arxiv.org/abs/2203.16614|
|Is Word Error Rate a good evaluation metric for Speech Recognition in Indic Languages?|interspeech22||https://arxiv.org/abs/2203.16601|
|Improving Speech Recognition for Indic Languages using Language Model|interspeech22||https://arxiv.org/abs/2203.16595|
|Code Switched and Code Mixed Speech Recognition for Indic languages|interspeech22||https://arxiv.org/abs/2203.16578|
|Recent improvements of ASR models in the face of adversarial attacks|interspeech22||https://arxiv.org/abs/2203.16536|
|Vakyansh: ASR Toolkit for Low Resource Indic languages|interspeech22||https://arxiv.org/abs/2203.16512|
|Learn2Sing 2.0: Diffusion and Mutual Information-Based Target Speaker SVS by Learning from Singing Teacher|interspeech22||https://arxiv.org/abs/2203.16408|
|Rainbow Keywords: Efficient Incremental Learning for Online Spoken Keyword Spotting|interspeech22||https://arxiv.org/abs/2203.16361|
|Does Audio Deepfake Detection Generalize?|interspeech22||https://arxiv.org/abs/2203.16263|
|Phase-Aware Deep Speech Enhancement: It's All About The Frame Length|interspeech22||https://arxiv.org/abs/2203.16222|
|Probing phoneme, language and speaker information in unsupervised speech representations|interspeech22||https://arxiv.org/abs/2203.16193|
|Example-based Explanations with Adversarial Attacks for Respiratory Sound Analysis|interspeech22||https://arxiv.org/abs/2203.16141|
|Improving Distortion Robustness of Self-supervised Speech Processing Tasks with Domain Adaptation|interspeech22||https://arxiv.org/abs/2203.16104|
|Combination of Time-domain, Frequency-domain, and Cepstral-domain Acoustic Features for Speech Commands Classification|interspeech22||https://arxiv.org/abs/2203.16085|
|Using Adapters to Overcome Catastrophic Forgetting in End-to-End Automatic Speech Recognition|interspeech22||https://arxiv.org/abs/2203.16082|
|Asymmetric Proxy Loss for Multi-View Acoustic Word Embeddings|interspeech22||https://arxiv.org/abs/2203.16080|
|Disentangling the Impacts of Language and Channel Variability on Speech Separation Networks|interspeech22||https://arxiv.org/abs/2203.16040|
|Optimizing Shoulder to Shoulder: A Coordinated Sub-Band Fusion Model for Real-Time Full-Band Speech Enhancement|interspeech22||https://arxiv.org/abs/2203.16033|
|Multi-Target Filter and Detector for Speaker Diarization|interspeech22||https://arxiv.org/abs/2203.16007|
|Device-Directed Speech Detection: Regularization via Distillation for Weakly-Supervised Models|interspeech22||https://arxiv.org/abs/2203.15975|
|Multi-scale Speaker Diarization with Dynamic Scale Weighting|interspeech22||https://arxiv.org/abs/2203.15974|
|Using Active Speaker Faces for Diarization in TV shows|interspeech22||https://arxiv.org/abs/2203.15961|
|4-bit Conformer with Native Quantization Aware Training for Speech Recognition|interspeech22||https://arxiv.org/abs/2203.15952|
|Improving Mispronunciation Detection with Wav2vec2-based Momentum Pseudo-Labeling for Accentedness and Intelligibility Assessment|interspeech22||https://arxiv.org/abs/2203.15937|
|An Overview & Analysis of Sequence-to-Sequence Emotional Voice Conversion|interspeech22||https://arxiv.org/abs/2203.15873|
|WAVPROMPT: Towards Few-Shot Spoken Language Understanding with Frozen Language Models|interspeech22||https://arxiv.org/abs/2203.15863|
|Seq-2-Seq based Refinement of ASR Output for Spoken Name Capture|interspeech22||https://arxiv.org/abs/2203.15833|
|Unsupervised Text-to-Speech Synthesis by Unsupervised Automatic Speech Recognition|interspeech22||https://arxiv.org/abs/2203.15796|
|Streaming parallel transducer beam search with fast-slow cascaded encoders|interspeech22||https://arxiv.org/abs/2203.15773|
|A Sparsity-promoting Dictionary Model for Variational Autoencoders|interspeech22||https://arxiv.org/abs/2203.15758|
|A Passive Similarity based CNN Filter Pruning for Efficient Acoustic Scene Classification|interspeech22||https://arxiv.org/abs/2203.15751|
|DRSpeech: Degradation-Robust Text-to-Speech Synthesis with Frame-Level and Utterance-Level Acoustic Representation Learning|interspeech22||https://arxiv.org/abs/2203.15683|
|CycleGAN-Based Unpaired Speech Dereverberation|interspeech22||https://arxiv.org/abs/2203.15652|
|Nix-TTS: An Incredibly Lightweight End-to-End Text-to-Speech Model via Non End-to-End Distillation|interspeech22||https://arxiv.org/abs/2203.15643|
|Dynamic Latency for CTC-Based Streaming Automatic Speech Recognition With Emformer|interspeech22||https://arxiv.org/abs/2203.15613|
|Locality Matters: A Locality-Biased Linear Attention for Automatic Speech Recognition|interspeech22||https://arxiv.org/abs/2203.15609|
|Earnings-22: A Practical Benchmark for Accents in the Wild|interspeech22||https://arxiv.org/abs/2203.15591|
|Disentangling speech from surroundings in a neural audio codec|interspeech22||https://arxiv.org/abs/2203.15578|
|Interactive Audio-text Representation for Automated Audio Captioning with Contrastive Learning|interspeech22||https://arxiv.org/abs/2203.15526|
|Learning neural audio features without supervision|interspeech22||https://arxiv.org/abs/2203.15519|
|Representing `how you say' with `what you say': English corpus of focused speech and text reflecting corresponding implications|interspeech22||https://arxiv.org/abs/2203.15483|
|Speech Segmentation Optimization using Segmented Bilingual Speech Corpus for End-to-end Speech Translation|interspeech22||https://arxiv.org/abs/2203.15479|
|Transfer Learning Framework for Low-Resource Text-to-Speech using a Large-Scale Unlabeled Speech Corpus|interspeech22||https://arxiv.org/abs/2203.15447|
|Training Speaker Embedding Extractors Using Multi-Speaker Audio with Unknown Speaker Boundaries|interspeech22||https://arxiv.org/abs/2203.15436|
|Investigating Self-supervised Pretraining Frameworks for Pathological Speech Recognition|interspeech22||https://arxiv.org/abs/2203.15431|
|Automatic Detection of Speech Sound Disorder in Child Speech Using Posterior-based Speaker Representations|interspeech22||https://arxiv.org/abs/2203.15405|
|Short-Term Word-Learning in a Dynamically Changing Environment|interspeech22||https://arxiv.org/abs/2203.15404|
|VoiceMe: Personalized voice generation in TTS|interspeech22||https://arxiv.org/abs/2203.15379|
|Spoofing-Aware Speaker Verification by Multi-Level Fusion|interspeech22||https://arxiv.org/abs/2203.15377|
|Frequency Dynamic Convolution: Frequency-Adaptive Pattern Recognition for Sound Event Detection|interspeech22||https://arxiv.org/abs/2203.15296|
|Mel Frequency Spectral Domain Defenses against Adversarial Attacks on Speech Recognition Systems|interspeech22||https://arxiv.org/abs/2203.15283|
|Decomposed Temporal Dynamic CNN: Efficient Time-Adaptive Network for Text-Independent Speaker Verification Explained with Speaker Activation Map|interspeech22||https://arxiv.org/abs/2203.15277|
|Applying Syntax$\unicode{x2013}$Prosody Mapping Hypothesis and Prosodic Well-Formedness Constraints to Neural Sequence-to-Sequence Speech Synthesis|interspeech22||https://arxiv.org/abs/2203.15276|
|MFA-Conformer: Multi-scale Feature Aggregation Conformer for Automatic Speaker Verification|interspeech22||https://arxiv.org/abs/2203.15249|
|Visualizations of Complex Sequences of Family-Infant Vocalizations Using Bag-of-Audio-Words Approach Based on Wav2vec 2.0 Features|interspeech22||https://arxiv.org/abs/2203.15183|
|Improving Generalization of Deep Neural Network Acoustic Models with Length Perturbation and N-best Based Label Smoothing|interspeech22||https://arxiv.org/abs/2203.15176|
|CMGAN: Conformer-based Metric GAN for Speech Enhancement|interspeech22||https://arxiv.org/abs/2203.15149|
|Separate What You Describe: Language-Queried Audio Source Separation|interspeech22||https://arxiv.org/abs/2203.15147|
|Word Discovery in Visually Grounded, Self-Supervised Speech Models|interspeech22||https://arxiv.org/abs/2203.15081|
|Neural Vocoder is All You Need for Speech Super-resolution|interspeech22||https://arxiv.org/abs/2203.14941|
|Probabilistic Spherical Discriminant Analysis: An Alternative to PLDA for length-normalized embeddings|interspeech22||https://arxiv.org/abs/2203.14893|
|Dual-Path Style Learning for End-to-End Noise-Robust Speech Recognition|interspeech22||https://arxiv.org/abs/2203.14838|
|Multilingual Simultaneous Speech Translation|interspeech22||https://arxiv.org/abs/2203.14835|
|SASV|interspeech22||https://arxiv.org/abs/2203.14732|
|Training speaker recognition systems with limited data|interspeech22||https://arxiv.org/abs/2203.14688|
|Analysis of Voice Conversion and Code-Switching Synthesis Using VQ-VAE|interspeech22||https://arxiv.org/abs/2203.14640|
|SyncNet: Using Causal Convolutions and Correlating Objective for Time Delay Estimation in Audio Signals|interspeech22||https://arxiv.org/abs/2203.14639|
|On-the-fly Feature Based Speaker Adaptation for Dysarthric and Elderly Speech Recognition|interspeech22||https://arxiv.org/abs/2203.14593|
|An Effective Dereverberation Algorithm by Fusing MVDR and MCLP|interspeech22||https://arxiv.org/abs/2203.14561|
|Investigating Active-learning-based Training Data Selection for Speech Spoofing Countermeasure|interspeech22||https://arxiv.org/abs/2203.14553|
|Self-supervised curriculum learning for speaker verification|interspeech22||https://arxiv.org/abs/2203.14525|
|Multi-source wideband doa estimation method by frequency focusing and error weighting|interspeech22||https://arxiv.org/abs/2203.14494|
|Bunched LPCNet2: Efficient Neural Vocoders Covering Devices from Cloud to Edge|interspeech22||https://arxiv.org/abs/2203.14416|
|SMP-PHAT: Lightweight DoA Estimation by Merging Microphone Pairs|interspeech22||https://arxiv.org/abs/2203.14409|
|Listen, Adapt, Better WER: Source-free Single-utterance Test-time Adaptation for Automatic Speech Recognition|interspeech22||https://arxiv.org/abs/2203.14222|
|Towards Privacy-Preserving Speech Representation for Client-Side Data Sharing|interspeech22||https://arxiv.org/abs/2203.14171|
|A Neural Vocoder Based Packet Loss Concealment Algorithm|interspeech22||https://arxiv.org/abs/2203.14010|
|A Cross-Domain Approach for Continuous Impression Recognition from Dyadic Audio-Visual-Physio Signals|interspeech22||https://arxiv.org/abs/2203.13932|
|Speech-enhanced and Noise-aware Networks for Robust Speech Recognition|interspeech22||https://arxiv.org/abs/2203.13696|
|Chain-based Discriminative Autoencoders for Speech Recognition|interspeech22||https://arxiv.org/abs/2203.13687|
|EmotionNAS: Two-stream Architecture Search for Speech Emotion Recognition|interspeech22||https://arxiv.org/abs/2203.13617|
|Embedding Recurrent Layers with Dual-Path Strategy in a Variant of Convolutional Network for Speaker-Independent Speech Separation|interspeech22||https://arxiv.org/abs/2203.13574|
|Leveraging unsupervised and weakly-supervised data to improve direct speech-to-speech translation|interspeech22||https://arxiv.org/abs/2203.13339|
|Complex Frequency Domain Linear Prediction: A Tool to Compute Modulation Spectrum of Speech|interspeech22||https://arxiv.org/abs/2203.13216|
|Characterizing Therapist's Speaking Style in Relation to Empathy in Psychotherapy|interspeech22||https://arxiv.org/abs/2203.13127|
|mcBERT: Momentum Contrastive Learning with BERT for Zero-Shot Slot Filling|interspeech22||https://arxiv.org/abs/2203.12940|
|SelfRemaster: Self-Supervised Speech Restoration with Analysis-by-Synthesis Approach Using Channel Modeling|interspeech22||https://arxiv.org/abs/2203.12937|
|Pseudo Label Is Better Than Human Label|interspeech22||https://arxiv.org/abs/2203.12668|
|A Scalable Model Specialization Framework for Training and Inference using Submodels and its Application to Speech Model Personalization|interspeech22||https://arxiv.org/abs/2203.12559|
|The VoicePrivacy|interspeech22||https://arxiv.org/abs/2203.12468|
|PHO-LID: A Unified Model Incorporating Acoustic-Phonetic and Phonotactic Information for Language Identification|interspeech22||https://arxiv.org/abs/2203.12366|
|Wider or Deeper Neural Network Architecture for Acoustic Scene Classification with Mismatched Recording Devices|interspeech22||https://arxiv.org/abs/2203.12314|
|Estimation of speaker age and height from speech signal using bi-encoder transformer mixture model|interspeech22||https://arxiv.org/abs/2203.11774|
|CT-SAT: Contextual Transformer for Sequential Audio Tagging|interspeech22||https://arxiv.org/abs/2203.11573|
|Joint Noise Reduction and Listening Enhancement for Full-End Speech Enhancement|interspeech22||https://arxiv.org/abs/2203.11500|
|Residual-Guided Non-Intrusive Speech Quality Assessment|interspeech22||https://arxiv.org/abs/2203.11499|
|Modeling speech recognition and synthesis simultaneously: Encoding and decoding lexical and sublexical semantic information into speech with no direct access to speech data|interspeech22||https://arxiv.org/abs/2203.11476|
|The VoiceMOS Challenge|interspeech22||https://arxiv.org/abs/2203.11389|
|Enhancing Speech Recognition Decoding via Layer Aggregation|interspeech22||https://arxiv.org/abs/2203.11325|
|Automated detection of foreground speech with wearable sensing in everyday home environments: A transfer learning approach|interspeech22||https://arxiv.org/abs/2203.11294|
|Differentiable Duration Modeling for End-to-End Text-to-Speech|interspeech22||https://arxiv.org/abs/2203.11049|
|Separating Content from Speaker Identity in Speech for the Assessment of Cognitive Impairments|interspeech22||https://arxiv.org/abs/2203.10827|
|Vocal effort modeling in neural TTS for improving the intelligibility of synthetic speech in noise|interspeech22||https://arxiv.org/abs/2203.10637|
|Similarity and Content-based Phonetic Self Attention for Speech Recognition|interspeech22||https://arxiv.org/abs/2203.10252|
|Towards a Perceptual Model for Estimating the Quality of Visual Speech|interspeech22||https://arxiv.org/abs/2203.10117|
|Speaker Embedding-aware Neural Diarization: an Efficient Framework for Overlapping Speech Diarization in Meeting Scenarios|interspeech22||https://arxiv.org/abs/2203.09767|
|SepTr: Separable Transformer for Audio Spectrogram Processing|interspeech22||https://arxiv.org/abs/2203.09581|
|Pushing the limits of raw waveform speaker recognition|interspeech22||https://arxiv.org/abs/2203.08488|
|Interpretable Dysarthric Speaker Adaptation based on Optimal-Transport|interspeech22||https://arxiv.org/abs/2203.07143|
|DUAL: Discrete Spoken Unit Adaptive Learning for Textless Spoken Question Answering|interspeech22||https://arxiv.org/abs/2203.04911|
|A study on joint modeling and data augmentation of multi-modalities for audio-visual scene classification|interspeech22||https://arxiv.org/abs/2203.04114|
|Korean Tokenization for Beam Search Rescoring in Speech Recognition|interspeech22||https://arxiv.org/abs/2203.03583|
|PercepNet+: A Phase and SNR Aware PercepNet for Real-Time Speech Enhancement|interspeech22||https://arxiv.org/abs/2203.02263|
|Selective Pseudo-labeling and Class-wise Discriminative Fusion for Sound Event Detection|interspeech22||https://arxiv.org/abs/2203.02191|
|Improving Non-native Word-level Pronunciation Scoring with Phone-level Mixup Data Augmentation and Multi-source Information|interspeech22||https://arxiv.org/abs/2203.01826|
|A Multi-Scale Time-Frequency Spectrogram Discriminator for GAN-based Non-Autoregressive TTS|interspeech22||https://arxiv.org/abs/2203.01080|
|Real time spectrogram inversion on mobile phone|interspeech22||https://arxiv.org/abs/2203.00756|
|A Conformer Based Acoustic Model for Robust Automatic Speech Recognition|interspeech22||https://arxiv.org/abs/2203.00725|
|TRILLsson: Distilled Universal Paralinguistic Speech Representations|interspeech22||https://arxiv.org/abs/2203.00236|
|ICASSP|interspeech22||https://arxiv.org/abs/2202.13288|
|Bi-directional Joint Neural Networks for Intent Classification and Slot Filling|interspeech22||https://arxiv.org/abs/2202.13079|
|End-to-end LPCNet: A Neural Vocoder With Fully-Differentiable LPC Estimation|interspeech22||https://arxiv.org/abs/2202.11301|
|A Summary of the ComParE COVID-19 Challenges|interspeech22||https://arxiv.org/abs/2202.08981|
|SpeechPainter: Text-conditioned Speech Inpainting|interspeech22||https://arxiv.org/abs/2202.07273|
|SHAS: Approaching optimal Segmentation for End-to-End Speech Translation|interspeech22||https://arxiv.org/abs/2202.04774|
|Streaming Multi-Talker ASR with Token-Level Serialized Output Training|interspeech22||https://arxiv.org/abs/2202.00842|
|Internal language model estimation through explicit context vector learning for attention-based encoder-decoder ASR|interspeech22||https://arxiv.org/abs/2201.11627|
|On the Effectiveness of Pinyin-Character Dual-Decoding for End-to-End Mandarin Chinese ASR|interspeech22||https://arxiv.org/abs/2201.10792|
|SASV Challenge|interspeech22||https://arxiv.org/abs/2201.10283|
|Variational Auto-Encoder Based Variability Encoding for Dysarthric Speech Recognition|interspeech22||https://arxiv.org/abs/2201.09422|
|NAS-VAD: Neural Architecture Search for Voice Activity Detection|interspeech22||https://arxiv.org/abs/2201.09032|
|Opencpop: A High-Quality Open Source Chinese Popular Song Corpus for Singing Voice Synthesis|interspeech22||https://arxiv.org/abs/2201.07429|
|How Bad Are Artifacts?: Analyzing the Impact of Speech Enhancement Errors on ASR|interspeech22||https://arxiv.org/abs/2201.06685|
|Group Gated Fusion on Attention-based Bidirectional Alignment for Multimodal Emotion Recognition|interspeech22||https://arxiv.org/abs/2201.06309|
|Investigation of Data Augmentation Techniques for Disordered Speech Recognition|interspeech22||https://arxiv.org/abs/2201.05562|
|Spectro-Temporal Deep Features for Disordered Speech Assessment and Recognition|interspeech22||https://arxiv.org/abs/2201.05554|
|The Effectiveness of Time Stretching for Enhancing Dysarthric Speech for Improved Dysarthric Speech Recognition|interspeech22||https://arxiv.org/abs/2201.04908|
|VoxSRC 2021: The Third VoxCeleb Speaker Recognition Challenge|interspeech22||https://arxiv.org/abs/2201.04583|
|Robust Self-Supervised Audio-Visual Speech Recognition|interspeech22||https://arxiv.org/abs/2201.01763|
|Domain Prompts: Towards memory and compute efficient domain adaptation of ASR systems|interspeech22||https://arxiv.org/abs/2112.08718|
|PM-MMUT: Boosted Phone-mask Data Augmentation using Multi-Modeling Unit Training for Phonetic-Reduction-Robust E2E Speech Recognition|interspeech22||https://arxiv.org/abs/2112.06721|
|Directed Speech Separation for Automatic Speech Recognition of Long Form Conversational Speech|interspeech22||https://arxiv.org/abs/2112.05863|
|SP-SEDT: Self-supervised Pre-training for Sound Event Detection Transformer|interspeech22||https://arxiv.org/abs/2111.15222|
|Implicit Acoustic Echo Cancellation for Keyword Spotting and Device-Directed Speech Detection|interspeech22||https://arxiv.org/abs/2111.10639|
|Uformer: A Unet based dilated complex & real dual-path conformer network for simultaneous speech enhancement and dereverberation|interspeech22||https://arxiv.org/abs/2111.06015|
|Membership Inference Attacks Against Self-supervised Speech Models|interspeech22||https://arxiv.org/abs/2111.05113|
|LiMuSE: Lightweight Multi-modal Speaker Extraction|interspeech22||https://arxiv.org/abs/2111.04063|
|SNRi Target Training for Joint Speech Enhancement and Recognition|interspeech22||https://arxiv.org/abs/2111.00764|
|Revisiting joint decoding based multi-talker speech recognition with DNN acoustic model|interspeech22||https://arxiv.org/abs/2111.00009|
|Time-domain Ad-hoc Array Speech Enhancement Using a Triple-path Network|interspeech22||https://arxiv.org/abs/2110.11844|
|RCT: Random Consistency Training for Semi-supervised Sound Event Detection|interspeech22||https://arxiv.org/abs/2110.11144|
|Progressive Learning for Stabilizing Label Selection in Speech Separation with Mapping-based Method|interspeech22||https://arxiv.org/abs/2110.10593|
|Private Language Model Adaptation for Speech Recognition|interspeech22||https://arxiv.org/abs/2110.10026|
|DECAR: Deep Clustering for learning general-purpose Audio Representations|interspeech22||https://arxiv.org/abs/2110.08895|
|From Start to Finish: Latency Reduction Strategies for Incremental Speech Synthesis in Simultaneous Speech-to-Speech Translation|interspeech22||https://arxiv.org/abs/2110.08214|
|DeToxy: A Large-Scale Multimodal Dataset for Toxicity Classification in Spoken Utterances|interspeech22||https://arxiv.org/abs/2110.07592|
|Exploring Timbre Disentanglement in Non-Autoregressive Cross-Lingual Text-to-Speech|interspeech22||https://arxiv.org/abs/2110.07192|
|Couple Learning for semi-supervised sound event detection|interspeech22||https://arxiv.org/abs/2110.05809|
|Adapting TTS models For New Speakers using Transfer Learning|interspeech22||https://arxiv.org/abs/2110.05798|
|Internal Language Model Adaptation with Text-Only Data for End-to-End Speech Recognition|interspeech22||https://arxiv.org/abs/2110.05354|
|Unsupervised Source Separation via Bayesian Inference in the Latent Domain|interspeech22||https://arxiv.org/abs/2110.05313|
|Efficient Training of Audio Transformers with Patchout|interspeech22||https://arxiv.org/abs/2110.05069|
|Targeted Subset Selection for Limited-data ASR Accent Adaptation|interspeech22||https://arxiv.org/abs/2110.04908|
|SCaLa: Supervised Contrastive Learning for End-to-End Speech Recognition|interspeech22||https://arxiv.org/abs/2110.04187|
|A Study of Low-Resource Speech Commands Recognition based on Adversarial Reprogramming|interspeech22||https://arxiv.org/abs/2110.03894|
|Environment Aware Text-to-Speech Synthesis|interspeech22||https://arxiv.org/abs/2110.03887|
|Input Length Matters: Improving RNN-T and MWER Training for Long-form Telephony Speech Recognition|interspeech22||https://arxiv.org/abs/2110.03841|
|PEAF: Learnable Power Efficient Analog Acoustic Features for Audio Recognition|interspeech22||https://arxiv.org/abs/2110.03715|
|End-To-End Label Uncertainty Modeling for Speech-based Arousal Recognition Using Bayesian Neural Networks|interspeech22||https://arxiv.org/abs/2110.03299|
|CTC Variations Through New WFST Topologies|interspeech22||https://arxiv.org/abs/2110.03098|
|Emphasis control for parallel neural TTS|interspeech22||https://arxiv.org/abs/2110.03012|
|Adversarial Attacks on Machinery Fault Diagnosis|interspeech22||https://arxiv.org/abs/2110.02498|
|MSR-NV: Neural Vocoder Using Multiple Sampling Rates|interspeech22||https://arxiv.org/abs/2109.13714|
|DDS: A new device-degraded speech dataset for speech enhancement|interspeech22||https://arxiv.org/abs/2109.07931|
|Daft-Exprt: Cross-Speaker Prosody Transfer on Any Text for Expressive Speech Synthesis|interspeech22||https://arxiv.org/abs/2108.02271|
|Human Perception of Audio Deepfakes|interspeech22||https://arxiv.org/abs/2107.09667|
|DPT-FSNet: Dual-path Transformer Based Full-band and Sub-band Fusion Network for Speech Enhancement|interspeech22||https://arxiv.org/abs/2104.13002|
|Enhancing Word-Level Semantic Representation via Dependency Structure for Expressive Text-to-Speech Synthesis|interspeech22||https://arxiv.org/abs/2104.06835|
|Lombard Effect for Bilingual Speakers in Cantonese and English: importance of spectro-temporal features|interspeech22||https://arxiv.org/abs/2204.06907|
|ADFF: Attention Based Deep Feature Fusion Approach for Music Emotion Recognition|interspeech22||https://arxiv.org/abs/2204.05649|
|Unsupervised Uncertainty Measures of Automatic Speech Recognition for Non-intrusive Speech Intelligibility Prediction|interspeech22||https://arxiv.org/abs/2204.04288|
|Exploiting Hidden Representations from a DNN-based Speech Recogniser for Speech Intelligibility Prediction in Hearing-impaired Listeners|interspeech22||https://arxiv.org/abs/2204.04287|
|Disentangled Latent Speech Representation for Automatic Pathological Intelligibility Assessment|interspeech22||https://arxiv.org/abs/2204.04016|
|RaDur: A Reference-aware and Duration-robust Network for Target Sound Detection|interspeech22||https://arxiv.org/abs/2204.02143|
|A Two-student Learning Framework for Mixed Supervised Target Sound Detection|interspeech22||https://arxiv.org/abs/2204.02088|
|An objective test tool for pitch extractors' response attributes|interspeech22||https://arxiv.org/abs/2204.00902|
|Improving Target Sound Extraction with Timestamp Information|interspeech22||https://arxiv.org/abs/2204.00821|
|Fast Real-time Personalized Speech Enhancement: End-to-End Enhancement Network (E3Net) and Knowledge Distillation|interspeech22||https://arxiv.org/abs/2204.00771|
|End-to-End Multi-speaker ASR with Independent Vector Analysis|interspeech22||https://arxiv.org/abs/2204.00218|
|Spatial Loss for Unsupervised Multi-channel Source Separation|interspeech22||https://arxiv.org/abs/2204.00210|
|Better Intermediates Improve CTC Inference|interspeech22||https://arxiv.org/abs/2204.00176|
|InterAug: Augmenting Noisy Intermediate Predictions for CTC-based ASR|interspeech22||https://arxiv.org/abs/2204.00174|
|Open Source MagicData-RAMC: A Rich Annotated Mandarin Conversational(RAMC) Speech Dataset|interspeech22||https://arxiv.org/abs/2203.16844|
|A Hybrid Continuity Loss to Reduce Over-Suppression for Time-domain Target Speaker Extraction|interspeech22||https://arxiv.org/abs/2203.16843|
|On Metric Learning for Audio-Text Cross-Modal Retrieval|interspeech22||https://arxiv.org/abs/2203.15537|
|Frequency-Directional Attention Model for Multilingual Automatic Speech Recognition|interspeech22||https://arxiv.org/abs/2203.15473|
|Investigation of Different Calibration Methods for Deep Speaker Embedding based Verification Systems|interspeech22||https://arxiv.org/abs/2203.15106|
|Robust Speaker Recognition with Transformers Using wav2vec 2.0|interspeech22||https://arxiv.org/abs/2203.15095|
|Analyzing Language-Independent Speaker Anonymization Framework under Unseen Conditions|interspeech22||https://arxiv.org/abs/2203.14834|
|STUDIES: Corpus of Japanese Empathetic Dialogue Speech Towards Friendly Voice Agent|interspeech22||https://arxiv.org/abs/2203.14757|
|WeSinger: Data-augmented Singing Voice Synthesis with Auxiliary Losses|interspeech22||https://arxiv.org/abs/2203.10750|
|ECAPA-TDNN for Multi-speaker Text-to-speech Synthesis|interspeech22||https://arxiv.org/abs/2203.10473|
|TaylorBeamformer: Learning All-Neural Beamformer for Multi-Channel Speech Enhancement from Taylor's Approximation Theory|interspeech22||https://arxiv.org/abs/2203.07195|
|MDNet: Learning Monaural Speech Enhancement from Deep Prior Gradient|interspeech22||https://arxiv.org/abs/2203.07179|
|RefineGAN: Universally Generating Waveform Better than Ground Truth with Highly Accurate Pitch and Intensity Responses|interspeech22||https://arxiv.org/abs/2111.00962|
|Independence-based Joint Dereverberation and Separation with Neural Source Model|interspeech22||https://arxiv.org/abs/2110.06545|
|Disentangled dimensionality reduction for noise-robust speaker diarisation|interspeech22||https://arxiv.org/abs/2110.03380|
