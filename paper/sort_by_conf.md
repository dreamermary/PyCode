|题目|会议||链接|
|---|---|---|---|
|The USTC-NELSLIP Systems for Simultaneous Speech Translation Task at IWSLT 2021|acl21||https://aclanthology.org/2021.iwslt-1.2/|
|Multilingual Speech Translation from Efficient Finetuning of Pretrained Models|acl21||https://aclanthology.org/2021.acl-long.68/|
|Beyond Sentence-Level End-to-End Speech Translation: Context Helps|acl21||https://aclanthology.org/2021.acl-long.200/|
|Stacked Acoustic-and-Textual Encoding: Integrating the Pre-trained Models into Speech Translation Encoders|acl21||https://aclanthology.org/2021.acl-long.204/|
|Cascade versus Direct Speech Translation: Do the Differences Still Make a Difference?|acl21||https://aclanthology.org/2021.acl-long.224/|
|Improving Speech Translation by Understanding and Learning from the Auxiliary Text Translation Task|acl21||https://aclanthology.org/2021.acl-long.328/|
|Without Further Ado: Direct and Simultaneous Speech Translation by AppTek in 2021|acl21||https://aclanthology.org/2021.iwslt-1.5/|
|The Volctrans Neural Speech Translation System for IWSLT 2021|acl21||https://aclanthology.org/2021.iwslt-1.6/|
|A Large-Scale Chinese Multimodal NER Dataset with Speech Clues|acl21||https://aclanthology.org/2021.acl-long.218/|
|The NiuTrans End-to-End Speech Translation System for IWSLT 2021 Offline Task|acl21||https://aclanthology.org/2021.iwslt-1.9/|
|ESPnet-ST IWSLT 2021 Offline Speech Translation System|acl21||https://aclanthology.org/2021.iwslt-1.10/|
|End-to-End Speech Translation with Pre-trained Models and Adapters: UPC at IWSLT 2021|acl21||https://aclanthology.org/2021.iwslt-1.11/|
|VUS at IWSLT 2021: A Finetuned Pipeline for Offline Speech Translation|acl21||https://aclanthology.org/2021.iwslt-1.12/|
|KIT’s IWSLT 2021 Offline Speech Translation System|acl21||https://aclanthology.org/2021.iwslt-1.13/|
|FST: the FAIR Speech Translation System for the IWSLT21 Multilingual Shared Task|acl21||https://aclanthology.org/2021.iwslt-1.14/|
|Maastricht University’s Multilingual Speech Translation System for IWSLT 2021|acl21||https://aclanthology.org/2021.iwslt-1.15/|
|ZJU’s IWSLT 2021 Speech Translation System|acl21||https://aclanthology.org/2021.iwslt-1.16/|
|Multilingual Speech Translation with Unified Transformer: Huawei Noah’s Ark Lab at IWSLT 2021|acl21||https://aclanthology.org/2021.iwslt-1.17/|
|Multilingual Speech Translation KIT @ IWSLT2021|acl21||https://aclanthology.org/2021.iwslt-1.18/|
|Edinburgh’s End-to-End Multilingual Speech Translation System for IWSLT 2021|acl21||https://aclanthology.org/2021.iwslt-1.19/|
|ON-TRAC’ systems for the IWSLT 2021 low-resource speech translation and multilingual speech translation shared tasks|acl21||https://aclanthology.org/2021.iwslt-1.20/|
|IMS’ Systems for the IWSLT 2021 Low-Resource Speech Translation Task|acl21||https://aclanthology.org/2021.iwslt-1.21/|
|The USYD-JD Speech Translation System for IWSLT2021|acl21||https://aclanthology.org/2021.iwslt-1.22/|
|Inverted Projection for Robust Speech Translation|acl21||https://aclanthology.org/2021.iwslt-1.28/|
|Towards the evaluation of automatic simultaneous speech translation from a communicative perspective|acl21||https://aclanthology.org/2021.iwslt-1.29/|
|Lightweight Adapter Tuning for Multilingual Speech Translation|acl21||https://aclanthology.org/2021.acl-short.103/|
|NeurST: Neural Speech Translation Toolkit|acl21||https://aclanthology.org/2021.acl-demo.7/|
|||||
|Uwspeech: Speech To Speech Translation For Unwritten Languages|aaai21||	https://arxiv.org/abs/2006.07926|
|Listen, Understand And Translate: Triple Supervision Decouples End-To-End Speech-To-Text Translation	|aaai21||https://www.aaai.org/AAAI21Papers/AAAI-10343.DongQ.pdf|
|Multi-Spectrogan: High-Diversity And High-Fidelity Spectrogram Generation With Adversarial Style Combination For Speech Synthesis|aaai21||	https://arxiv.org/abs/2012.07267|
|Consecutive Decoding For Speech-To-Text Translation	|aaai21||https://www.aaai.org/AAAI21Papers/AAAI-9845.DongQ.pdf|
|||||
|Is "moby dick" a Whale or a Bird? Named Entities and Terminology in Speech Translation.|emnlp21||	https://arxiv.org/abs/2109.07439|
|Speechformer - Reducing Information Loss in Direct Speech Translation.|emnlp21||	https://arxiv.org/abs/2109.04574|
|Mutual-Learning Improves End-to-End Speech Translation.	|emnlp21||https://dblp.org/rec/conf/emnlp/ZhaoLCG21|
|||||
|Sig2Sig: Signal Translation Networks to Take the Remains of the Past	|icassp21||https://ieeexplore.ieee.org/document/9415084|
|Robust Latent Representations Via Cross-Modal Translation and Alignment|icassp21||	https://ieeexplore.ieee.org/document/9413456|
|ORTHROS: non-autoregressive end-to-end speech translation With dual-decoder|icassp21||	https://ieeexplore.ieee.org/document/9415093|
|Cascaded Models with Cyclic Feedback for Direct Speech Translation|icassp21||	https://ieeexplore.ieee.org/document/9413719|
|Jointly Trained Transformers Models for Spoken Language Translation|icassp21||	https://ieeexplore.ieee.org/document/9414159|
|Streaming Simultaneous Speech Translation with Augmented Memory Transformer|icassp21||	https://ieeexplore.ieee.org/document/9414897|
|An Empirical Study of End-To-End Simultaneous Speech Translation Decoding Strategies|icassp21||	https://ieeexplore.ieee.org/document/9414276|
|Sentence Boundary Augmentation for Neural Machine Translation Robustness|icassp21||	https://ieeexplore.ieee.org/document/9413492|
|An Empirical Study on Task-Oriented Dialogue Translation	|icassp21||https://ieeexplore.ieee.org/document/9413521|
|Machine Translation Verbosity Control for Automatic Dubbing|icassp21||	https://ieeexplore.ieee.org/document/9414411|
|||||
|End-to-End Speech Translation for Code Switched Speech|acl22||https://arxiv.org/abs/2204.05076|
|Learning When to Translate for Streaming Speech|acl22||https://arxiv.org/abs/2109.07368|
|Direct speech-to-speech translation with discrete units|acl22||https://arxiv.org/abs/2107.05604|
|Under the Morphosyntactic Lens: A Multifaceted Evaluation of Gender Bias in Speech Translation|acl22||https://arxiv.org/abs/2203.09866|
|Sample, Translate, Recombine: Leveraging Audio Alignments for Data Augmentation in End-to-end Speech Translation|acl22||https://arxiv.org/abs/2203.08757|
|STEMM: Self-learning with Speech-text Manifold Mixup for Speech Translation|acl22||https://arxiv.org/abs/2203.10426|
|||||
|Regularizing End-to-End Speech Translation with Triangular Decomposition Agreement|aaai22||https://arxiv.org/abs/2112.10991|
|||||
|Tackling data scarcity in speech translation using zero-shot multilingual machine translation techniques|icassp22||https://arxiv.org/abs/2201.11172|
|Isometric MT: Neural Machine Translation for Automatic Dubbing|icassp22||https://arxiv.org/abs/2112.08682|
|Prosody-Aware Neural Machine Translation for Dubbing|icassp22||https://arxiv.org/abs/2112.08548|
|||||
|||||
|Relative Positional Encoding for Speech Recognition and Direct Translation|https://www.isca-speech.org/archive/interspeech_2020/pham20_interspeech.html|interspeech20|ASR Neural Network Architectures I|
|Efficient Wait-k Models for Simultaneous Machine Translation|https://www.isca-speech.org/archive/interspeech_2020/elbayad20_interspeech.html|interspeech20|Speech Translation and Multilingual/Multimodal Learning|
|Investigating Self-Supervised Pre-Training for End-to-End Speech Translation|https://www.isca-speech.org/archive/interspeech_2020/nguyen20_interspeech.html|interspeech20|Speech Translation and Multilingual/Multimodal Learning|
|Contextualized Translation of Automatically Segmented Speech|https://www.isca-speech.org/archive/interspeech_2020/gaido20_interspeech.html|interspeech20|Speech Translation and Multilingual/Multimodal Learning|
|Self-Training for End-to-End Speech Translation|https://www.isca-speech.org/archive/interspeech_2020/pino20_interspeech.html|interspeech20|Speech Translation and Multilingual/Multimodal Learning|
|Self-Supervised Representations Improve End-to-End Speech Translation|https://www.isca-speech.org/archive/interspeech_2020/wu20g_interspeech.html|interspeech20|Speech Translation and Multilingual/Multimodal Learning|
|Low-Latency Sequence-to-Sequence Speech Recognition and Translation by Partial Hypothesis Selection|https://www.isca-speech.org/archive/interspeech_2020/liu20s_interspeech.html|interspeech20|ASR Neural Network Architectures and Training II|
|Improving Cross-Lingual Transfer Learning for End-to-End Speech Recognition with Speech Translation|https://www.isca-speech.org/archive/interspeech_2020/wang20ia_interspeech.html|interspeech20|Multilingual and Code-Switched ASR|
|||||
|Domain-Aware Self-Attention for Multi-Domain Neural Machine Translation|https://www.isca-speech.org/archive/interspeech_2021/zhang21n_interspeech.html|interspeech21|Novel Neural Network Architectures for ASR|
|SpecRec: An Alternative Solution for Improving End-to-End Speech-to-Text Translation via Spectrogram Reconstruction|https://www.isca-speech.org/archive/interspeech_2021/chen21i_interspeech.html|interspeech21|Spoken Machine Translation|
|Subtitle Translation as Markup Translation|https://www.isca-speech.org/archive/interspeech_2021/cherry21_interspeech.html|interspeech21|Spoken Machine Translation|
|Large-Scale Self- and Semi-Supervised Learning for Speech Translation|https://www.isca-speech.org/archive/interspeech_2021/wang21r_interspeech.html|interspeech21|Spoken Machine Translation|
|CoVoST 2 and Massively Multilingual Speech Translation|https://www.isca-speech.org/archive/interspeech_2021/wang21s_interspeech.html|interspeech21|Spoken Machine Translation|
|AlloST: Low-Resource Speech Translation Without Source Transcription|https://www.isca-speech.org/archive/interspeech_2021/cheng21_interspeech.html|interspeech21|Spoken Machine Translation|
|Weakly-Supervised Speech-to-Text Mapping with Visually Connected Non-Parallel Speech-Text Data Using Cyclic Partially-Aligned Transformer|https://www.isca-speech.org/archive/interspeech_2021/effendi21_interspeech.html|interspeech21|Spoken Machine Translation|
|Transcribing Paralinguistic Acoustic Cues to Target Language Text in Transformer-Based Speech-to-Text Translation|https://www.isca-speech.org/archive/interspeech_2021/tokuyama21_interspeech.html|interspeech21|Spoken Machine Translation|
|End-to-End Speech Translation via Cross-Modal Progressive Training|https://www.isca-speech.org/archive/interspeech_2021/ye21_interspeech.html|interspeech21|Spoken Machine Translation|
|ASR Posterior-Based Loss for Multi-Task End-to-End Speech Translation|https://www.isca-speech.org/archive/interspeech_2021/ko21_interspeech.html|interspeech21|Spoken Machine Translation|
|Towards Simultaneous Machine Interpretation|https://www.isca-speech.org/archive/interspeech_2021/perezgonzalezdemartos21_interspeech.html|interspeech21|Spoken Machine Translation|
|Lexical Modeling of ASR Errors for Robust Speech Translation|https://www.isca-speech.org/archive/interspeech_2021/martucci21_interspeech.html|interspeech21|Spoken Machine Translation|
|Optimally Encoding Inductive Biases into the Transformer Improves End-to-End Speech Translation|https://www.isca-speech.org/archive/interspeech_2021/vyas21_interspeech.html|interspeech21|Spoken Machine Translation|
|Effects of Feature Scaling and Fusion on Sign Language Translation|https://www.isca-speech.org/archive/interspeech_2021/ananthanarayana21_interspeech.html|interspeech21|Spoken Machine Translation|
|Integrating Frequency Translational Invariance in TDNNs and Frequency Positional Information in 2D ResNets to Enhance Speaker Verification|https://www.isca-speech.org/archive/interspeech_2021/thienpondt21_interspeech.html|interspeech21|SdSV Challenge 2021: Analysis and Exploration of New Ideas on Short-Duration Speaker Verification|
|Impact of Encoding and Segmentation Strategies on End-to-End Simultaneous Speech Translation|https://www.isca-speech.org/archive/interspeech_2021/nguyen21d_interspeech.html|interspeech21|Spoken Language Processing II|
|Lost in Interpreting: Speech Translation from Source or Interpreter?|https://www.isca-speech.org/archive/interspeech_2021/machacek21_interspeech.html|interspeech21|Spoken Language Processing II|
|The Multilingual TEDx Corpus for Speech Recognition and Translation|https://www.isca-speech.org/archive/interspeech_2021/salesky21_interspeech.html|interspeech21|Tools, Corpora and Resources|
|kosp2e: Korean Speech to English Translation Corpus|https://www.isca-speech.org/archive/interspeech_2021/cho21b_interspeech.html|interspeech21|Tools, Corpora and Resources|
|||||
|Highland Puebla Nahuatl Speech Translation Corpus for Endangered Language Documentation|naacl21||https://aclanthology.org/2021.americasnlp-1.7/|
|BSTC: A Large-Scale Chinese-English Speech Translation Dataset|naacl21||https://aclanthology.org/2021.autosimtrans-1.5/|
|Source and Target Bidirectional Knowledge Distillation for End-to-end Speech Translation|naacl21||https://aclanthology.org/2021.naacl-main.150/|
|||||
|Large-Scale Streaming End-to-End Speech Translation with Neural Transducers|interspeech22||https://arxiv.org/abs/2204.05352|
|GigaST: A 10,000-hour Pseudo Speech Translation Corpus|interspeech22||https://arxiv.org/abs/2204.03939|
|Enhanced Direct Speech-to-Speech Translation Using Self-supervised Pre-training and Data Augmentation|interspeech22||https://arxiv.org/abs/2204.02967|
|Combining Spectral and Self-Supervised Features for Low Resource Speech Recognition and Translation|interspeech22||https://arxiv.org/abs/2204.02470|
|Speech Segmentation Optimization using Segmented Bilingual Speech Corpus for End-to-end Speech Translation|interspeech22||https://arxiv.org/abs/2203.15479|
|Multilingual Simultaneous Speech Translation|interspeech22||https://arxiv.org/abs/2203.14835|
|Leveraging unsupervised and weakly-supervised data to improve direct speech-to-speech translation|interspeech22||https://arxiv.org/abs/2203.13339|
|SHAS: Approaching optimal Segmentation for End-to-End Speech Translation|interspeech22||https://arxiv.org/abs/2202.04774|
|From Start to Finish: Latency Reduction Strategies for Incremental Speech Synthesis in Simultaneous Speech-to-Speech Translation|interspeech22||https://arxiv.org/abs/2110.08214|


