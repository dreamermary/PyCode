>关键词：框架/综述实时/流/多语/预训练微调/数据增强/S2S/ML/iwlst/NA/CS/NER/transformer改进
    CS: code-switch
    NA: Non-autogress
    iwslt比赛: 低资源，多语，离线


### 综合
|---|---|---|---|
|---|---|---|---|
|Cascade versus Direct Speech Translation: Do the Differences Still Make a Difference?|acl21|综述：级联&端到端 |https://aclanthology.org/2021.acl-long.224/|
|An Empirical Study on Task-Oriented Dialogue Translation	|icassp21| |https://ieeexplore.ieee.org/document/9413521|
|NeurST: Neural Speech Translation Toolkit|acl21| 框架|https://aclanthology.org/2021.acl-demo.7/|
|A Large-Scale Chinese Multimodal NER Dataset with Speech Clues|acl21|数据集 |https://aclanthology.org/2021.acl-long.218/|

### 数据的利用，多任务/预训练
|---|---|---|---|
|---|---|---|---|
|Stacked Acoustic-and-Textual Encoding: Integrating the Pre-trained Models into Speech Translation Encoders|acl21| |https://aclanthology.org/2021.acl-long.204/|
|Improving Speech Translation by Understanding and Learning from the Auxiliary Text Translation Task|acl21| |https://aclanthology.org/2021.acl-long.328/|
|Listen, Understand And Translate: Triple Supervision Decouples End-To-End Speech-To-Text Translation	|aaai21| |https://www.aaai.org/AAAI21Papers/AAAI-10343.DongQ.pdf|
|Consecutive Decoding For Speech-To-Text Translation	|aaai21| |https://www.aaai.org/AAAI21Papers/AAAI-9845.DongQ.pdf|
|STEMM: Self-learning with Speech-text Manifold Mixup for Speech Translation|acl22| |https://arxiv.org/abs/2203.10426|
||||
|Regularizing End-to-End Speech Translation with Triangular Decomposition Agreement|aaai22| 周|https://arxiv.org/abs/2112.10991|
|Beyond Sentence-Level End-to-End Speech Translation: Context Helps|acl21| |https://aclanthology.org/2021.acl-long.200/|
|Robust Latent Representations Via Cross-Modal Translation and Alignment|icassp21| 复杂|	https://ieeexplore.ieee.org/document/9413456|
|Cascaded Models with Cyclic Feedback for Direct Speech Translation|icassp21| |	https://ieeexplore.ieee.org/document/9413719|
|Jointly Trained Transformers Models for Spoken Language Translation|icassp21|HOW2 |	https://ieeexplore.ieee.org/document/9414159|



### 多语
|---|---|---|---|
|---|---|---|---|
|Multilingual Speech Translation from Efficient Finetuning of Pretrained Models|acl21|多语/预训练微调|https://aclanthology.org/2021.acl-long.68/|
|Lightweight Adapter Tuning for Multilingual Speech Translation|acl21|多语|https://aclanthology.org/2021.acl-short.103/|

### 杂
|---|---|---|---|
|---|---|---|---|
|Speechformer - Reducing Information Loss in Direct Speech Translation.|emnlp21|transformer改进 |	https://arxiv.org/abs/2109.04574|
|Mutual-Learning Improves End-to-End Speech Translation.	|emnlp21|ML|https://dblp.org/rec/conf/emnlp/ZhaoLCG21|
|End-to-End Speech Translation for Code Switched Speech|acl22|CS|https://arxiv.org/abs/2204.05076|
|Sample, Translate, Recombine: Leveraging Audio Alignments for Data Augmentation in End-to-end Speech Translation|acl22|数据增强|https://arxiv.org/abs/2203.08757|
|Is "moby dick" a Whale or a Bird? Named Entities and Terminology in Speech Translation.|emnlp21|NER |	https://arxiv.org/abs/2109.07439|
|ORTHROS: non-autoregressive end-to-end speech translation With dual-decoder|icassp21|NA|	https://ieeexplore.ieee.org/document/9415093|
|Under the Morphosyntactic Lens: A Multifaceted Evaluation of Gender Bias in Speech Translation|acl22| |https://arxiv.org/abs/2203.09866|

### 流/实时
|---|---|---|---|
|---|---|---|---|
|Learning When to Translate for Streaming Speech|acl22|流|https://arxiv.org/abs/2109.07368|
|Streaming Simultaneous Speech Translation with Augmented Memory Transformer|icassp21|实时/流|	https://ieeexplore.ieee.org/document/9414897|
|An Empirical Study of End-To-End Simultaneous Speech Translation Decoding Strategies|icassp21|实时/解码策略综述|	https://ieeexplore.ieee.org/document/9414276|

### MT
|---|---|---|---|
|---|---|---|---|
|Machine Translation Verbosity Control for Automatic Dubbing|icassp21| |	https://ieeexplore.ieee.org/document/9414411|
|Sentence Boundary Augmentation for Neural Machine Translation Robustness|icassp21| |	https://ieeexplore.ieee.org/document/9413492|
|Tackling data scarcity in speech translation using zero-shot multilingual machine translation techniques|icassp22|多语MT|https://arxiv.org/abs/2201.11172|
|Isometric MT: Neural Machine Translation for Automatic Dubbing|icassp22| |https://arxiv.org/abs/2112.08682|
|Prosody-Aware Neural Machine Translation for Dubbing|icassp22| |https://arxiv.org/abs/2112.08548|

### S2S
|---|---|---|---|
|---|---|---|---|
|Sig2Sig: Signal Translation Networks to Take the Remains of the Past	|icassp21| |https://ieeexplore.ieee.org/document/9415084|
|Uwspeech: Speech To Speech Translation For Unwritten Languages|aaai21|S2S|	https://arxiv.org/abs/2006.07926|
|Direct speech-to-speech translation with discrete units|acl22|S2S|https://arxiv.org/abs/2107.05604|


### iwslt
|---|---|---|---|
|---|---|---|---|
|Towards the evaluation of automatic simultaneous speech translation from a communicative perspective|acl21|实时|https://aclanthology.org/2021.iwslt-1.29/|
|Without Further Ado: Direct and Simultaneous Speech Translation by AppTek in 2021|acl21| 实时|https://aclanthology.org/2021.iwslt-1.5/|
|The USTC-NELSLIP Systems for Simultaneous Speech Translation Task at IWSLT 2021|acl21|实时|https://aclanthology.org/2021.iwslt-1.2/|
|The NiuTrans End-to-End Speech Translation System for IWSLT 2021 Offline Task|acl21|离线|https://aclanthology.org/2021.iwslt-1.9/|
|ESPnet-ST IWSLT 2021 Offline Speech Translation System|acl21|离线|https://aclanthology.org/2021.iwslt-1.10/|
|VUS at IWSLT 2021: A Finetuned Pipeline for Offline Speech Translation|acl21|离线|https://aclanthology.org/2021.iwslt-1.12/|
|KIT’s IWSLT 2021 Offline Speech Translation System|acl21|离线|https://aclanthology.org/2021.iwslt-1.13/|
|FST: the FAIR Speech Translation System for the IWSLT21 Multilingual Shared Task|acl21|多语|https://aclanthology.org/2021.iwslt-1.14/|
|Maastricht University’s Multilingual Speech Translation System for IWSLT 2021|acl21|多语|https://aclanthology.org/2021.iwslt-1.15/|
|Edinburgh’s End-to-End Multilingual Speech Translation System for IWSLT 2021|acl21|多语|https://aclanthology.org/2021.iwslt-1.19/|
|Multilingual Speech Translation with Unified Transformer: Huawei Noah’s Ark Lab at IWSLT 2021|acl21|多语|https://aclanthology.org/2021.iwslt-1.17/|
|Multilingual Speech Translation KIT @ IWSLT2021|acl21|多语|https://aclanthology.org/2021.iwslt-1.18/|
|ON-TRAC’ systems for the IWSLT 2021 low-resource speech translation and multilingual speech translation shared tasks|acl21|低资源/多语|https://aclanthology.org/2021.iwslt-1.20/|
|IMS’ Systems for the IWSLT 2021 Low-Resource Speech Translation Task|acl21|低资源|https://aclanthology.org/2021.iwslt-1.21/|
|The USYD-JD Speech Translation System for IWSLT2021|acl21|iwslt|https://aclanthology.org/2021.iwslt-1.22/|
|Inverted Projection for Robust Speech Translation|acl21| |https://aclanthology.org/2021.iwslt-1.28/|
|The Volctrans Neural Speech Translation System for IWSLT 2021|acl21|iwslt|https://aclanthology.org/2021.iwslt-1.6/|
|ZJU’s IWSLT 2021 Speech Translation System|acl21|iwslt|https://aclanthology.org/2021.iwslt-1.16/|
|End-to-End Speech Translation with Pre-trained Models and Adapters: UPC at IWSLT 2021|acl21|iwslt|https://aclanthology.org/2021.iwslt-1.11/|



